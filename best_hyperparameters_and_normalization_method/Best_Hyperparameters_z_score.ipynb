{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e019071b-b915-4e05-93ac-b1d4ccc67773",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFolderHBK = r\"G:\\Semester Arbeit\\Programming\\Extracted_Features\\HBK\\HBK_14285Hz_original_all_features\\features\"\n",
    "targetFolderMCC5 = r\"G:\\Semester Arbeit\\Programming\\Extracted_Features\\MCC5\\MCC5_12800Hz_original_all_features_motor_vibration_x\\features\"\n",
    "targetFolderSIZA = r\"G:\\Semester Arbeit\\Programming\\Extracted_Features\\SIZA\\SIZA_original_all_features\\features\"\n",
    "normalization_method = \"z_score\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24c9ea-6eb1-4abc-a4a4-735cf1178187",
   "metadata": {},
   "source": [
    "# Environment Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eaba3c8-a35f-4004-b6a5-a62b3eec640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mlflow\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, hamming_loss, hinge_loss, jaccard_score, log_loss, precision_score, recall_score, f1_score, make_scorer\n",
    "from pathlib import Path\n",
    "from pycaret.classification import * \n",
    "from torch import tensor\n",
    "from torchmetrics.classification import BinaryAccuracy, MulticlassAccuracy\n",
    "import optuna\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import GANDALFConfig, CategoryEmbeddingModel,GatedAdditiveTreeEnsembleConfig, NodeConfig, FTTransformerConfig, TabNetModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    ModelConfig,\n",
    "    TrainerConfig,\n",
    "    ExperimentConfig,\n",
    ")\n",
    "from collections import Counter\n",
    "from data_loader import load_feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3d6c1-e829-4aee-b5f4-19a277312efd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2758484f-d1a4-477c-a32f-e760037badc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeDataframe(dataframe, normalization_method):\n",
    "    \"\"\"\n",
    "    Normalizes the features of a dataframe using a specified method.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The input dataframe with a 'Label' column.\n",
    "        normalization_method (str): The method to use (\"min_max\", \"z_score\", \"robust_scaling\").\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe with scaled features.\n",
    "    \"\"\"\n",
    "    # Separate features (X) and the target variable (y)\n",
    "    y = dataframe['Label']\n",
    "    X = dataframe.drop(columns=['Label'])\n",
    "\n",
    "    # Select the scaler based on the chosen method\n",
    "    if normalization_method == \"min_max\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif normalization_method == \"z_score\":\n",
    "        scaler = StandardScaler()\n",
    "    elif normalization_method == \"robust_scaling\":\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        # Raise an error for an invalid method name\n",
    "        raise ValueError(f\"Unknown normalization_method: '{normalization_method}'\")\n",
    "\n",
    "    # Fit the scaler to the data and transform it\n",
    "    X_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X),\n",
    "        columns=X.columns,\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    # Rejoin the scaled features with the label column\n",
    "    df_scaled = X_scaled.join(y)\n",
    "    \n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44aae2d5-3c4b-4bbb-bbbc-6621172653d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredictionHistograms(df, domain, normalization):\n",
    "    # 1) mark correct vs incorrect\n",
    "    df = df.copy()\n",
    "    df['prediction_quality'] = np.where(\n",
    "        df['Label'] == df['prediction_label'],\n",
    "        'correct',\n",
    "        'incorrect'\n",
    "    )\n",
    "    \n",
    "    # 2) choose a palette (you can override these colors if you like)\n",
    "    pal = dict(zip(\n",
    "        ['correct','incorrect'],\n",
    "        sns.color_palette(n_colors=2)\n",
    "    ))\n",
    "    \n",
    "    skip = {'Label','prediction_label','prediction_score','prediction_quality'}\n",
    "    for col in df.columns:\n",
    "        if col in skip:\n",
    "            continue\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        sns.histplot(\n",
    "            data=df, x=col, hue='prediction_quality',\n",
    "            palette=pal,\n",
    "            kde=True, multiple='layer', element='step',\n",
    "            alpha=0.5,\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # 3) build a manual legend using the same palette\n",
    "        handles = [\n",
    "            mpatches.Patch(color=pal[k], label=k)\n",
    "            for k in ['correct','incorrect']\n",
    "        ]\n",
    "        ax.legend(\n",
    "            handles=handles,\n",
    "            title='Prediction Quality'\n",
    "        )\n",
    "        \n",
    "        ax.set_title(\n",
    "            f\"Distribution of {col} in the '{domain}' domain\\n\"\n",
    "            f\"(normalization = '{normalization}')\"\n",
    "        )\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7180ffc-82c3-4100-a659-90dfe8bdeff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_predictions(df):\n",
    "    return df[\n",
    "        ((df['Label'] == 'damaged')   & (df['prediction_label'] == 'healthy'))\n",
    "      | ((df['Label'] == 'healthy')  & (df['prediction_label'] == 'damaged'))\n",
    "    ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6effaf0-7730-46e4-9b29-a6133fc41f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance_df(model, df):\n",
    "    importance = model.feature_importances_\n",
    "    n = len(importance)\n",
    "    features = df.columns[:n]\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Features': features,\n",
    "        'importance': importance\n",
    "    })\n",
    "    return fi_df.sort_values(by='importance', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d896eca8-c332-4e1a-8643-647da5fb5650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_feature_importance_df(model, df):\n",
    "    if not hasattr(model, 'coef_'):\n",
    "        raise ValueError(\"This SVM model has no coefficients. Use a linear kernel.\")\n",
    "    \n",
    "    importance = model.coef_.ravel()  # Flatten in case of binary classification\n",
    "    n = len(importance)\n",
    "    features = df.columns[:n]\n",
    "    fi_df = pd.DataFrame({\n",
    "        'Features': features,\n",
    "        'importance': abs(importance)\n",
    "    })\n",
    "    return fi_df.sort_values(by='importance', ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3ffb6f-eed8-4a5d-9b91-737370fc234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_counter = Counter()\n",
    "def add_top_features(feature_df: pd.DataFrame, top_n: int):\n",
    "    top_features = feature_df.nlargest(top_n, 'importance')['Features']\n",
    "    feature_counter.update(top_features)\n",
    "    \n",
    "def plot_feature_importance():\n",
    "    feature_freq = pd.DataFrame(feature_counter.items(), columns=['Feature', 'Count'])\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(data=feature_freq.sort_values(by='Count', ascending=False),\n",
    "                x='Feature', y='Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title('Feature Frequency Across Experiments')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7dc31c-45ef-49c4-9f58-7890b966ccd7",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f13cd2ff-10b7-4db8-9fc8-f968e9c5324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"Best_Hyperparameters_z_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ba897d-d88c-410a-9597-96585f9a7b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 161 files into a DataFrame with shape (200093, 30)\n",
      "Applied binary classification: 'healthy' vs 'damaged'.\n",
      "Dropped 'Speed' and 'Torque' columns.\n",
      "Final DataFrame shape: (200093, 28)\n"
     ]
    }
   ],
   "source": [
    "df_binary_HBK = load_feature_data(\n",
    "    features_path=targetFolderHBK,\n",
    "    include_augmentations=False,      # Only 'original' data\n",
    "    include_speed_torque=False,       # Drop operating conditions\n",
    "    binary_classification=True,       # 'healthy' vs 'damaged'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72b37f31-8878-4168-aa49-a720052e2c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 36 files into a DataFrame with shape (53928, 30)\n",
      "Applied binary classification: 'healthy' vs 'damaged'.\n",
      "Dropped 'Speed' and 'Torque' columns.\n",
      "Final DataFrame shape: (53928, 28)\n"
     ]
    }
   ],
   "source": [
    "df_binary_SIZA = load_feature_data(\n",
    "    features_path=targetFolderSIZA,\n",
    "    include_augmentations=False,      # Only 'original' data\n",
    "    include_speed_torque=False,       # Drop operating conditions\n",
    "    binary_classification=True,       # 'healthy' vs 'damaged'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87904925-1ca9-40f1-adec-82912fb5bd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 36 files into a DataFrame with shape (53928, 30)\n",
      "Applied binary classification: 'healthy' vs 'damaged'.\n",
      "Dropped 'Speed' and 'Torque' columns.\n",
      "Final DataFrame shape: (53928, 28)\n"
     ]
    }
   ],
   "source": [
    "df_binary_MCC5 = load_feature_data(\n",
    "    features_path=targetFolderMCC5,\n",
    "    include_augmentations=False,      # Only 'original' data\n",
    "    include_speed_torque=False,       # Drop operating conditions\n",
    "    binary_classification=True,       # 'healthy' vs 'damaged'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb35e28-7098-45a1-bb31-899fd8610880",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_binary_HBK, df_binary_SIZA, df_binary_MCC5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d994ee23-ed86-4e93-b379-c145716083cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "normalized_df = normalizeDataframe(combined_df, normalization_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d0ded1-6f65-4a37-bb3c-5a59f1d1964b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df_training_normalized, features_df_testing_normalized = train_test_split(\n",
    "    normalized_df, \n",
    "    test_size=0.2,    # e.g., 20% for testing\n",
    "    random_state=42   # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd27e3ca-e055-4837-9084-3b94820aec39",
   "metadata": {},
   "source": [
    "# Experiment Setup (ML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3aea3-e600-4a35-92b7-ea5d9981ebe5",
   "metadata": {},
   "source": [
    "## Setup Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b4ff813-0eb2-45b8-a876-ec6929d1b040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5b5f9_row9_col1, #T_5b5f9_row16_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5b5f9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5b5f9_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_5b5f9_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5b5f9_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_5b5f9_row0_col1\" class=\"data row0 col1\" >1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5b5f9_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_5b5f9_row1_col1\" class=\"data row1 col1\" >Label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5b5f9_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_5b5f9_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5b5f9_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_5b5f9_row3_col1\" class=\"data row3 col1\" >damaged: 0, healthy: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5b5f9_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_5b5f9_row4_col1\" class=\"data row4 col1\" >(246359, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5b5f9_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_5b5f9_row5_col1\" class=\"data row5 col1\" >(246359, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5b5f9_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_5b5f9_row6_col1\" class=\"data row6 col1\" >(172451, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5b5f9_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_5b5f9_row7_col1\" class=\"data row7 col1\" >(73908, 28)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5b5f9_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_5b5f9_row8_col1\" class=\"data row8 col1\" >27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5b5f9_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_5b5f9_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5b5f9_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_5b5f9_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5b5f9_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_5b5f9_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_5b5f9_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_5b5f9_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_5b5f9_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_5b5f9_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_5b5f9_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_5b5f9_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_5b5f9_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_5b5f9_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_5b5f9_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_5b5f9_row16_col1\" class=\"data row16 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_5b5f9_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_5b5f9_row17_col1\" class=\"data row17 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_5b5f9_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_5b5f9_row18_col1\" class=\"data row18 col1\" >Best_Hyperparameters_z_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5b5f9_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_5b5f9_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_5b5f9_row19_col1\" class=\"data row19 col1\" >e833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27107fd5120>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "experiment = setup(features_df_training_normalized, target='Label', log_experiment = True, experiment_name = experiment_name, use_gpu = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d6300a-a54c-480c-8735-026fdbb0fd45",
   "metadata": {},
   "source": [
    "## Add aditional metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdb3d97b-cb84-42ed-b00b-ec01fcc7bfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                                          Log Loss\n",
       "Display Name                                                  Log Loss\n",
       "Score Function       <pycaret.internal.metrics.EncodedDecodedLabels...\n",
       "Scorer               make_scorer(log_loss, greater_is_better=False,...\n",
       "Target                                                      pred_proba\n",
       "Args                                                                {}\n",
       "Greater is Better                                                False\n",
       "Multiclass                                                        True\n",
       "Custom                                                            True\n",
       "Name: log_loss, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary classification metrics\n",
    "add_metric('balanced_acc', 'Balance Acc', balanced_accuracy_score, target='pred', greater_is_better=True)\n",
    "add_metric('hamming_loss', 'Hamming Loss', hamming_loss, target='pred', greater_is_better=False)\n",
    "add_metric('jaccard_score', 'Jaccard Score', jaccard_score, target='pred', greater_is_better=True)\n",
    "add_metric('log_loss', 'Log Loss', log_loss, target='pred_proba', greater_is_better=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe742ef7-ec02-4e73-b2a5-f2b36eee0066",
   "metadata": {},
   "source": [
    "# Macro\n",
    "add_metric('precision_macro', 'Precision Macro', \n",
    "           lambda y, y_pred: precision_score(y, y_pred, average='macro'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "add_metric('recall_macro', 'Recall Macro', \n",
    "           lambda y, y_pred: recall_score(y, y_pred, average='macro'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "add_metric('f1_macro', 'F1 Macro', \n",
    "           lambda y, y_pred: f1_score(y, y_pred, average='macro'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "# Micro\n",
    "add_metric('precision_micro', 'Precision Micro', \n",
    "           lambda y, y_pred: precision_score(y, y_pred, average='micro'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "add_metric('recall_micro', 'Recall Micro', \n",
    "           lambda y, y_pred: recall_score(y, y_pred, average='micro'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "add_metric('f1_micro', 'F1 Micro', \n",
    "           lambda y, y_pred: f1_score(y, y_pred, average='micro'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "# Weighted\n",
    "add_metric('precision_weighted', 'Precision Weighted', \n",
    "           lambda y, y_pred: precision_score(y, y_pred, average='weighted'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "add_metric('recall_weighted', 'Recall Weighted', \n",
    "           lambda y, y_pred: recall_score(y, y_pred, average='weighted'), \n",
    "           greater_is_better=True)\n",
    "\n",
    "add_metric('f1_weighted', 'F1 Weighted', \n",
    "           lambda y, y_pred: f1_score(y, y_pred, average='weighted'), \n",
    "           greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9faa1a3-cf7b-46ea-84b4-6b15167e1e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Display Name</th>\n",
       "      <th>Score Function</th>\n",
       "      <th>Scorer</th>\n",
       "      <th>Target</th>\n",
       "      <th>Args</th>\n",
       "      <th>Greater is Better</th>\n",
       "      <th>Multiclass</th>\n",
       "      <th>Custom</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>&lt;function accuracy_score at 0x000002716C87BA30&gt;</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>pred</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>AUC</td>\n",
       "      <td>AUC</td>\n",
       "      <td>&lt;pycaret.internal.metrics.BinaryMulticlassScor...</td>\n",
       "      <td>make_scorer(roc_auc_score, response_method=('d...</td>\n",
       "      <td>pred_proba</td>\n",
       "      <td>{'average': 'weighted', 'multi_class': 'ovr'}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>Recall</td>\n",
       "      <td>Recall</td>\n",
       "      <td>&lt;pycaret.internal.metrics.BinaryMulticlassScor...</td>\n",
       "      <td>make_scorer(recall_score, response_method='pre...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{'average': 'weighted'}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>Precision</td>\n",
       "      <td>Prec.</td>\n",
       "      <td>&lt;pycaret.internal.metrics.BinaryMulticlassScor...</td>\n",
       "      <td>make_scorer(precision_score, response_method='...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{'average': 'weighted'}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>F1</td>\n",
       "      <td>F1</td>\n",
       "      <td>&lt;pycaret.internal.metrics.BinaryMulticlassScor...</td>\n",
       "      <td>make_scorer(f1_score, response_method='predict...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{'average': 'weighted'}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kappa</th>\n",
       "      <td>Kappa</td>\n",
       "      <td>Kappa</td>\n",
       "      <td>&lt;function cohen_kappa_score at 0x000002716C87B...</td>\n",
       "      <td>make_scorer(cohen_kappa_score, response_method...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>MCC</td>\n",
       "      <td>MCC</td>\n",
       "      <td>&lt;function matthews_corrcoef at 0x000002716C8E0...</td>\n",
       "      <td>make_scorer(matthews_corrcoef, response_method...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balanced_acc</th>\n",
       "      <td>Balance Acc</td>\n",
       "      <td>Balance Acc</td>\n",
       "      <td>&lt;pycaret.internal.metrics.EncodedDecodedLabels...</td>\n",
       "      <td>make_scorer(balanced_accuracy_score, response_...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>Hamming Loss</td>\n",
       "      <td>Hamming Loss</td>\n",
       "      <td>&lt;pycaret.internal.metrics.EncodedDecodedLabels...</td>\n",
       "      <td>make_scorer(hamming_loss, greater_is_better=Fa...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard_score</th>\n",
       "      <td>Jaccard Score</td>\n",
       "      <td>Jaccard Score</td>\n",
       "      <td>&lt;pycaret.internal.metrics.EncodedDecodedLabels...</td>\n",
       "      <td>make_scorer(jaccard_score, response_method='pr...</td>\n",
       "      <td>pred</td>\n",
       "      <td>{}</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_loss</th>\n",
       "      <td>Log Loss</td>\n",
       "      <td>Log Loss</td>\n",
       "      <td>&lt;pycaret.internal.metrics.EncodedDecodedLabels...</td>\n",
       "      <td>make_scorer(log_loss, greater_is_better=False,...</td>\n",
       "      <td>pred_proba</td>\n",
       "      <td>{}</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name   Display Name  \\\n",
       "ID                                            \n",
       "acc                 Accuracy       Accuracy   \n",
       "auc                      AUC            AUC   \n",
       "recall                Recall         Recall   \n",
       "precision          Precision          Prec.   \n",
       "f1                        F1             F1   \n",
       "kappa                  Kappa          Kappa   \n",
       "mcc                      MCC            MCC   \n",
       "balanced_acc     Balance Acc    Balance Acc   \n",
       "hamming_loss    Hamming Loss   Hamming Loss   \n",
       "jaccard_score  Jaccard Score  Jaccard Score   \n",
       "log_loss            Log Loss       Log Loss   \n",
       "\n",
       "                                                  Score Function  \\\n",
       "ID                                                                 \n",
       "acc              <function accuracy_score at 0x000002716C87BA30>   \n",
       "auc            <pycaret.internal.metrics.BinaryMulticlassScor...   \n",
       "recall         <pycaret.internal.metrics.BinaryMulticlassScor...   \n",
       "precision      <pycaret.internal.metrics.BinaryMulticlassScor...   \n",
       "f1             <pycaret.internal.metrics.BinaryMulticlassScor...   \n",
       "kappa          <function cohen_kappa_score at 0x000002716C87B...   \n",
       "mcc            <function matthews_corrcoef at 0x000002716C8E0...   \n",
       "balanced_acc   <pycaret.internal.metrics.EncodedDecodedLabels...   \n",
       "hamming_loss   <pycaret.internal.metrics.EncodedDecodedLabels...   \n",
       "jaccard_score  <pycaret.internal.metrics.EncodedDecodedLabels...   \n",
       "log_loss       <pycaret.internal.metrics.EncodedDecodedLabels...   \n",
       "\n",
       "                                                          Scorer      Target  \\\n",
       "ID                                                                             \n",
       "acc                                                     accuracy        pred   \n",
       "auc            make_scorer(roc_auc_score, response_method=('d...  pred_proba   \n",
       "recall         make_scorer(recall_score, response_method='pre...        pred   \n",
       "precision      make_scorer(precision_score, response_method='...        pred   \n",
       "f1             make_scorer(f1_score, response_method='predict...        pred   \n",
       "kappa          make_scorer(cohen_kappa_score, response_method...        pred   \n",
       "mcc            make_scorer(matthews_corrcoef, response_method...        pred   \n",
       "balanced_acc   make_scorer(balanced_accuracy_score, response_...        pred   \n",
       "hamming_loss   make_scorer(hamming_loss, greater_is_better=Fa...        pred   \n",
       "jaccard_score  make_scorer(jaccard_score, response_method='pr...        pred   \n",
       "log_loss       make_scorer(log_loss, greater_is_better=False,...  pred_proba   \n",
       "\n",
       "                                                        Args  \\\n",
       "ID                                                             \n",
       "acc                                                       {}   \n",
       "auc            {'average': 'weighted', 'multi_class': 'ovr'}   \n",
       "recall                               {'average': 'weighted'}   \n",
       "precision                            {'average': 'weighted'}   \n",
       "f1                                   {'average': 'weighted'}   \n",
       "kappa                                                     {}   \n",
       "mcc                                                       {}   \n",
       "balanced_acc                                              {}   \n",
       "hamming_loss                                              {}   \n",
       "jaccard_score                                             {}   \n",
       "log_loss                                                  {}   \n",
       "\n",
       "               Greater is Better  Multiclass  Custom  \n",
       "ID                                                    \n",
       "acc                         True        True   False  \n",
       "auc                         True        True   False  \n",
       "recall                      True        True   False  \n",
       "precision                   True        True   False  \n",
       "f1                          True        True   False  \n",
       "kappa                       True        True   False  \n",
       "mcc                         True        True   False  \n",
       "balanced_acc                True        True    True  \n",
       "hamming_loss               False        True    True  \n",
       "jaccard_score               True        True    True  \n",
       "log_loss                   False        True    True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics = get_metrics()\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18a5e119-0bbb-4ee9-8da6-e10a63eaaa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations_tuning = 10\n",
    "optimized_metric = 'F1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de3f05-6198-4ae2-adba-d294aee48b08",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca0ce27b-40e1-468f-945e-ee949316a92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_0cadc_row10_col0, #T_0cadc_row10_col1, #T_0cadc_row10_col2, #T_0cadc_row10_col3, #T_0cadc_row10_col4, #T_0cadc_row10_col5, #T_0cadc_row10_col6, #T_0cadc_row10_col7, #T_0cadc_row10_col8, #T_0cadc_row10_col9, #T_0cadc_row10_col10 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_0cadc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_0cadc_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_0cadc_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_0cadc_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_0cadc_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_0cadc_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_0cadc_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_0cadc_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_0cadc_level0_col7\" class=\"col_heading level0 col7\" >Balance Acc</th>\n",
       "      <th id=\"T_0cadc_level0_col8\" class=\"col_heading level0 col8\" >Hamming Loss</th>\n",
       "      <th id=\"T_0cadc_level0_col9\" class=\"col_heading level0 col9\" >Jaccard Score</th>\n",
       "      <th id=\"T_0cadc_level0_col10\" class=\"col_heading level0 col10\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_0cadc_row0_col0\" class=\"data row0 col0\" >0.9498</td>\n",
       "      <td id=\"T_0cadc_row0_col1\" class=\"data row0 col1\" >0.9859</td>\n",
       "      <td id=\"T_0cadc_row0_col2\" class=\"data row0 col2\" >0.9498</td>\n",
       "      <td id=\"T_0cadc_row0_col3\" class=\"data row0 col3\" >0.9511</td>\n",
       "      <td id=\"T_0cadc_row0_col4\" class=\"data row0 col4\" >0.9480</td>\n",
       "      <td id=\"T_0cadc_row0_col5\" class=\"data row0 col5\" >0.8464</td>\n",
       "      <td id=\"T_0cadc_row0_col6\" class=\"data row0 col6\" >0.8531</td>\n",
       "      <td id=\"T_0cadc_row0_col7\" class=\"data row0 col7\" >0.8959</td>\n",
       "      <td id=\"T_0cadc_row0_col8\" class=\"data row0 col8\" >0.0502</td>\n",
       "      <td id=\"T_0cadc_row0_col9\" class=\"data row0 col9\" >0.7817</td>\n",
       "      <td id=\"T_0cadc_row0_col10\" class=\"data row0 col10\" >0.1186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_0cadc_row1_col0\" class=\"data row1 col0\" >0.9546</td>\n",
       "      <td id=\"T_0cadc_row1_col1\" class=\"data row1 col1\" >0.9867</td>\n",
       "      <td id=\"T_0cadc_row1_col2\" class=\"data row1 col2\" >0.9546</td>\n",
       "      <td id=\"T_0cadc_row1_col3\" class=\"data row1 col3\" >0.9554</td>\n",
       "      <td id=\"T_0cadc_row1_col4\" class=\"data row1 col4\" >0.9532</td>\n",
       "      <td id=\"T_0cadc_row1_col5\" class=\"data row1 col5\" >0.8622</td>\n",
       "      <td id=\"T_0cadc_row1_col6\" class=\"data row1 col6\" >0.8672</td>\n",
       "      <td id=\"T_0cadc_row1_col7\" class=\"data row1 col7\" >0.9072</td>\n",
       "      <td id=\"T_0cadc_row1_col8\" class=\"data row1 col8\" >0.0454</td>\n",
       "      <td id=\"T_0cadc_row1_col9\" class=\"data row1 col9\" >0.8028</td>\n",
       "      <td id=\"T_0cadc_row1_col10\" class=\"data row1 col10\" >0.1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_0cadc_row2_col0\" class=\"data row2 col0\" >0.9511</td>\n",
       "      <td id=\"T_0cadc_row2_col1\" class=\"data row2 col1\" >0.9866</td>\n",
       "      <td id=\"T_0cadc_row2_col2\" class=\"data row2 col2\" >0.9511</td>\n",
       "      <td id=\"T_0cadc_row2_col3\" class=\"data row2 col3\" >0.9523</td>\n",
       "      <td id=\"T_0cadc_row2_col4\" class=\"data row2 col4\" >0.9493</td>\n",
       "      <td id=\"T_0cadc_row2_col5\" class=\"data row2 col5\" >0.8503</td>\n",
       "      <td id=\"T_0cadc_row2_col6\" class=\"data row2 col6\" >0.8568</td>\n",
       "      <td id=\"T_0cadc_row2_col7\" class=\"data row2 col7\" >0.8983</td>\n",
       "      <td id=\"T_0cadc_row2_col8\" class=\"data row2 col8\" >0.0489</td>\n",
       "      <td id=\"T_0cadc_row2_col9\" class=\"data row2 col9\" >0.7868</td>\n",
       "      <td id=\"T_0cadc_row2_col10\" class=\"data row2 col10\" >0.1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_0cadc_row3_col0\" class=\"data row3 col0\" >0.9542</td>\n",
       "      <td id=\"T_0cadc_row3_col1\" class=\"data row3 col1\" >0.9879</td>\n",
       "      <td id=\"T_0cadc_row3_col2\" class=\"data row3 col2\" >0.9542</td>\n",
       "      <td id=\"T_0cadc_row3_col3\" class=\"data row3 col3\" >0.9552</td>\n",
       "      <td id=\"T_0cadc_row3_col4\" class=\"data row3 col4\" >0.9528</td>\n",
       "      <td id=\"T_0cadc_row3_col5\" class=\"data row3 col5\" >0.8609</td>\n",
       "      <td id=\"T_0cadc_row3_col6\" class=\"data row3 col6\" >0.8662</td>\n",
       "      <td id=\"T_0cadc_row3_col7\" class=\"data row3 col7\" >0.9058</td>\n",
       "      <td id=\"T_0cadc_row3_col8\" class=\"data row3 col8\" >0.0458</td>\n",
       "      <td id=\"T_0cadc_row3_col9\" class=\"data row3 col9\" >0.8009</td>\n",
       "      <td id=\"T_0cadc_row3_col10\" class=\"data row3 col10\" >0.1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_0cadc_row4_col0\" class=\"data row4 col0\" >0.9538</td>\n",
       "      <td id=\"T_0cadc_row4_col1\" class=\"data row4 col1\" >0.9867</td>\n",
       "      <td id=\"T_0cadc_row4_col2\" class=\"data row4 col2\" >0.9538</td>\n",
       "      <td id=\"T_0cadc_row4_col3\" class=\"data row4 col3\" >0.9548</td>\n",
       "      <td id=\"T_0cadc_row4_col4\" class=\"data row4 col4\" >0.9523</td>\n",
       "      <td id=\"T_0cadc_row4_col5\" class=\"data row4 col5\" >0.8596</td>\n",
       "      <td id=\"T_0cadc_row4_col6\" class=\"data row4 col6\" >0.8650</td>\n",
       "      <td id=\"T_0cadc_row4_col7\" class=\"data row4 col7\" >0.9049</td>\n",
       "      <td id=\"T_0cadc_row4_col8\" class=\"data row4 col8\" >0.0462</td>\n",
       "      <td id=\"T_0cadc_row4_col9\" class=\"data row4 col9\" >0.7991</td>\n",
       "      <td id=\"T_0cadc_row4_col10\" class=\"data row4 col10\" >0.1126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_0cadc_row5_col0\" class=\"data row5 col0\" >0.9508</td>\n",
       "      <td id=\"T_0cadc_row5_col1\" class=\"data row5 col1\" >0.9859</td>\n",
       "      <td id=\"T_0cadc_row5_col2\" class=\"data row5 col2\" >0.9508</td>\n",
       "      <td id=\"T_0cadc_row5_col3\" class=\"data row5 col3\" >0.9519</td>\n",
       "      <td id=\"T_0cadc_row5_col4\" class=\"data row5 col4\" >0.9490</td>\n",
       "      <td id=\"T_0cadc_row5_col5\" class=\"data row5 col5\" >0.8495</td>\n",
       "      <td id=\"T_0cadc_row5_col6\" class=\"data row5 col6\" >0.8558</td>\n",
       "      <td id=\"T_0cadc_row5_col7\" class=\"data row5 col7\" >0.8984</td>\n",
       "      <td id=\"T_0cadc_row5_col8\" class=\"data row5 col8\" >0.0492</td>\n",
       "      <td id=\"T_0cadc_row5_col9\" class=\"data row5 col9\" >0.7860</td>\n",
       "      <td id=\"T_0cadc_row5_col10\" class=\"data row5 col10\" >0.1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_0cadc_row6_col0\" class=\"data row6 col0\" >0.9517</td>\n",
       "      <td id=\"T_0cadc_row6_col1\" class=\"data row6 col1\" >0.9865</td>\n",
       "      <td id=\"T_0cadc_row6_col2\" class=\"data row6 col2\" >0.9517</td>\n",
       "      <td id=\"T_0cadc_row6_col3\" class=\"data row6 col3\" >0.9526</td>\n",
       "      <td id=\"T_0cadc_row6_col4\" class=\"data row6 col4\" >0.9501</td>\n",
       "      <td id=\"T_0cadc_row6_col5\" class=\"data row6 col5\" >0.8528</td>\n",
       "      <td id=\"T_0cadc_row6_col6\" class=\"data row6 col6\" >0.8585</td>\n",
       "      <td id=\"T_0cadc_row6_col7\" class=\"data row6 col7\" >0.9010</td>\n",
       "      <td id=\"T_0cadc_row6_col8\" class=\"data row6 col8\" >0.0483</td>\n",
       "      <td id=\"T_0cadc_row6_col9\" class=\"data row6 col9\" >0.7903</td>\n",
       "      <td id=\"T_0cadc_row6_col10\" class=\"data row6 col10\" >0.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_0cadc_row7_col0\" class=\"data row7 col0\" >0.9539</td>\n",
       "      <td id=\"T_0cadc_row7_col1\" class=\"data row7 col1\" >0.9874</td>\n",
       "      <td id=\"T_0cadc_row7_col2\" class=\"data row7 col2\" >0.9539</td>\n",
       "      <td id=\"T_0cadc_row7_col3\" class=\"data row7 col3\" >0.9548</td>\n",
       "      <td id=\"T_0cadc_row7_col4\" class=\"data row7 col4\" >0.9524</td>\n",
       "      <td id=\"T_0cadc_row7_col5\" class=\"data row7 col5\" >0.8598</td>\n",
       "      <td id=\"T_0cadc_row7_col6\" class=\"data row7 col6\" >0.8651</td>\n",
       "      <td id=\"T_0cadc_row7_col7\" class=\"data row7 col7\" >0.9053</td>\n",
       "      <td id=\"T_0cadc_row7_col8\" class=\"data row7 col8\" >0.0461</td>\n",
       "      <td id=\"T_0cadc_row7_col9\" class=\"data row7 col9\" >0.7995</td>\n",
       "      <td id=\"T_0cadc_row7_col10\" class=\"data row7 col10\" >0.1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_0cadc_row8_col0\" class=\"data row8 col0\" >0.9519</td>\n",
       "      <td id=\"T_0cadc_row8_col1\" class=\"data row8 col1\" >0.9856</td>\n",
       "      <td id=\"T_0cadc_row8_col2\" class=\"data row8 col2\" >0.9519</td>\n",
       "      <td id=\"T_0cadc_row8_col3\" class=\"data row8 col3\" >0.9527</td>\n",
       "      <td id=\"T_0cadc_row8_col4\" class=\"data row8 col4\" >0.9503</td>\n",
       "      <td id=\"T_0cadc_row8_col5\" class=\"data row8 col5\" >0.8534</td>\n",
       "      <td id=\"T_0cadc_row8_col6\" class=\"data row8 col6\" >0.8590</td>\n",
       "      <td id=\"T_0cadc_row8_col7\" class=\"data row8 col7\" >0.9017</td>\n",
       "      <td id=\"T_0cadc_row8_col8\" class=\"data row8 col8\" >0.0481</td>\n",
       "      <td id=\"T_0cadc_row8_col9\" class=\"data row8 col9\" >0.7912</td>\n",
       "      <td id=\"T_0cadc_row8_col10\" class=\"data row8 col10\" >0.1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_0cadc_row9_col0\" class=\"data row9 col0\" >0.9506</td>\n",
       "      <td id=\"T_0cadc_row9_col1\" class=\"data row9 col1\" >0.9865</td>\n",
       "      <td id=\"T_0cadc_row9_col2\" class=\"data row9 col2\" >0.9506</td>\n",
       "      <td id=\"T_0cadc_row9_col3\" class=\"data row9 col3\" >0.9518</td>\n",
       "      <td id=\"T_0cadc_row9_col4\" class=\"data row9 col4\" >0.9488</td>\n",
       "      <td id=\"T_0cadc_row9_col5\" class=\"data row9 col5\" >0.8489</td>\n",
       "      <td id=\"T_0cadc_row9_col6\" class=\"data row9 col6\" >0.8553</td>\n",
       "      <td id=\"T_0cadc_row9_col7\" class=\"data row9 col7\" >0.8977</td>\n",
       "      <td id=\"T_0cadc_row9_col8\" class=\"data row9 col8\" >0.0494</td>\n",
       "      <td id=\"T_0cadc_row9_col9\" class=\"data row9 col9\" >0.7850</td>\n",
       "      <td id=\"T_0cadc_row9_col10\" class=\"data row9 col10\" >0.1161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_0cadc_row10_col0\" class=\"data row10 col0\" >0.9522</td>\n",
       "      <td id=\"T_0cadc_row10_col1\" class=\"data row10 col1\" >0.9866</td>\n",
       "      <td id=\"T_0cadc_row10_col2\" class=\"data row10 col2\" >0.9522</td>\n",
       "      <td id=\"T_0cadc_row10_col3\" class=\"data row10 col3\" >0.9533</td>\n",
       "      <td id=\"T_0cadc_row10_col4\" class=\"data row10 col4\" >0.9506</td>\n",
       "      <td id=\"T_0cadc_row10_col5\" class=\"data row10 col5\" >0.8544</td>\n",
       "      <td id=\"T_0cadc_row10_col6\" class=\"data row10 col6\" >0.8602</td>\n",
       "      <td id=\"T_0cadc_row10_col7\" class=\"data row10 col7\" >0.9016</td>\n",
       "      <td id=\"T_0cadc_row10_col8\" class=\"data row10 col8\" >0.0478</td>\n",
       "      <td id=\"T_0cadc_row10_col9\" class=\"data row10 col9\" >0.7924</td>\n",
       "      <td id=\"T_0cadc_row10_col10\" class=\"data row10 col10\" >0.1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_0cadc_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_0cadc_row11_col0\" class=\"data row11 col0\" >0.0017</td>\n",
       "      <td id=\"T_0cadc_row11_col1\" class=\"data row11 col1\" >0.0006</td>\n",
       "      <td id=\"T_0cadc_row11_col2\" class=\"data row11 col2\" >0.0017</td>\n",
       "      <td id=\"T_0cadc_row11_col3\" class=\"data row11 col3\" >0.0015</td>\n",
       "      <td id=\"T_0cadc_row11_col4\" class=\"data row11 col4\" >0.0018</td>\n",
       "      <td id=\"T_0cadc_row11_col5\" class=\"data row11 col5\" >0.0055</td>\n",
       "      <td id=\"T_0cadc_row11_col6\" class=\"data row11 col6\" >0.0049</td>\n",
       "      <td id=\"T_0cadc_row11_col7\" class=\"data row11 col7\" >0.0038</td>\n",
       "      <td id=\"T_0cadc_row11_col8\" class=\"data row11 col8\" >0.0017</td>\n",
       "      <td id=\"T_0cadc_row11_col9\" class=\"data row11 col9\" >0.0072</td>\n",
       "      <td id=\"T_0cadc_row11_col10\" class=\"data row11 col10\" >0.0027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2710ce83eb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 11:36:24 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "lightgbm = create_model('lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9639f68f-46f5-4854-b520-3fc11e40f3ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_68177_row10_col0, #T_68177_row10_col1, #T_68177_row10_col2, #T_68177_row10_col3, #T_68177_row10_col4, #T_68177_row10_col5, #T_68177_row10_col6, #T_68177_row10_col7, #T_68177_row10_col8, #T_68177_row10_col9, #T_68177_row10_col10 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_68177\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_68177_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_68177_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_68177_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_68177_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_68177_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_68177_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_68177_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_68177_level0_col7\" class=\"col_heading level0 col7\" >Balance Acc</th>\n",
       "      <th id=\"T_68177_level0_col8\" class=\"col_heading level0 col8\" >Hamming Loss</th>\n",
       "      <th id=\"T_68177_level0_col9\" class=\"col_heading level0 col9\" >Jaccard Score</th>\n",
       "      <th id=\"T_68177_level0_col10\" class=\"col_heading level0 col10\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_68177_row0_col0\" class=\"data row0 col0\" >0.9737</td>\n",
       "      <td id=\"T_68177_row0_col1\" class=\"data row0 col1\" >0.9929</td>\n",
       "      <td id=\"T_68177_row0_col2\" class=\"data row0 col2\" >0.9737</td>\n",
       "      <td id=\"T_68177_row0_col3\" class=\"data row0 col3\" >0.9736</td>\n",
       "      <td id=\"T_68177_row0_col4\" class=\"data row0 col4\" >0.9734</td>\n",
       "      <td id=\"T_68177_row0_col5\" class=\"data row0 col5\" >0.9231</td>\n",
       "      <td id=\"T_68177_row0_col6\" class=\"data row0 col6\" >0.9237</td>\n",
       "      <td id=\"T_68177_row0_col7\" class=\"data row0 col7\" >0.9531</td>\n",
       "      <td id=\"T_68177_row0_col8\" class=\"data row0 col8\" >0.0263</td>\n",
       "      <td id=\"T_68177_row0_col9\" class=\"data row0 col9\" >0.8868</td>\n",
       "      <td id=\"T_68177_row0_col10\" class=\"data row0 col10\" >0.0804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_68177_row1_col0\" class=\"data row1 col0\" >0.9775</td>\n",
       "      <td id=\"T_68177_row1_col1\" class=\"data row1 col1\" >0.9936</td>\n",
       "      <td id=\"T_68177_row1_col2\" class=\"data row1 col2\" >0.9775</td>\n",
       "      <td id=\"T_68177_row1_col3\" class=\"data row1 col3\" >0.9774</td>\n",
       "      <td id=\"T_68177_row1_col4\" class=\"data row1 col4\" >0.9773</td>\n",
       "      <td id=\"T_68177_row1_col5\" class=\"data row1 col5\" >0.9345</td>\n",
       "      <td id=\"T_68177_row1_col6\" class=\"data row1 col6\" >0.9349</td>\n",
       "      <td id=\"T_68177_row1_col7\" class=\"data row1 col7\" >0.9598</td>\n",
       "      <td id=\"T_68177_row1_col8\" class=\"data row1 col8\" >0.0225</td>\n",
       "      <td id=\"T_68177_row1_col9\" class=\"data row1 col9\" >0.9028</td>\n",
       "      <td id=\"T_68177_row1_col10\" class=\"data row1 col10\" >0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_68177_row2_col0\" class=\"data row2 col0\" >0.9739</td>\n",
       "      <td id=\"T_68177_row2_col1\" class=\"data row2 col1\" >0.9933</td>\n",
       "      <td id=\"T_68177_row2_col2\" class=\"data row2 col2\" >0.9739</td>\n",
       "      <td id=\"T_68177_row2_col3\" class=\"data row2 col3\" >0.9738</td>\n",
       "      <td id=\"T_68177_row2_col4\" class=\"data row2 col4\" >0.9737</td>\n",
       "      <td id=\"T_68177_row2_col5\" class=\"data row2 col5\" >0.9238</td>\n",
       "      <td id=\"T_68177_row2_col6\" class=\"data row2 col6\" >0.9244</td>\n",
       "      <td id=\"T_68177_row2_col7\" class=\"data row2 col7\" >0.9535</td>\n",
       "      <td id=\"T_68177_row2_col8\" class=\"data row2 col8\" >0.0261</td>\n",
       "      <td id=\"T_68177_row2_col9\" class=\"data row2 col9\" >0.8877</td>\n",
       "      <td id=\"T_68177_row2_col10\" class=\"data row2 col10\" >0.0791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_68177_row3_col0\" class=\"data row3 col0\" >0.9761</td>\n",
       "      <td id=\"T_68177_row3_col1\" class=\"data row3 col1\" >0.9938</td>\n",
       "      <td id=\"T_68177_row3_col2\" class=\"data row3 col2\" >0.9761</td>\n",
       "      <td id=\"T_68177_row3_col3\" class=\"data row3 col3\" >0.9760</td>\n",
       "      <td id=\"T_68177_row3_col4\" class=\"data row3 col4\" >0.9759</td>\n",
       "      <td id=\"T_68177_row3_col5\" class=\"data row3 col5\" >0.9305</td>\n",
       "      <td id=\"T_68177_row3_col6\" class=\"data row3 col6\" >0.9308</td>\n",
       "      <td id=\"T_68177_row3_col7\" class=\"data row3 col7\" >0.9583</td>\n",
       "      <td id=\"T_68177_row3_col8\" class=\"data row3 col8\" >0.0239</td>\n",
       "      <td id=\"T_68177_row3_col9\" class=\"data row3 col9\" >0.8972</td>\n",
       "      <td id=\"T_68177_row3_col10\" class=\"data row3 col10\" >0.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_68177_row4_col0\" class=\"data row4 col0\" >0.9756</td>\n",
       "      <td id=\"T_68177_row4_col1\" class=\"data row4 col1\" >0.9936</td>\n",
       "      <td id=\"T_68177_row4_col2\" class=\"data row4 col2\" >0.9756</td>\n",
       "      <td id=\"T_68177_row4_col3\" class=\"data row4 col3\" >0.9755</td>\n",
       "      <td id=\"T_68177_row4_col4\" class=\"data row4 col4\" >0.9755</td>\n",
       "      <td id=\"T_68177_row4_col5\" class=\"data row4 col5\" >0.9291</td>\n",
       "      <td id=\"T_68177_row4_col6\" class=\"data row4 col6\" >0.9295</td>\n",
       "      <td id=\"T_68177_row4_col7\" class=\"data row4 col7\" >0.9577</td>\n",
       "      <td id=\"T_68177_row4_col8\" class=\"data row4 col8\" >0.0244</td>\n",
       "      <td id=\"T_68177_row4_col9\" class=\"data row4 col9\" >0.8953</td>\n",
       "      <td id=\"T_68177_row4_col10\" class=\"data row4 col10\" >0.0746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_68177_row5_col0\" class=\"data row5 col0\" >0.9734</td>\n",
       "      <td id=\"T_68177_row5_col1\" class=\"data row5 col1\" >0.9931</td>\n",
       "      <td id=\"T_68177_row5_col2\" class=\"data row5 col2\" >0.9734</td>\n",
       "      <td id=\"T_68177_row5_col3\" class=\"data row5 col3\" >0.9733</td>\n",
       "      <td id=\"T_68177_row5_col4\" class=\"data row5 col4\" >0.9732</td>\n",
       "      <td id=\"T_68177_row5_col5\" class=\"data row5 col5\" >0.9224</td>\n",
       "      <td id=\"T_68177_row5_col6\" class=\"data row5 col6\" >0.9230</td>\n",
       "      <td id=\"T_68177_row5_col7\" class=\"data row5 col7\" >0.9522</td>\n",
       "      <td id=\"T_68177_row5_col8\" class=\"data row5 col8\" >0.0266</td>\n",
       "      <td id=\"T_68177_row5_col9\" class=\"data row5 col9\" >0.8856</td>\n",
       "      <td id=\"T_68177_row5_col10\" class=\"data row5 col10\" >0.0810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_68177_row6_col0\" class=\"data row6 col0\" >0.9744</td>\n",
       "      <td id=\"T_68177_row6_col1\" class=\"data row6 col1\" >0.9927</td>\n",
       "      <td id=\"T_68177_row6_col2\" class=\"data row6 col2\" >0.9744</td>\n",
       "      <td id=\"T_68177_row6_col3\" class=\"data row6 col3\" >0.9742</td>\n",
       "      <td id=\"T_68177_row6_col4\" class=\"data row6 col4\" >0.9742</td>\n",
       "      <td id=\"T_68177_row6_col5\" class=\"data row6 col5\" >0.9253</td>\n",
       "      <td id=\"T_68177_row6_col6\" class=\"data row6 col6\" >0.9257</td>\n",
       "      <td id=\"T_68177_row6_col7\" class=\"data row6 col7\" >0.9553</td>\n",
       "      <td id=\"T_68177_row6_col8\" class=\"data row6 col8\" >0.0256</td>\n",
       "      <td id=\"T_68177_row6_col9\" class=\"data row6 col9\" >0.8899</td>\n",
       "      <td id=\"T_68177_row6_col10\" class=\"data row6 col10\" >0.0831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_68177_row7_col0\" class=\"data row7 col0\" >0.9766</td>\n",
       "      <td id=\"T_68177_row7_col1\" class=\"data row7 col1\" >0.9934</td>\n",
       "      <td id=\"T_68177_row7_col2\" class=\"data row7 col2\" >0.9766</td>\n",
       "      <td id=\"T_68177_row7_col3\" class=\"data row7 col3\" >0.9766</td>\n",
       "      <td id=\"T_68177_row7_col4\" class=\"data row7 col4\" >0.9764</td>\n",
       "      <td id=\"T_68177_row7_col5\" class=\"data row7 col5\" >0.9318</td>\n",
       "      <td id=\"T_68177_row7_col6\" class=\"data row7 col6\" >0.9323</td>\n",
       "      <td id=\"T_68177_row7_col7\" class=\"data row7 col7\" >0.9577</td>\n",
       "      <td id=\"T_68177_row7_col8\" class=\"data row7 col8\" >0.0234</td>\n",
       "      <td id=\"T_68177_row7_col9\" class=\"data row7 col9\" >0.8989</td>\n",
       "      <td id=\"T_68177_row7_col10\" class=\"data row7 col10\" >0.0765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_68177_row8_col0\" class=\"data row8 col0\" >0.9731</td>\n",
       "      <td id=\"T_68177_row8_col1\" class=\"data row8 col1\" >0.9926</td>\n",
       "      <td id=\"T_68177_row8_col2\" class=\"data row8 col2\" >0.9731</td>\n",
       "      <td id=\"T_68177_row8_col3\" class=\"data row8 col3\" >0.9729</td>\n",
       "      <td id=\"T_68177_row8_col4\" class=\"data row8 col4\" >0.9729</td>\n",
       "      <td id=\"T_68177_row8_col5\" class=\"data row8 col5\" >0.9216</td>\n",
       "      <td id=\"T_68177_row8_col6\" class=\"data row8 col6\" >0.9220</td>\n",
       "      <td id=\"T_68177_row8_col7\" class=\"data row8 col7\" >0.9536</td>\n",
       "      <td id=\"T_68177_row8_col8\" class=\"data row8 col8\" >0.0269</td>\n",
       "      <td id=\"T_68177_row8_col9\" class=\"data row8 col9\" >0.8848</td>\n",
       "      <td id=\"T_68177_row8_col10\" class=\"data row8 col10\" >0.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_68177_row9_col0\" class=\"data row9 col0\" >0.9742</td>\n",
       "      <td id=\"T_68177_row9_col1\" class=\"data row9 col1\" >0.9931</td>\n",
       "      <td id=\"T_68177_row9_col2\" class=\"data row9 col2\" >0.9742</td>\n",
       "      <td id=\"T_68177_row9_col3\" class=\"data row9 col3\" >0.9741</td>\n",
       "      <td id=\"T_68177_row9_col4\" class=\"data row9 col4\" >0.9739</td>\n",
       "      <td id=\"T_68177_row9_col5\" class=\"data row9 col5\" >0.9246</td>\n",
       "      <td id=\"T_68177_row9_col6\" class=\"data row9 col6\" >0.9252</td>\n",
       "      <td id=\"T_68177_row9_col7\" class=\"data row9 col7\" >0.9538</td>\n",
       "      <td id=\"T_68177_row9_col8\" class=\"data row9 col8\" >0.0258</td>\n",
       "      <td id=\"T_68177_row9_col9\" class=\"data row9 col9\" >0.8889</td>\n",
       "      <td id=\"T_68177_row9_col10\" class=\"data row9 col10\" >0.0807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_68177_row10_col0\" class=\"data row10 col0\" >0.9749</td>\n",
       "      <td id=\"T_68177_row10_col1\" class=\"data row10 col1\" >0.9932</td>\n",
       "      <td id=\"T_68177_row10_col2\" class=\"data row10 col2\" >0.9749</td>\n",
       "      <td id=\"T_68177_row10_col3\" class=\"data row10 col3\" >0.9747</td>\n",
       "      <td id=\"T_68177_row10_col4\" class=\"data row10 col4\" >0.9746</td>\n",
       "      <td id=\"T_68177_row10_col5\" class=\"data row10 col5\" >0.9267</td>\n",
       "      <td id=\"T_68177_row10_col6\" class=\"data row10 col6\" >0.9271</td>\n",
       "      <td id=\"T_68177_row10_col7\" class=\"data row10 col7\" >0.9555</td>\n",
       "      <td id=\"T_68177_row10_col8\" class=\"data row10 col8\" >0.0251</td>\n",
       "      <td id=\"T_68177_row10_col9\" class=\"data row10 col9\" >0.8918</td>\n",
       "      <td id=\"T_68177_row10_col10\" class=\"data row10 col10\" >0.0785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_68177_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_68177_row11_col0\" class=\"data row11 col0\" >0.0014</td>\n",
       "      <td id=\"T_68177_row11_col1\" class=\"data row11 col1\" >0.0004</td>\n",
       "      <td id=\"T_68177_row11_col2\" class=\"data row11 col2\" >0.0014</td>\n",
       "      <td id=\"T_68177_row11_col3\" class=\"data row11 col3\" >0.0014</td>\n",
       "      <td id=\"T_68177_row11_col4\" class=\"data row11 col4\" >0.0015</td>\n",
       "      <td id=\"T_68177_row11_col5\" class=\"data row11 col5\" >0.0042</td>\n",
       "      <td id=\"T_68177_row11_col6\" class=\"data row11 col6\" >0.0042</td>\n",
       "      <td id=\"T_68177_row11_col7\" class=\"data row11 col7\" >0.0025</td>\n",
       "      <td id=\"T_68177_row11_col8\" class=\"data row11 col8\" >0.0014</td>\n",
       "      <td id=\"T_68177_row11_col9\" class=\"data row11 col9\" >0.0059</td>\n",
       "      <td id=\"T_68177_row11_col10\" class=\"data row11 col10\" >0.0036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2710cee69b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007333 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007673 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007215 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007648 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007895 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007612 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007604 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007309 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007323 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007989 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007283 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008054 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007639 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007650 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007400 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007455 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007593 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007658 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007673 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007805 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007296 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007758 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007678 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007435 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007727 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007650 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.011738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007647 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008178 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007721 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007891 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007527 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007356 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007556 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007231 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007697 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007615 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007597 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007601 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.008405 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007723 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007212 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007725 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007648 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007410 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008840 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007348 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007821 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.012540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007793 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009165 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007545 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007303 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007688 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007687 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.008018 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007534 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008087 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007695 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007381 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007557 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007632 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007559 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007365 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007464 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007096 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007561 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007752 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007622 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009275 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007710 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007625 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007880 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007428 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007600 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007552 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007221 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007781 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007625 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007812 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007574 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007483 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007461 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007612 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007369 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009188 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007690 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007793 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007271 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007686 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007383 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008101 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007770 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.009269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.008307 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.008132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007631 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008274 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007616 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008135 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007598 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007523 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007677 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007622 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007856 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007723 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007946 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007590 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007223 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007670 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007776 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007730 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007724 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008087 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007199 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007711 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007626 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007778 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007787 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008266 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007680 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007267 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007718 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007918 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009634 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.008374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008160 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007798 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007909 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007917 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.008074 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007779 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007702 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007549 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007758 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007904 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008616 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008988 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.011514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008554 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008150 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.014253 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007650 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.014443 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.010817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007703 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007305 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007602 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007759 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.008043 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007603 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.008062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007291 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008890 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.011035 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.013807 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008368 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.012160 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007708 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007762 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008639 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.009038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007561 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007803 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007760 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.013983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007842 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.008582 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007697 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007654 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007369 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007772 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007723 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007473 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007821 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.31 MB) transferred to GPU in 0.007718 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007621 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.015437 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007602 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007694 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007721 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007583 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007805 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007513 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.33 MB) transferred to GPU in 0.007795 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007703 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.32 MB) transferred to GPU in 0.007574 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9154130135317432, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9154130135317432\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8015013984914804, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8015013984914804\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009337 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006519 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006075 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006330 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006079 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006041 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006494 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005811 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006239 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.012822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006050 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005944 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006092 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005948 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005699 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006276 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005745 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005965 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005904 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006135 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.006147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006074 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005868 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005935 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006256 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006791 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006207 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005991 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.013420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006054 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006014 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013137 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.012784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006347 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.013861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006017 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006002 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.008313 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012182 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012786 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.011380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006315 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006171 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006027 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.016162 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006182 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006124 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005992 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006128 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006595 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006186 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005773 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008707 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006026 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005937 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005811 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006214 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006476 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010818 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006139 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007564 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005969 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.005971 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006228 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006385 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.009532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012991 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005885 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006067 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006348 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.007336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005950 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.013948 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006026 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006572 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.012675 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011453 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006276 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005985 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006045 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006282 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.011556 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005793 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006464 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005993 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006141 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006117 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006156 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005968 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006362 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006378 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006133 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006498 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006124 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005879 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006217 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006057 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006208 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005987 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006129 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.006472 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006202 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005802 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005960 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005924 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005872 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006577 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006443 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006047 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006412 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006303 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006680 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006260 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005799 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.008129 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008492 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006331 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006642 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006354 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005859 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006131 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006168 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005944 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006000 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006398 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006077 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006064 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005938 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006343 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005955 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006245 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006051 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006134 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006622 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006325 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005733 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006238 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006326 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006165 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.005872 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005970 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006077 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006046 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006184 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006189 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005838 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006218 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006000 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005914 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006127 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006289 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006065 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006266 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006002 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.008237 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.021958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006493 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009162 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006323 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005860 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.008226 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006156 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005917 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006491 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006048 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006326 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013876 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006406 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.007806 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006400 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007776 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.009069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010169 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013730 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005922 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011424 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005578 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.005984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006043 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.012907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.013886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006257 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006227 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006196 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.012295 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005896 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.012990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006020 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005828 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006370 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006100 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005767 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006275 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006001 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006394 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.013262 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006451 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006271 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.012930 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.014262 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005955 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006340 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006240 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006674 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006348 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006186 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.014062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.007285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006359 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011141 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007061 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006807 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006769 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.009010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006472 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008112 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.023541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005888 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006186 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006162 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.013315 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006568 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013041 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006123 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013168 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011081 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008295 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010888 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.011384 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013292 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013533 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006352 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011075 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.011930 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013029 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.011167 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.011311 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012096 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006510 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.009900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013352 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006257 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.015966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.029510 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.012910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006265 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006052 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006358 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010918 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006682 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006181 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009110 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005696 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006733 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006465 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005944 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006543 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005809 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006109 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005935 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006557 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006280 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006178 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006087 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005908 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006126 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006315 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006318 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005895 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006024 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005775 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006014 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006178 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.012362 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005717 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.006317 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005885 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006133 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006009 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005992 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006055 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005970 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006680 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006126 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006063 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006191 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006000 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006248 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006218 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009586 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.013213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005960 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006605 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006337 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005914 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006029 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005957 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010078 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005844 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006191 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.009222 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005654 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005975 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006139 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.005743 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005805 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006497 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006311 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006061 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.038012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005715 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006064 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005897 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010939 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006199 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005747 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005947 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005987 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006443 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006366 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006866 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.018606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006467 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009078 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006110 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005946 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006100 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006360 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.013147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006037 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006262 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005988 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006169 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005992 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005889 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006481 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006335 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.011430 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006095 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.034802 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006439 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006015 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005804 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005761 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005955 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006018 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005955 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005740 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.005922 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006035 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.029067 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006013 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006617 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005955 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006267 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005946 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006343 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005778 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005823 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005994 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005868 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005957 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006222 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006273 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006015 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006180 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010233 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007028 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008447 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.008114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006019 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006414 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005715 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006335 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006141 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006327 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006545 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006262 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005878 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006413 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006265 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007947 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006260 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006112 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.034885 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006026 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005824 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005872 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010462 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006037 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006371 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.010786 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006250 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006011 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005939 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.32 MB) transferred to GPU in 0.006404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006492 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005914 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.007293 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006099 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006242 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006092 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005988 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006126 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.010920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005834 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006121 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.005991 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006216 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.005792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.005659 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.31 MB) transferred to GPU in 0.006277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.008396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.29 MB) transferred to GPU in 0.006200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006180 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.30 MB) transferred to GPU in 0.006589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9835213023850458, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9835213023850458\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5555114819840539, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5555114819840539\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006419 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006510 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006619 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.011646 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006637 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.012130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006309 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006221 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010840 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009661 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007309 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006588 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.013312 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006383 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008599 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006839 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.011717 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006762 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.014952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009221 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009343 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009205 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008845 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009208 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.010057 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006447 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006577 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006798 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006684 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006348 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.012021 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006212 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006178 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010137 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007203 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006161 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006231 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.013344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009331 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006323 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006408 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.015122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006501 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006702 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006603 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.007179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006573 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.020325 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.013840 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006191 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006320 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.012153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.029145 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005924 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006601 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006814 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.010836 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.013893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006169 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006170 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006701 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.017983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009522 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.024745 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006425 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007124 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006247 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006311 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009499 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007013 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010461 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006594 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006461 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010129 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006668 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006205 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006245 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006993 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006632 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008409 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006937 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.010030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.013949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006482 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006301 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.027681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006522 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006311 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.012374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009718 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008898 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006712 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006439 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006484 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009474 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008596 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009129 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008813 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009282 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008739 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006452 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005918 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006368 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006709 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006300 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005871 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006994 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006480 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006543 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006426 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009728 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006222 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006699 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006536 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006778 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.012876 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006445 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006305 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006323 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006281 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.013306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006690 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009006 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006447 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006818 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.019148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009121 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006593 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006777 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007253 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.013143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006539 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006783 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006590 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006293 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006721 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006378 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006198 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006496 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.005957 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.039036 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006462 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007067 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006975 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006629 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006518 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006547 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.018734 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006783 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006917 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006168 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006449 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009100 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006516 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006577 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006568 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008683 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009821 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006438 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006131 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.011076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007835 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.014024 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006511 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006690 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006388 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006126 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.015279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006807 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006438 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006812 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005968 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009300 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.032966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006702 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.006626 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006490 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010131 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009434 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006671 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006663 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.012846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006482 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009127 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006529 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006559 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006860 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006144 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.013618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006205 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006557 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006574 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006598 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.005963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006758 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006524 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.020198 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006747 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006497 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006521 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006808 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006926 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006563 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006827 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.024100 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.023474 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.011853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.013425 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.021120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008651 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006524 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006823 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006538 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006613 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009222 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008659 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009474 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006250 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006451 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.018448 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006844 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006186 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006619 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007335 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008170 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.028569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007018 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006333 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007047 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.005976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008492 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.016932 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.016111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006723 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006350 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.008148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009622 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.020200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006889 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.011070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009302 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006660 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006475 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006751 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.46 MB) transferred to GPU in 0.006419 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006600 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007188 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.007111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.015997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.011616 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006527 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006188 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006280 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.010826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006501 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008696 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.43 MB) transferred to GPU in 0.009116 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.028637 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006665 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.006821 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006531 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.007435 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.006973 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.44 MB) transferred to GPU in 0.009417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.009897 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.45 MB) transferred to GPU in 0.008502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8852572230783469, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8852572230783469\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.590268229296821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.590268229296821\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009399 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008657 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008711 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008655 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008573 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009079 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008658 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.016290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008802 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010094 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009252 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008547 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.021314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008590 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008765 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008672 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008470 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009191 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008756 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.014719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008520 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008657 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008799 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008928 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008724 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008799 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.009305 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008581 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008543 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010296 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008873 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.015649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.016100 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008890 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008665 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008595 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008981 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008635 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008856 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008686 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008813 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008594 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008256 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008671 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013041 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008701 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008937 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008771 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008468 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008354 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009018 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013171 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008717 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008485 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.012210 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009146 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008629 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008714 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008722 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.011244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008378 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008744 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008770 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.028830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.015820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009697 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008836 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008537 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.016359 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008583 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009422 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008511 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008519 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008769 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.009194 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.016044 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008740 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.015608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008686 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.014725 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.017748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010370 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.016435 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008430 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008803 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008837 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008746 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009521 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009367 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009021 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009053 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008644 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008827 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009260 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008570 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008841 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009581 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008724 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008475 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008768 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.79 MB) transferred to GPU in 0.008815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008457 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008707 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4026990690660863, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4026990690660863\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9167134015788723, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9167134015788723\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006675 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006703 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007460 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007078 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006707 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006384 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006834 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006499 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007047 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006897 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007379 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006688 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006437 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006590 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006358 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006612 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007181 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006696 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006798 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007637 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006655 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006359 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006647 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.011655 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006602 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006876 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.011030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006811 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007057 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006594 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007352 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007170 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006801 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.008038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.007058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009530 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009810 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009293 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006994 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006728 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006413 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006564 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006888 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006811 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006629 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006710 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006798 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006750 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006462 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006671 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006274 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006735 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006460 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007020 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006801 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.008663 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006758 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.012316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006634 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.010223 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006902 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006859 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007416 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007257 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009231 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006684 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007485 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006626 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006563 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006812 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007024 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006781 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006696 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006699 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006472 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006836 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006682 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006486 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006605 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010650 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006556 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006985 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006432 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006827 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.013697 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006207 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006660 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007205 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007243 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008712 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006659 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009425 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008735 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009597 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009727 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007303 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007095 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006715 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006482 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006933 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007065 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009247 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009731 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009278 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010408 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009415 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009782 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009350 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006730 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007203 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006391 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006946 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007043 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006639 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007260 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006871 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006803 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006609 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.012873 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006471 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007021 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006577 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.012873 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006773 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006725 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.007261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006960 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006584 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.007290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006388 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006944 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006743 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008549 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.011083 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013227 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006938 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006879 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007019 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006571 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006648 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006667 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007068 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006466 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006840 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006666 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006673 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006561 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009490 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009615 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009045 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009137 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009250 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009435 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009339 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009299 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009242 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009202 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.023690 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008993 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009126 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009639 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008943 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009519 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009512 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009724 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009515 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008789 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009579 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009789 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009240 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014172 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009481 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009896 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.018395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009282 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009415 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009504 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009795 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010350 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009392 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006651 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006534 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.007259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006545 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006775 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006656 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006646 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006605 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006780 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006708 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006371 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006527 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006482 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006743 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006694 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007515 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006717 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006601 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006782 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006884 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006494 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006785 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006759 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006818 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007053 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006992 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006800 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006457 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009154 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009542 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009107 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009862 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009309 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.011958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006841 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006670 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006666 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009297 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009325 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009485 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008928 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009262 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008999 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.021514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013588 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006490 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006701 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007208 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006731 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006664 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006688 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006777 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014407 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006622 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.011732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.011684 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006689 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006656 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007301 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006759 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014044 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006734 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006309 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010665 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006388 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006483 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006600 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006667 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006378 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006385 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006947 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006159 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006924 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006659 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006273 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006196 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006891 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006744 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006731 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006408 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.007098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006576 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006761 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.005959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006626 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007374 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006672 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006535 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.011444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006800 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006721 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007892 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006718 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006928 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006671 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006777 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009201 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008798 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008610 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.008929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010061 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009144 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009180 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009144 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009599 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008933 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009570 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009212 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009880 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009543 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009405 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009756 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009595 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008809 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009203 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.008963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009029 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009534 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010791 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009950 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009288 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009389 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009577 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009014 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009167 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.019259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010426 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009457 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009493 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.011614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006818 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006583 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006552 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.017289 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006647 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006674 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006480 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006586 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006282 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007678 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006434 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006337 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007194 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006163 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006330 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006672 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006902 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006317 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006461 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006501 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010384 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006666 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006154 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006687 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.008445 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006802 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006742 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.011003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006751 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008914 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009016 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008740 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009529 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009400 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009674 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009257 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009391 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009546 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009268 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008771 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009325 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008557 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009326 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009006 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009891 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009746 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.028255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008643 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010480 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009037 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010403 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009866 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009289 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009515 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.012319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009596 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009556 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008862 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009459 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009094 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009806 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009337 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013499 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008807 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009661 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009378 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009481 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009410 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006517 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006554 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006449 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006743 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009943 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006223 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006493 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006703 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007054 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006603 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006849 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007129 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006629 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006225 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006542 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006227 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007134 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006294 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006521 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006198 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.007211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006182 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006379 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006225 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006598 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006452 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006414 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.005936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006812 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006867 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.015385 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006813 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006251 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008657 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009367 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010400 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008787 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009605 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008504 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009663 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009663 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008648 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009198 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009075 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008890 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009814 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009428 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008703 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009460 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009161 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009053 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009487 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010100 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009390 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009283 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009785 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009615 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009242 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.013663 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.014598 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008596 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.012059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009088 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009432 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009712 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006890 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006567 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006573 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006268 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007264 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006611 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006740 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006488 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006443 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006416 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.026569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006828 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006149 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006225 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.031689 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.005930 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006772 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006654 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006538 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006568 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006247 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006110 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006518 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.011871 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007478 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006660 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006529 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006838 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006370 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006612 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009725 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006730 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006227 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006371 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006542 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009181 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009759 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008803 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008693 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009207 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009267 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009027 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008737 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009191 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009161 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009605 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010302 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009079 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009252 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009253 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008762 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008664 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009992 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008908 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009401 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009079 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008971 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008764 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009160 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009970 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010146 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009128 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009303 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009424 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009611 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009564 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009026 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009523 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009017 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009504 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008879 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014413 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.013761 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008750 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009645 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006630 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006672 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.012270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006823 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006327 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007146 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006711 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006654 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.005997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.011983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006687 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006576 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006611 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.006676 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.005945 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006266 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007702 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006635 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006609 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006398 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006601 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006303 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006718 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006856 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006989 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006898 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006384 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009325 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008552 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008615 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009208 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010027 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009088 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009078 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009401 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009486 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009228 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009253 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009362 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009742 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009243 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009165 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009616 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009001 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009635 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009516 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009216 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009480 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009611 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009095 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009538 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009542 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008810 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009459 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014018 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014093 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.014091 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.013040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.012690 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009264 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010745 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009366 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009467 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006889 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007568 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006723 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006276 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006439 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006655 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.005915 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.005868 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006467 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006300 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006888 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006691 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006394 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.032302 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006917 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.47 MB) transferred to GPU in 0.010225 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.005963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006579 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006546 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.007396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006288 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007457 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006506 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006386 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006800 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.007075 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006101 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.007170 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.010613 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006307 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006770 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.006910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.006448 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.006527 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.014037 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008947 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009208 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008992 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009673 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009015 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009101 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009427 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.008899 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009518 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009184 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009657 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008804 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009266 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009650 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008885 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009233 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.010021 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009631 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009488 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009659 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009105 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009189 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013867 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009225 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009454 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.50 MB) transferred to GPU in 0.009130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.008719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.009182 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009371 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009273 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.009794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.48 MB) transferred to GPU in 0.013945 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.49 MB) transferred to GPU in 0.013220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7408788634950649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7408788634950649\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6004845120898863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6004845120898863\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009510 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009483 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.008940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009387 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.021881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009578 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009615 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009274 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.008832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009324 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009461 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010035 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009774 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009805 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5375518035553336, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5375518035553336\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7063102564974573, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7063102564974573\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009572 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008834 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008473 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008668 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009085 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008657 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008521 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009102 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008859 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008989 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008698 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008965 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008777 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008939 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008664 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010011 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008937 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008558 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008878 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008603 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008841 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008276 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009365 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008871 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008571 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008599 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008994 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008798 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012987 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013280 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.026089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013260 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012335 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.012986 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012397 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012540 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009422 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009307 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008538 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008844 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008710 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008643 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008506 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008775 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008677 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008705 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009559 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008867 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008648 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008488 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008576 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013095 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012485 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012809 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013251 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012617 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.012976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013282 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013418 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013228 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012412 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008769 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008068 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010930 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008423 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008771 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008593 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008558 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008547 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008878 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008533 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008684 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008667 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008631 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008274 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008844 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008638 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009167 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008520 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012302 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.026123 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012767 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012466 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.014120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008645 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009814 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009015 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008849 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008652 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008795 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008896 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010240 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008894 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009137 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009128 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008709 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008676 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009058 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008257 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009150 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.031670 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008799 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008628 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009134 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009446 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008471 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008891 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012604 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012712 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.017996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012268 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.012687 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.014478 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013554 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009499 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013664 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009083 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009579 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009133 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009288 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008834 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008760 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008527 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008803 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008725 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008935 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008965 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009189 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008945 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008823 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009068 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008908 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008762 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008950 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009127 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008915 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008727 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009055 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008808 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012617 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.024865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013242 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.014038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.017841 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012745 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009902 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008488 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008532 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008598 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008439 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008669 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008797 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008928 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009388 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008665 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009198 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009240 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008388 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009416 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008416 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008914 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008806 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.029166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008451 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008859 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008957 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008948 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009055 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008772 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008898 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012465 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012803 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.019319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013315 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013744 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012945 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012505 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008789 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008922 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008225 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008975 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008536 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009356 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008465 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008579 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009383 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012366 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009055 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008742 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008687 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009077 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008646 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008793 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008811 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009247 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008975 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008950 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008572 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010814 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008970 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012804 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013044 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012567 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012879 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013009 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013169 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012791 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.029097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009283 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008867 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008647 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.011310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010731 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009246 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009126 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008932 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009001 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008793 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008821 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008918 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008696 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009019 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008836 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008897 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009313 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008661 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008860 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008523 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009362 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.015025 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012506 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012427 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012602 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012943 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012960 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013498 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012644 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013292 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.008880 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008776 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.030585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008146 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009196 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008985 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008895 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008749 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009831 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009021 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008689 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008172 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008889 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009391 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008873 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008683 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008785 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008780 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008839 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012116 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012989 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012756 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.012796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013066 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013274 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012433 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.009149 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008787 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009025 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008610 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008631 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008664 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009183 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008771 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008871 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.010738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008674 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008975 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013962 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008572 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008342 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008751 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009278 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009190 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.008760 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008745 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008321 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008978 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008870 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008539 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.008855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013041 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.009550 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012659 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.031681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012948 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013168 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012702 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012887 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.81 MB) transferred to GPU in 0.013354 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.035496 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.012794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (3.80 MB) transferred to GPU in 0.013056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9104918076999859, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9104918076999859\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.917109151084164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.917109151084164\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010497 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005037 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005282 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005410 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005342 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005185 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005701 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005726 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005096 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005414 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005652 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005518 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005223 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005714 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005117 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005171 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005288 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005020 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005281 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005413 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005571 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.007499 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007081 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007615 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005327 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005133 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004828 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.008674 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005135 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.008529 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005237 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005201 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005233 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005091 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005526 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005946 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005563 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005415 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.015069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005401 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005534 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006797 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.006938 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006706 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007301 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009633 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005324 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005321 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.007441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004999 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005184 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005438 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005290 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005180 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005444 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005256 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005051 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005227 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005415 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005534 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005301 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004908 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.007115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006678 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007238 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009965 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005535 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005433 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005057 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005293 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004914 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005296 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.004916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004844 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005399 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004749 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005582 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005024 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005077 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005215 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005188 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004839 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005041 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005292 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005218 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005283 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005217 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004764 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005046 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004749 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005127 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.007353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007599 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007137 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009430 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005237 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005152 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.009429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005438 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005202 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005474 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005144 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005426 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005050 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005167 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.016422 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005584 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005203 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005559 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007127 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.006709 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007048 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007139 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.007303 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007044 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005214 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005238 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005221 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005296 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005163 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005144 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005135 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.004780 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005063 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005305 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005085 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005050 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005358 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005112 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.004936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005359 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006860 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.006905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007046 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005218 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005210 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005541 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005186 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005162 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004787 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005150 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005184 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005326 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005276 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005169 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005267 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005461 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005645 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005239 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006480 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005052 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005238 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005756 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006912 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.006926 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.008143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007734 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005088 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.031402 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006248 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004813 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005103 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005160 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005424 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005398 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005138 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005112 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005214 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005481 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005083 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005539 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005519 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005452 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007018 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.006923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007370 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006788 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009663 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005065 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005611 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.009053 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005588 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.004934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005487 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005208 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005451 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004896 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005202 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.006044 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005228 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005097 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005280 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005329 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005247 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005430 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005658 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007139 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006981 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007353 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.009115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007107 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.009073 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.012645 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005401 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005077 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005081 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005357 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005048 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004800 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004960 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.006553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.005040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005199 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.004920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.005122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005250 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005082 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.004822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005516 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.005114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.65 MB) transferred to GPU in 0.006764 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.008337 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007434 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.67 MB) transferred to GPU in 0.007488 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007242 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (1.66 MB) transferred to GPU in 0.007031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5899432172047115, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5899432172047115\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.40007178249309194, subsample=1.0 will be ignored. Current value: bagging_fraction=0.40007178249309194\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155205, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009670 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225122 -> initscore=-1.236065\n",
      "[LightGBM] [Info] Start training from score -1.236065\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005856 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.010580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005886 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005884 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005873 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005841 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006241 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005812 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006291 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006124 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005821 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006210 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005860 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006352 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006218 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005723 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005779 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005918 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006106 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006003 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006688 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005928 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005773 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005932 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005701 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005512 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005957 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006665 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.019658 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006078 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006557 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005769 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006647 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005845 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005664 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005566 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006020 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006031 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005773 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006267 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008121 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008452 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008280 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.013925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008505 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008252 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008668 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008423 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008884 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008292 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008634 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008604 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008497 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008015 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008447 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008154 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.014112 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008708 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008371 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008268 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008315 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008360 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008426 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008800 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008467 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008601 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008594 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008689 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008094 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008768 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008352 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008430 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008415 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008252 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008697 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008289 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008240 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008483 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008264 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011672 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.016125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012091 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008194 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008632 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008350 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008196 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008619 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006016 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005868 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006066 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006093 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006645 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005909 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005583 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006019 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006447 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006137 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006016 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005710 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005554 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005438 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006139 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005880 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006889 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005749 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005887 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006389 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005837 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005670 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006075 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006116 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006211 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005760 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005872 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006001 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006178 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006079 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005520 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005635 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006406 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006178 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007851 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008603 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008331 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012239 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008091 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007876 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008807 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008215 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008201 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008101 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008875 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008408 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007722 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008930 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008289 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008537 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008190 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008747 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008747 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008694 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008727 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008222 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008286 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008475 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008429 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008318 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008557 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008233 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008323 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008081 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008593 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008616 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008529 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008411 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008710 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007994 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008458 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008368 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.027291 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008717 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.013195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008513 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34940, number of negative: 120266\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225120 -> initscore=-1.236074\n",
      "[LightGBM] [Info] Start training from score -1.236074\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005954 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005684 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006016 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005671 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005837 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005760 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006445 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005879 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006163 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005993 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005755 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005558 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005484 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006022 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005492 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007133 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009193 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005940 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006089 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006114 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006622 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005832 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005432 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005795 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006265 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006279 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005904 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005710 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005554 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005856 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006085 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006412 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006471 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006411 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006367 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005505 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005959 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008028 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008168 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007981 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007924 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008002 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007973 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008212 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008656 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008724 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008434 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008424 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008331 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008610 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007841 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008656 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008335 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008318 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007904 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008443 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008497 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008570 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008762 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008074 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008651 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008626 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008651 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.027883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008430 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007960 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008285 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009317 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008961 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008512 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008311 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008217 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009301 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012556 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008859 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008083 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008190 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008531 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008779 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008574 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008574 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008165 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008136 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012243 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011979 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.014231 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.011931 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012017 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.013056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012294 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008898 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008212 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008365 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008236 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006392 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006096 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005866 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005916 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005835 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005890 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005848 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005988 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006009 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005700 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006558 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.010980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005756 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005866 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005822 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005435 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005795 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006184 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006128 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005842 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005423 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005607 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005814 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005840 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005935 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005704 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006545 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006232 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008174 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.010808 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008034 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008423 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008457 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008389 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008331 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008317 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008617 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008132 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008956 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008459 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009112 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008671 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008581 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008926 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008595 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009171 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008534 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008767 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008419 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008792 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007946 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008339 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008246 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008896 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008559 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008530 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008158 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008895 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011797 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008504 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008595 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009305 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008836 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008131 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008384 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008629 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012387 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012046 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.024552 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012109 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012302 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008819 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008866 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008424 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008452 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008745 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009317 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005785 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006141 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006006 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006120 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008938 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005720 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005662 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005552 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006163 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005810 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006477 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005780 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005872 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005785 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005716 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006786 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005897 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005987 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006046 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005986 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005867 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005806 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005679 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006032 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005441 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006472 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005781 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005893 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.026364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006325 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005655 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006432 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005997 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005808 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006350 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005887 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006103 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005739 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006041 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005780 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005976 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005784 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008057 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008083 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007794 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008299 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008421 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008275 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008087 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008312 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007926 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008445 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008711 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.034048 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008369 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008002 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008683 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008289 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008023 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008509 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008390 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008247 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008337 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008501 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008020 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008213 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008300 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008140 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008926 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008296 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008368 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008133 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011092 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008592 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008507 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008594 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008744 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008693 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008244 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008292 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012185 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008945 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008224 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008428 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009026 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008332 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008237 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008494 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008491 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008240 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008333 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008578 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012528 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012288 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009378 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009596 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008734 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008418 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009154 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008526 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009451 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006004 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005949 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006039 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006002 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006293 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005562 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005964 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006051 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006021 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006746 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006040 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006172 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006005 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005843 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006300 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005974 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005996 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006228 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005587 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006050 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006088 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006085 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012313 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005991 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005994 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005981 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006083 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006053 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006098 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005830 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.017564 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005901 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005921 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005772 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005827 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005987 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006358 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006016 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006138 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005975 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005616 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008064 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008293 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008312 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007967 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009068 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008202 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008581 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008249 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.024150 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008580 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008609 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008601 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008758 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008416 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008793 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008387 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008702 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008294 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.010180 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008366 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008345 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.014375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009254 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008508 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008336 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012556 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012743 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012519 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012646 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011964 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008618 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008768 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008809 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009306 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008626 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008066 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008602 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.013880 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012396 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.013714 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008877 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008672 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008732 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008570 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008391 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008738 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008438 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012153 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009381 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005683 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005650 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005781 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006311 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006151 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005811 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006814 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005951 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006695 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005837 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.018950 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006356 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006096 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006879 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006448 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005929 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005952 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006268 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006095 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006341 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006590 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006123 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006051 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005624 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005787 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005678 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006157 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006356 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006166 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006129 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005617 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006080 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006596 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006134 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006162 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006417 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006391 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006155 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006078 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005854 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006124 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006515 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006273 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006065 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005681 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006081 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006054 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006011 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006517 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006227 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006149 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006426 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007919 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008426 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008149 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008815 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008548 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008245 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008302 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008422 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009857 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008210 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008503 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008220 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008370 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008161 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008308 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008515 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008639 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008998 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008675 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.024774 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008411 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008226 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008697 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009427 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012143 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008341 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008066 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008427 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008729 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008008 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008468 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008810 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008226 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008479 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008301 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008490 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008434 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012398 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011990 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008487 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008326 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.019773 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008405 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008209 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008741 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009496 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008315 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008558 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008676 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008468 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008656 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012271 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008646 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008591 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.010533 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005942 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006084 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006255 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005796 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005707 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005948 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007389 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006012 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005936 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006074 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006069 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005866 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006119 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005853 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005791 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006026 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005807 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005641 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005950 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005881 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006082 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006171 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005574 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006266 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005581 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006118 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005829 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006748 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005728 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005771 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005905 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005529 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006475 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005471 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005753 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006326 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005560 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005440 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006076 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009816 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005777 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006825 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006042 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006525 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005804 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005982 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006051 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007923 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.032010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008333 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007849 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008620 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008205 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008125 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008117 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008393 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008189 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008544 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008272 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009349 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008559 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008335 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008840 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008576 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008377 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008506 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008511 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008270 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008516 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008116 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008491 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008685 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009043 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008660 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008933 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008813 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008313 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008328 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008448 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008633 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009264 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008256 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008627 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008858 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008343 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008294 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009187 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009189 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008589 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012333 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011968 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.011943 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008623 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.027196 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008489 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008712 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008295 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008437 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008522 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008130 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008746 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008192 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012268 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.013304 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011983 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008433 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008401 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007970 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008736 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008361 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008602 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008423 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008175 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008456 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009614 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005790 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006142 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005863 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005925 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005941 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005761 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006071 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005873 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006038 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005888 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006088 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006000 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006644 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005517 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006434 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006177 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006394 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005934 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005995 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006093 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005966 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005897 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006281 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011754 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006029 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005903 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005889 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005844 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006493 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005797 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005469 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006457 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006321 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005495 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005558 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005920 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005719 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006215 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012010 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006262 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006131 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005973 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006355 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005850 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005862 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006555 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005964 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005450 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005864 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006164 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006222 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007186 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005800 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005846 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006150 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006179 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006044 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006170 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008059 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007692 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008263 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.014200 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008338 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008102 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008264 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008324 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007926 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008637 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.014122 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009171 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008584 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.010500 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008364 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008169 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008161 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008068 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008276 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.010443 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008512 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009865 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008422 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008403 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.015971 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008965 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009033 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008613 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008342 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.009575 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008501 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008598 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008404 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008298 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008334 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008376 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008433 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.025585 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008590 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012563 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012194 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008385 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007953 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008265 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008198 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008072 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008310 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009046 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008300 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008805 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008269 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008493 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009582 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.016219 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012380 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012147 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.011799 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012108 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.012062 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008502 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008882 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008398 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008369 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008640 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008977 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008363 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008195 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008874 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008637 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Info] Number of positive: 34941, number of negative: 120265\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 6885\n",
      "[LightGBM] [Info] Number of data points in the train set: 155206, number of used features: 27\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3070, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (4.14 MB) transferred to GPU in 0.009436 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.225127 -> initscore=-1.236037\n",
      "[LightGBM] [Info] Start training from score -1.236037\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005820 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005572 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006128 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005767 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006139 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006173 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005855 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005876 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005869 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006958 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005883 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005911 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005472 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006972 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005907 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005817 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005478 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005713 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005725 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006154 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005915 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005649 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006226 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005913 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005517 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005833 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006070 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005606 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006019 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.028246 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006316 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006235 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006049 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006047 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005551 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005891 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006086 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006063 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005757 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006367 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006412 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005706 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.005536 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005569 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006102 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006242 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.006395 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.022595 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005927 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006319 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006852 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005826 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006259 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006090 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005980 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.005847 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006030 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.005828 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.006162 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.006229 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008284 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008408 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008148 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008001 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008104 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008490 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007763 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009061 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008890 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008234 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008309 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008766 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008322 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007910 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008445 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008490 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008887 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008176 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008194 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008205 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008362 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.007782 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008191 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008382 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008160 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008714 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008371 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008351 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008516 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008226 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008937 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.009113 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007915 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008653 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008346 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008636 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008127 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008230 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008420 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008647 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008442 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008202 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008087 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008613 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008204 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008531 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.013111 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.007805 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008406 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008431 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008115 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008344 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.007900 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008546 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008553 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008392 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.009277 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008314 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008287 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.013318 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.011206 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.012343 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012372 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012305 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.014491 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008238 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008414 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008452 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008416 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008437 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008156 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008261 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008373 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.15 MB) transferred to GPU in 0.008984 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.13 MB) transferred to GPU in 0.008514 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008024 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.008375 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 27 dense feature groups (2.14 MB) transferred to GPU in 0.012056 secs. 0 sparse feature groups\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9627785651341085, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9627785651341085\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.516283594226422, subsample=1.0 will be ignored. Current value: bagging_fraction=0.516283594226422\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 11:53:44 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "lightgbm_tuned_model, lightgbm_tuner = tune_model(lightgbm, search_library = 'optuna', return_tuner=True, n_iter=num_iterations_tuning, optimize=optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07469b55-3844-4312-b370-4abd01748ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(bagging_fraction=0.8455104741417432, bagging_freq=0,\n",
      "               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "               device='gpu', feature_fraction=0.42947671039481,\n",
      "               importance_type='split', learning_rate=0.47910287588557177,\n",
      "               max_depth=-1, min_child_samples=41, min_child_weight=0.001,\n",
      "               min_split_gain=0.23016472358397666, n_estimators=245, n_jobs=-1,\n",
      "               num_leaves=250, objective=None, random_state=1768,\n",
      "               reg_alpha=0.00039695268896179983,\n",
      "               reg_lambda=3.6071600095045767e-06, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "print(lightgbm_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "535108d7-e316-4bc1-a4a6-377f4dce0961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_65e22\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_65e22_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_65e22_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_65e22_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_65e22_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_65e22_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_65e22_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_65e22_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_65e22_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_65e22_level0_col8\" class=\"col_heading level0 col8\" >Balance Acc</th>\n",
       "      <th id=\"T_65e22_level0_col9\" class=\"col_heading level0 col9\" >Hamming Loss</th>\n",
       "      <th id=\"T_65e22_level0_col10\" class=\"col_heading level0 col10\" >Jaccard Score</th>\n",
       "      <th id=\"T_65e22_level0_col11\" class=\"col_heading level0 col11\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_65e22_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_65e22_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_65e22_row0_col1\" class=\"data row0 col1\" >0.9781</td>\n",
       "      <td id=\"T_65e22_row0_col2\" class=\"data row0 col2\" >0.9943</td>\n",
       "      <td id=\"T_65e22_row0_col3\" class=\"data row0 col3\" >0.9781</td>\n",
       "      <td id=\"T_65e22_row0_col4\" class=\"data row0 col4\" >0.9780</td>\n",
       "      <td id=\"T_65e22_row0_col5\" class=\"data row0 col5\" >0.9780</td>\n",
       "      <td id=\"T_65e22_row0_col6\" class=\"data row0 col6\" >0.9366</td>\n",
       "      <td id=\"T_65e22_row0_col7\" class=\"data row0 col7\" >0.9369</td>\n",
       "      <td id=\"T_65e22_row0_col8\" class=\"data row0 col8\" >0.9617</td>\n",
       "      <td id=\"T_65e22_row0_col9\" class=\"data row0 col9\" >0.0219</td>\n",
       "      <td id=\"T_65e22_row0_col10\" class=\"data row0 col10\" >0.9060</td>\n",
       "      <td id=\"T_65e22_row0_col11\" class=\"data row0 col11\" >0.0704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27188b93a30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n",
      "[LightGBM] [Warning] feature_fraction is set=0.42947671039481, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.42947671039481\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8455104741417432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8455104741417432\n",
      "[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0\n"
     ]
    }
   ],
   "source": [
    "predictions_lightgbm = predict_model(lightgbm_tuned_model, data = features_df_testing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6de13ba-59cf-4048-8b12-75912f3fd0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02882d260f2b48eb99cb4f5150b07baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(lightgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31cadee3-f0e3-4f9d-89ba-517d8944a485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bandwidth</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meanFreq</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meanWavelet</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medianFreq</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spectral_flatness</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>skewness</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entropyWavelet</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spectral_skewness</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mean</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spectral_kurtosis</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>varWavelet</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>entropy</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>shape</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>meanSpectrogram</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>clearance</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>energy</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ptp</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>crest</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>entropySpectrogram</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>impulse</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>varSpectrogram</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>std</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>energyWavelet</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>energySpectrogram</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>rms</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features  importance\n",
       "0            bandwidth         320\n",
       "1             meanFreq         303\n",
       "2          meanWavelet         301\n",
       "3           medianFreq         295\n",
       "4    spectral_flatness         266\n",
       "5             skewness         184\n",
       "6       entropyWavelet         167\n",
       "7    spectral_skewness         163\n",
       "8                 mean         107\n",
       "9    spectral_kurtosis         105\n",
       "10    spectral_entropy          92\n",
       "11          varWavelet          92\n",
       "12             entropy          88\n",
       "13               shape          82\n",
       "14            kurtosis          52\n",
       "15     meanSpectrogram          45\n",
       "16           clearance          43\n",
       "17              energy          42\n",
       "18                 ptp          40\n",
       "19               crest          35\n",
       "20  entropySpectrogram          34\n",
       "21             impulse          33\n",
       "22      varSpectrogram          27\n",
       "23                 std          23\n",
       "24       energyWavelet          22\n",
       "25   energySpectrogram          22\n",
       "26                 rms          17"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightgbm_top_features = get_feature_importance_df(lightgbm, features_df_training_normalized)\n",
    "lightgbm_top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ba6b509-625a-40ed-be97-3ff2178817cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_9bf1a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9bf1a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_9bf1a_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_9bf1a_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_9bf1a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_9bf1a_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_9bf1a_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_9bf1a_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_9bf1a_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_9bf1a_level0_col8\" class=\"col_heading level0 col8\" >Balance Acc</th>\n",
       "      <th id=\"T_9bf1a_level0_col9\" class=\"col_heading level0 col9\" >Hamming Loss</th>\n",
       "      <th id=\"T_9bf1a_level0_col10\" class=\"col_heading level0 col10\" >Jaccard Score</th>\n",
       "      <th id=\"T_9bf1a_level0_col11\" class=\"col_heading level0 col11\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9bf1a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9bf1a_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_9bf1a_row0_col1\" class=\"data row0 col1\" >0.9522</td>\n",
       "      <td id=\"T_9bf1a_row0_col2\" class=\"data row0 col2\" >0.9866</td>\n",
       "      <td id=\"T_9bf1a_row0_col3\" class=\"data row0 col3\" >0.9522</td>\n",
       "      <td id=\"T_9bf1a_row0_col4\" class=\"data row0 col4\" >0.9532</td>\n",
       "      <td id=\"T_9bf1a_row0_col5\" class=\"data row0 col5\" >0.9506</td>\n",
       "      <td id=\"T_9bf1a_row0_col6\" class=\"data row0 col6\" >0.8549</td>\n",
       "      <td id=\"T_9bf1a_row0_col7\" class=\"data row0 col7\" >0.8606</td>\n",
       "      <td id=\"T_9bf1a_row0_col8\" class=\"data row0 col8\" >0.9023</td>\n",
       "      <td id=\"T_9bf1a_row0_col9\" class=\"data row0 col9\" >0.0478</td>\n",
       "      <td id=\"T_9bf1a_row0_col10\" class=\"data row0 col10\" >0.7933</td>\n",
       "      <td id=\"T_9bf1a_row0_col11\" class=\"data row0 col11\" >0.1148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27107fd6bf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_lightgbm = predict_model(lightgbm, data = features_df_testing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34173f0e-3b07-47ec-9bc1-6a932d4a3f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>rms</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>ptp</th>\n",
       "      <th>crest</th>\n",
       "      <th>impulse</th>\n",
       "      <th>clearance</th>\n",
       "      <th>shape</th>\n",
       "      <th>...</th>\n",
       "      <th>varWavelet</th>\n",
       "      <th>entropyWavelet</th>\n",
       "      <th>energyWavelet</th>\n",
       "      <th>meanSpectrogram</th>\n",
       "      <th>varSpectrogram</th>\n",
       "      <th>entropySpectrogram</th>\n",
       "      <th>energySpectrogram</th>\n",
       "      <th>Label</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93960</th>\n",
       "      <td>0.235183</td>\n",
       "      <td>1.062654</td>\n",
       "      <td>1.181320</td>\n",
       "      <td>0.246260</td>\n",
       "      <td>-0.055801</td>\n",
       "      <td>1.856693</td>\n",
       "      <td>0.318572</td>\n",
       "      <td>0.229234</td>\n",
       "      <td>1.887167</td>\n",
       "      <td>0.169256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175728</td>\n",
       "      <td>0.144233</td>\n",
       "      <td>0.515128</td>\n",
       "      <td>0.251476</td>\n",
       "      <td>-0.118528</td>\n",
       "      <td>-0.143934</td>\n",
       "      <td>-0.117957</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.012873</td>\n",
       "      <td>-0.573892</td>\n",
       "      <td>-0.608301</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>-0.772690</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>-0.026207</td>\n",
       "      <td>-0.986468</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276503</td>\n",
       "      <td>0.164883</td>\n",
       "      <td>-0.302537</td>\n",
       "      <td>-0.241933</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.8974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33266</th>\n",
       "      <td>0.068736</td>\n",
       "      <td>-0.612422</td>\n",
       "      <td>-0.648066</td>\n",
       "      <td>-0.205265</td>\n",
       "      <td>-0.089285</td>\n",
       "      <td>-0.831232</td>\n",
       "      <td>-0.524111</td>\n",
       "      <td>-0.441818</td>\n",
       "      <td>-1.303345</td>\n",
       "      <td>-0.235899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276743</td>\n",
       "      <td>0.163780</td>\n",
       "      <td>-0.303045</td>\n",
       "      <td>-0.242338</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>healthy</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.8038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238774</th>\n",
       "      <td>0.033096</td>\n",
       "      <td>-0.136916</td>\n",
       "      <td>-0.127309</td>\n",
       "      <td>0.167115</td>\n",
       "      <td>-0.073693</td>\n",
       "      <td>-0.051146</td>\n",
       "      <td>0.591589</td>\n",
       "      <td>0.398757</td>\n",
       "      <td>0.412783</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210708</td>\n",
       "      <td>0.202637</td>\n",
       "      <td>-0.225960</td>\n",
       "      <td>-0.198761</td>\n",
       "      <td>-0.119454</td>\n",
       "      <td>-0.155680</td>\n",
       "      <td>-0.119575</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.9226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210317</th>\n",
       "      <td>0.033394</td>\n",
       "      <td>-0.435811</td>\n",
       "      <td>-0.453998</td>\n",
       "      <td>0.078050</td>\n",
       "      <td>-0.009010</td>\n",
       "      <td>-0.571356</td>\n",
       "      <td>-0.224380</td>\n",
       "      <td>-0.089825</td>\n",
       "      <td>-0.517015</td>\n",
       "      <td>0.712591</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266166</td>\n",
       "      <td>0.174123</td>\n",
       "      <td>-0.291462</td>\n",
       "      <td>-0.236005</td>\n",
       "      <td>-0.119508</td>\n",
       "      <td>-0.156153</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.8891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241132</th>\n",
       "      <td>0.036482</td>\n",
       "      <td>-0.427159</td>\n",
       "      <td>-0.444468</td>\n",
       "      <td>-0.047157</td>\n",
       "      <td>0.270062</td>\n",
       "      <td>-0.459822</td>\n",
       "      <td>0.946953</td>\n",
       "      <td>0.994946</td>\n",
       "      <td>-0.094569</td>\n",
       "      <td>1.758543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264591</td>\n",
       "      <td>0.173715</td>\n",
       "      <td>-0.290368</td>\n",
       "      <td>-0.234696</td>\n",
       "      <td>-0.119505</td>\n",
       "      <td>-0.156126</td>\n",
       "      <td>-0.119630</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.8011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214791</th>\n",
       "      <td>0.035452</td>\n",
       "      <td>-0.406114</td>\n",
       "      <td>-0.421478</td>\n",
       "      <td>-0.047884</td>\n",
       "      <td>0.268881</td>\n",
       "      <td>-0.413760</td>\n",
       "      <td>0.859693</td>\n",
       "      <td>0.815125</td>\n",
       "      <td>-0.085377</td>\n",
       "      <td>1.173851</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262673</td>\n",
       "      <td>0.175848</td>\n",
       "      <td>-0.287531</td>\n",
       "      <td>-0.232590</td>\n",
       "      <td>-0.119501</td>\n",
       "      <td>-0.156096</td>\n",
       "      <td>-0.119626</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.8678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165165</th>\n",
       "      <td>0.112750</td>\n",
       "      <td>0.319713</td>\n",
       "      <td>0.371290</td>\n",
       "      <td>0.497024</td>\n",
       "      <td>0.115964</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>0.687841</td>\n",
       "      <td>0.680583</td>\n",
       "      <td>1.376881</td>\n",
       "      <td>1.164648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.136958</td>\n",
       "      <td>-0.019808</td>\n",
       "      <td>-0.080584</td>\n",
       "      <td>-0.116263</td>\n",
       "      <td>-0.139601</td>\n",
       "      <td>-0.116393</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217690</th>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.164117</td>\n",
       "      <td>0.201626</td>\n",
       "      <td>0.444060</td>\n",
       "      <td>-0.093651</td>\n",
       "      <td>0.278279</td>\n",
       "      <td>-0.162111</td>\n",
       "      <td>-0.169209</td>\n",
       "      <td>0.501702</td>\n",
       "      <td>-0.145207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105311</td>\n",
       "      <td>0.204984</td>\n",
       "      <td>-0.101980</td>\n",
       "      <td>-0.121442</td>\n",
       "      <td>-0.118854</td>\n",
       "      <td>-0.151695</td>\n",
       "      <td>-0.118953</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.7371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187170</th>\n",
       "      <td>0.043438</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>-0.589698</td>\n",
       "      <td>-0.139529</td>\n",
       "      <td>0.046979</td>\n",
       "      <td>-0.378676</td>\n",
       "      <td>-0.398164</td>\n",
       "      <td>0.139133</td>\n",
       "      <td>-0.672541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.162340</td>\n",
       "      <td>0.203661</td>\n",
       "      <td>-0.176265</td>\n",
       "      <td>-0.168930</td>\n",
       "      <td>-0.119230</td>\n",
       "      <td>-0.154169</td>\n",
       "      <td>-0.119347</td>\n",
       "      <td>damaged</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61590 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       rms       std  skewness  kurtosis       ptp     crest  \\\n",
       "93960   0.235183  1.062654  1.181320  0.246260 -0.055801  1.856693  0.318572   \n",
       "371     0.012873 -0.573892 -0.608301  0.586265 -0.043286 -0.772690  0.000642   \n",
       "33266   0.068736 -0.612422 -0.648066 -0.205265 -0.089285 -0.831232 -0.524111   \n",
       "238774  0.033096 -0.136916 -0.127309  0.167115 -0.073693 -0.051146  0.591589   \n",
       "210317  0.033394 -0.435811 -0.453998  0.078050 -0.009010 -0.571356 -0.224380   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "241132  0.036482 -0.427159 -0.444468 -0.047157  0.270062 -0.459822  0.946953   \n",
       "214791  0.035452 -0.406114 -0.421478 -0.047884  0.268881 -0.413760  0.859693   \n",
       "165165  0.112750  0.319713  0.371290  0.497024  0.115964  0.739326  0.687841   \n",
       "217690  0.038995  0.164117  0.201626  0.444060 -0.093651  0.278279 -0.162111   \n",
       "187170  0.043438  0.013482  0.037075 -0.589698 -0.139529  0.046979 -0.378676   \n",
       "\n",
       "         impulse  clearance     shape  ...  varWavelet  entropyWavelet  \\\n",
       "93960   0.229234   1.887167  0.169256  ...    0.175728        0.144233   \n",
       "371    -0.026207  -0.986468  0.022755  ...   -0.276503        0.164883   \n",
       "33266  -0.441818  -1.303345 -0.235899  ...   -0.276743        0.163780   \n",
       "238774  0.398757   0.412783 -0.002132  ...   -0.210708        0.202637   \n",
       "210317 -0.089825  -0.517015  0.712591  ...   -0.266166        0.174123   \n",
       "...          ...        ...       ...  ...         ...             ...   \n",
       "241132  0.994946  -0.094569  1.758543  ...   -0.264591        0.173715   \n",
       "214791  0.815125  -0.085377  1.173851  ...   -0.262673        0.175848   \n",
       "165165  0.680583   1.376881  1.164648  ...    0.002140        0.136958   \n",
       "217690 -0.169209   0.501702 -0.145207  ...   -0.105311        0.204984   \n",
       "187170 -0.398164   0.139133 -0.672541  ...   -0.162340        0.203661   \n",
       "\n",
       "        energyWavelet  meanSpectrogram  varSpectrogram  entropySpectrogram  \\\n",
       "93960        0.515128         0.251476       -0.118528           -0.143934   \n",
       "371         -0.302537        -0.241933       -0.119511           -0.156183   \n",
       "33266       -0.303045        -0.242338       -0.119511           -0.156183   \n",
       "238774      -0.225960        -0.198761       -0.119454           -0.155680   \n",
       "210317      -0.291462        -0.236005       -0.119508           -0.156153   \n",
       "...               ...              ...             ...                 ...   \n",
       "241132      -0.290368        -0.234696       -0.119505           -0.156126   \n",
       "214791      -0.287531        -0.232590       -0.119501           -0.156096   \n",
       "165165      -0.019808        -0.080584       -0.116263           -0.139601   \n",
       "217690      -0.101980        -0.121442       -0.118854           -0.151695   \n",
       "187170      -0.176265        -0.168930       -0.119230           -0.154169   \n",
       "\n",
       "        energySpectrogram    Label  prediction_label  prediction_score  \n",
       "93960           -0.117957  damaged           damaged            0.9999  \n",
       "371             -0.119637  healthy           damaged            0.8974  \n",
       "33266           -0.119637  healthy           healthy            0.8038  \n",
       "238774          -0.119575  damaged           damaged            0.9226  \n",
       "210317          -0.119633  damaged           damaged            0.8891  \n",
       "...                   ...      ...               ...               ...  \n",
       "241132          -0.119630  damaged           damaged            0.8011  \n",
       "214791          -0.119626  damaged           damaged            0.8678  \n",
       "165165          -0.116393  damaged           damaged            0.9998  \n",
       "217690          -0.118953  damaged           damaged            0.7371  \n",
       "187170          -0.119347  damaged           damaged            0.9996  \n",
       "\n",
       "[61590 rows x 30 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "789da63d-eb26-4f36-9559-4f8dc35b2c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>rms</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>ptp</th>\n",
       "      <th>crest</th>\n",
       "      <th>impulse</th>\n",
       "      <th>clearance</th>\n",
       "      <th>shape</th>\n",
       "      <th>...</th>\n",
       "      <th>varWavelet</th>\n",
       "      <th>entropyWavelet</th>\n",
       "      <th>energyWavelet</th>\n",
       "      <th>meanSpectrogram</th>\n",
       "      <th>varSpectrogram</th>\n",
       "      <th>entropySpectrogram</th>\n",
       "      <th>energySpectrogram</th>\n",
       "      <th>Label</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.012873</td>\n",
       "      <td>-0.573892</td>\n",
       "      <td>-0.608301</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>-0.772690</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>-0.026207</td>\n",
       "      <td>-0.986468</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276503</td>\n",
       "      <td>0.164883</td>\n",
       "      <td>-0.302537</td>\n",
       "      <td>-0.241933</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.8974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258524</th>\n",
       "      <td>0.036464</td>\n",
       "      <td>-0.602333</td>\n",
       "      <td>-0.637307</td>\n",
       "      <td>-0.407115</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>-0.806982</td>\n",
       "      <td>0.949561</td>\n",
       "      <td>0.854643</td>\n",
       "      <td>-1.057003</td>\n",
       "      <td>1.018010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276646</td>\n",
       "      <td>0.164046</td>\n",
       "      <td>-0.302923</td>\n",
       "      <td>-0.242255</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.6787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207745</th>\n",
       "      <td>0.036146</td>\n",
       "      <td>-0.054912</td>\n",
       "      <td>-0.037686</td>\n",
       "      <td>-0.206209</td>\n",
       "      <td>-0.191703</td>\n",
       "      <td>-0.166550</td>\n",
       "      <td>-0.817718</td>\n",
       "      <td>-0.706493</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-0.686273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178280</td>\n",
       "      <td>0.195415</td>\n",
       "      <td>-0.197872</td>\n",
       "      <td>-0.181161</td>\n",
       "      <td>-0.119248</td>\n",
       "      <td>-0.154350</td>\n",
       "      <td>-0.119369</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.8491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255723</th>\n",
       "      <td>0.035643</td>\n",
       "      <td>-0.187058</td>\n",
       "      <td>-0.182074</td>\n",
       "      <td>0.147473</td>\n",
       "      <td>-0.086570</td>\n",
       "      <td>-0.243538</td>\n",
       "      <td>-0.400318</td>\n",
       "      <td>-0.316864</td>\n",
       "      <td>-0.104728</td>\n",
       "      <td>0.027741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222601</td>\n",
       "      <td>0.196681</td>\n",
       "      <td>-0.240971</td>\n",
       "      <td>-0.205668</td>\n",
       "      <td>-0.119463</td>\n",
       "      <td>-0.155770</td>\n",
       "      <td>-0.119586</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.6397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207040</th>\n",
       "      <td>0.039656</td>\n",
       "      <td>-0.082632</td>\n",
       "      <td>-0.067949</td>\n",
       "      <td>0.162263</td>\n",
       "      <td>-0.036778</td>\n",
       "      <td>0.060171</td>\n",
       "      <td>0.134858</td>\n",
       "      <td>0.100614</td>\n",
       "      <td>0.324422</td>\n",
       "      <td>0.206646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195858</td>\n",
       "      <td>0.206877</td>\n",
       "      <td>-0.207824</td>\n",
       "      <td>-0.184564</td>\n",
       "      <td>-0.119401</td>\n",
       "      <td>-0.155277</td>\n",
       "      <td>-0.119519</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.6681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206916</th>\n",
       "      <td>0.041697</td>\n",
       "      <td>-0.158916</td>\n",
       "      <td>-0.151280</td>\n",
       "      <td>0.231444</td>\n",
       "      <td>-0.101904</td>\n",
       "      <td>-0.181929</td>\n",
       "      <td>-0.347732</td>\n",
       "      <td>-0.291088</td>\n",
       "      <td>-0.043652</td>\n",
       "      <td>-0.061274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216526</td>\n",
       "      <td>0.200570</td>\n",
       "      <td>-0.232714</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-0.119441</td>\n",
       "      <td>-0.155599</td>\n",
       "      <td>-0.119563</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.9436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200497</th>\n",
       "      <td>0.033159</td>\n",
       "      <td>-0.386435</td>\n",
       "      <td>-0.400006</td>\n",
       "      <td>0.047990</td>\n",
       "      <td>0.064846</td>\n",
       "      <td>-0.452461</td>\n",
       "      <td>0.219733</td>\n",
       "      <td>0.307008</td>\n",
       "      <td>-0.226820</td>\n",
       "      <td>1.091975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258714</td>\n",
       "      <td>0.176503</td>\n",
       "      <td>-0.284612</td>\n",
       "      <td>-0.231184</td>\n",
       "      <td>-0.119501</td>\n",
       "      <td>-0.156092</td>\n",
       "      <td>-0.119626</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.5748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258687</th>\n",
       "      <td>0.037649</td>\n",
       "      <td>-0.412417</td>\n",
       "      <td>-0.428330</td>\n",
       "      <td>0.099707</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>-0.512874</td>\n",
       "      <td>-0.121624</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.423838</td>\n",
       "      <td>0.784442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262370</td>\n",
       "      <td>0.174837</td>\n",
       "      <td>-0.288400</td>\n",
       "      <td>-0.233108</td>\n",
       "      <td>-0.119503</td>\n",
       "      <td>-0.156112</td>\n",
       "      <td>-0.119628</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.6131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205706</th>\n",
       "      <td>0.035491</td>\n",
       "      <td>-0.426794</td>\n",
       "      <td>-0.444088</td>\n",
       "      <td>0.048360</td>\n",
       "      <td>0.038563</td>\n",
       "      <td>-0.511299</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>0.161734</td>\n",
       "      <td>-0.395557</td>\n",
       "      <td>0.467480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.264963</td>\n",
       "      <td>0.174827</td>\n",
       "      <td>-0.290323</td>\n",
       "      <td>-0.234408</td>\n",
       "      <td>-0.119506</td>\n",
       "      <td>-0.156138</td>\n",
       "      <td>-0.119632</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.6595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201271</th>\n",
       "      <td>0.034609</td>\n",
       "      <td>-0.404988</td>\n",
       "      <td>-0.420263</td>\n",
       "      <td>-0.027683</td>\n",
       "      <td>-0.020592</td>\n",
       "      <td>-0.524025</td>\n",
       "      <td>-0.304570</td>\n",
       "      <td>-0.192165</td>\n",
       "      <td>-0.476571</td>\n",
       "      <td>0.417044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.261506</td>\n",
       "      <td>0.175662</td>\n",
       "      <td>-0.287366</td>\n",
       "      <td>-0.232991</td>\n",
       "      <td>-0.119503</td>\n",
       "      <td>-0.156113</td>\n",
       "      <td>-0.119629</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.6514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2943 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       rms       std  skewness  kurtosis       ptp     crest  \\\n",
       "371     0.012873 -0.573892 -0.608301  0.586265 -0.043286 -0.772690  0.000642   \n",
       "258524  0.036464 -0.602333 -0.637307 -0.407115  0.131417 -0.806982  0.949561   \n",
       "207745  0.036146 -0.054912 -0.037686 -0.206209 -0.191703 -0.166550 -0.817718   \n",
       "255723  0.035643 -0.187058 -0.182074  0.147473 -0.086570 -0.243538 -0.400318   \n",
       "207040  0.039656 -0.082632 -0.067949  0.162263 -0.036778  0.060171  0.134858   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "206916  0.041697 -0.158916 -0.151280  0.231444 -0.101904 -0.181929 -0.347732   \n",
       "200497  0.033159 -0.386435 -0.400006  0.047990  0.064846 -0.452461  0.219733   \n",
       "258687  0.037649 -0.412417 -0.428330  0.099707  0.062800 -0.512874 -0.121624   \n",
       "205706  0.035491 -0.426794 -0.444088  0.048360  0.038563 -0.511299  0.161131   \n",
       "201271  0.034609 -0.404988 -0.420263 -0.027683 -0.020592 -0.524025 -0.304570   \n",
       "\n",
       "         impulse  clearance     shape  ...  varWavelet  entropyWavelet  \\\n",
       "371    -0.026207  -0.986468  0.022755  ...   -0.276503        0.164883   \n",
       "258524  0.854643  -1.057003  1.018010  ...   -0.276646        0.164046   \n",
       "207745 -0.706493  -0.152971 -0.686273  ...   -0.178280        0.195415   \n",
       "255723 -0.316864  -0.104728  0.027741  ...   -0.222601        0.196681   \n",
       "207040  0.100614   0.324422  0.206646  ...   -0.195858        0.206877   \n",
       "...          ...        ...       ...  ...         ...             ...   \n",
       "206916 -0.291088  -0.043652 -0.061274  ...   -0.216526        0.200570   \n",
       "200497  0.307008  -0.226820  1.091975  ...   -0.258714        0.176503   \n",
       "258687 -0.001592  -0.423838  0.784442  ...   -0.262370        0.174837   \n",
       "205706  0.161734  -0.395557  0.467480  ...   -0.264963        0.174827   \n",
       "201271 -0.192165  -0.476571  0.417044  ...   -0.261506        0.175662   \n",
       "\n",
       "        energyWavelet  meanSpectrogram  varSpectrogram  entropySpectrogram  \\\n",
       "371         -0.302537        -0.241933       -0.119511           -0.156183   \n",
       "258524      -0.302923        -0.242255       -0.119511           -0.156183   \n",
       "207745      -0.197872        -0.181161       -0.119248           -0.154350   \n",
       "255723      -0.240971        -0.205668       -0.119463           -0.155770   \n",
       "207040      -0.207824        -0.184564       -0.119401           -0.155277   \n",
       "...               ...              ...             ...                 ...   \n",
       "206916      -0.232714        -0.198674       -0.119441           -0.155599   \n",
       "200497      -0.284612        -0.231184       -0.119501           -0.156092   \n",
       "258687      -0.288400        -0.233108       -0.119503           -0.156112   \n",
       "205706      -0.290323        -0.234408       -0.119506           -0.156138   \n",
       "201271      -0.287366        -0.232991       -0.119503           -0.156113   \n",
       "\n",
       "        energySpectrogram    Label  prediction_label  prediction_score  \n",
       "371             -0.119637  healthy           damaged            0.8974  \n",
       "258524          -0.119637  healthy           damaged            0.6787  \n",
       "207745          -0.119369  healthy           damaged            0.8491  \n",
       "255723          -0.119586  healthy           damaged            0.6397  \n",
       "207040          -0.119519  healthy           damaged            0.6681  \n",
       "...                   ...      ...               ...               ...  \n",
       "206916          -0.119563  healthy           damaged            0.9436  \n",
       "200497          -0.119626  healthy           damaged            0.5748  \n",
       "258687          -0.119628  healthy           damaged            0.6131  \n",
       "205706          -0.119632  healthy           damaged            0.6595  \n",
       "201271          -0.119629  healthy           damaged            0.6514  \n",
       "\n",
       "[2943 rows x 30 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_incorrect_predictions(predictions_lightgbm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d3df1-3151-4046-8abc-d66039145875",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6aa747c-a901-435f-b4ae-0e0cf24659a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3fd68_row10_col0, #T_3fd68_row10_col1, #T_3fd68_row10_col2, #T_3fd68_row10_col3, #T_3fd68_row10_col4, #T_3fd68_row10_col5, #T_3fd68_row10_col6, #T_3fd68_row10_col7, #T_3fd68_row10_col8, #T_3fd68_row10_col9, #T_3fd68_row10_col10 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3fd68\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3fd68_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_3fd68_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_3fd68_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_3fd68_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_3fd68_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_3fd68_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_3fd68_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_3fd68_level0_col7\" class=\"col_heading level0 col7\" >Balance Acc</th>\n",
       "      <th id=\"T_3fd68_level0_col8\" class=\"col_heading level0 col8\" >Hamming Loss</th>\n",
       "      <th id=\"T_3fd68_level0_col9\" class=\"col_heading level0 col9\" >Jaccard Score</th>\n",
       "      <th id=\"T_3fd68_level0_col10\" class=\"col_heading level0 col10\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3fd68_row0_col0\" class=\"data row0 col0\" >0.9746</td>\n",
       "      <td id=\"T_3fd68_row0_col1\" class=\"data row0 col1\" >0.9951</td>\n",
       "      <td id=\"T_3fd68_row0_col2\" class=\"data row0 col2\" >0.9746</td>\n",
       "      <td id=\"T_3fd68_row0_col3\" class=\"data row0 col3\" >0.9749</td>\n",
       "      <td id=\"T_3fd68_row0_col4\" class=\"data row0 col4\" >0.9742</td>\n",
       "      <td id=\"T_3fd68_row0_col5\" class=\"data row0 col5\" >0.9249</td>\n",
       "      <td id=\"T_3fd68_row0_col6\" class=\"data row0 col6\" >0.9265</td>\n",
       "      <td id=\"T_3fd68_row0_col7\" class=\"data row0 col7\" >0.9482</td>\n",
       "      <td id=\"T_3fd68_row0_col8\" class=\"data row0 col8\" >0.0254</td>\n",
       "      <td id=\"T_3fd68_row0_col9\" class=\"data row0 col9\" >0.8886</td>\n",
       "      <td id=\"T_3fd68_row0_col10\" class=\"data row0 col10\" >0.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3fd68_row1_col0\" class=\"data row1 col0\" >0.9788</td>\n",
       "      <td id=\"T_3fd68_row1_col1\" class=\"data row1 col1\" >0.9958</td>\n",
       "      <td id=\"T_3fd68_row1_col2\" class=\"data row1 col2\" >0.9788</td>\n",
       "      <td id=\"T_3fd68_row1_col3\" class=\"data row1 col3\" >0.9790</td>\n",
       "      <td id=\"T_3fd68_row1_col4\" class=\"data row1 col4\" >0.9785</td>\n",
       "      <td id=\"T_3fd68_row1_col5\" class=\"data row1 col5\" >0.9376</td>\n",
       "      <td id=\"T_3fd68_row1_col6\" class=\"data row1 col6\" >0.9386</td>\n",
       "      <td id=\"T_3fd68_row1_col7\" class=\"data row1 col7\" >0.9569</td>\n",
       "      <td id=\"T_3fd68_row1_col8\" class=\"data row1 col8\" >0.0212</td>\n",
       "      <td id=\"T_3fd68_row1_col9\" class=\"data row1 col9\" >0.9068</td>\n",
       "      <td id=\"T_3fd68_row1_col10\" class=\"data row1 col10\" >0.0718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3fd68_row2_col0\" class=\"data row2 col0\" >0.9741</td>\n",
       "      <td id=\"T_3fd68_row2_col1\" class=\"data row2 col1\" >0.9950</td>\n",
       "      <td id=\"T_3fd68_row2_col2\" class=\"data row2 col2\" >0.9741</td>\n",
       "      <td id=\"T_3fd68_row2_col3\" class=\"data row2 col3\" >0.9744</td>\n",
       "      <td id=\"T_3fd68_row2_col4\" class=\"data row2 col4\" >0.9736</td>\n",
       "      <td id=\"T_3fd68_row2_col5\" class=\"data row2 col5\" >0.9233</td>\n",
       "      <td id=\"T_3fd68_row2_col6\" class=\"data row2 col6\" >0.9249</td>\n",
       "      <td id=\"T_3fd68_row2_col7\" class=\"data row2 col7\" >0.9470</td>\n",
       "      <td id=\"T_3fd68_row2_col8\" class=\"data row2 col8\" >0.0259</td>\n",
       "      <td id=\"T_3fd68_row2_col9\" class=\"data row2 col9\" >0.8863</td>\n",
       "      <td id=\"T_3fd68_row2_col10\" class=\"data row2 col10\" >0.0783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3fd68_row3_col0\" class=\"data row3 col0\" >0.9772</td>\n",
       "      <td id=\"T_3fd68_row3_col1\" class=\"data row3 col1\" >0.9960</td>\n",
       "      <td id=\"T_3fd68_row3_col2\" class=\"data row3 col2\" >0.9772</td>\n",
       "      <td id=\"T_3fd68_row3_col3\" class=\"data row3 col3\" >0.9773</td>\n",
       "      <td id=\"T_3fd68_row3_col4\" class=\"data row3 col4\" >0.9768</td>\n",
       "      <td id=\"T_3fd68_row3_col5\" class=\"data row3 col5\" >0.9328</td>\n",
       "      <td id=\"T_3fd68_row3_col6\" class=\"data row3 col6\" >0.9339</td>\n",
       "      <td id=\"T_3fd68_row3_col7\" class=\"data row3 col7\" >0.9545</td>\n",
       "      <td id=\"T_3fd68_row3_col8\" class=\"data row3 col8\" >0.0228</td>\n",
       "      <td id=\"T_3fd68_row3_col9\" class=\"data row3 col9\" >0.9000</td>\n",
       "      <td id=\"T_3fd68_row3_col10\" class=\"data row3 col10\" >0.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3fd68_row4_col0\" class=\"data row4 col0\" >0.9780</td>\n",
       "      <td id=\"T_3fd68_row4_col1\" class=\"data row4 col1\" >0.9958</td>\n",
       "      <td id=\"T_3fd68_row4_col2\" class=\"data row4 col2\" >0.9780</td>\n",
       "      <td id=\"T_3fd68_row4_col3\" class=\"data row4 col3\" >0.9782</td>\n",
       "      <td id=\"T_3fd68_row4_col4\" class=\"data row4 col4\" >0.9776</td>\n",
       "      <td id=\"T_3fd68_row4_col5\" class=\"data row4 col5\" >0.9351</td>\n",
       "      <td id=\"T_3fd68_row4_col6\" class=\"data row4 col6\" >0.9363</td>\n",
       "      <td id=\"T_3fd68_row4_col7\" class=\"data row4 col7\" >0.9549</td>\n",
       "      <td id=\"T_3fd68_row4_col8\" class=\"data row4 col8\" >0.0220</td>\n",
       "      <td id=\"T_3fd68_row4_col9\" class=\"data row4 col9\" >0.9032</td>\n",
       "      <td id=\"T_3fd68_row4_col10\" class=\"data row4 col10\" >0.0748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3fd68_row5_col0\" class=\"data row5 col0\" >0.9764</td>\n",
       "      <td id=\"T_3fd68_row5_col1\" class=\"data row5 col1\" >0.9954</td>\n",
       "      <td id=\"T_3fd68_row5_col2\" class=\"data row5 col2\" >0.9764</td>\n",
       "      <td id=\"T_3fd68_row5_col3\" class=\"data row5 col3\" >0.9767</td>\n",
       "      <td id=\"T_3fd68_row5_col4\" class=\"data row5 col4\" >0.9760</td>\n",
       "      <td id=\"T_3fd68_row5_col5\" class=\"data row5 col5\" >0.9303</td>\n",
       "      <td id=\"T_3fd68_row5_col6\" class=\"data row5 col6\" >0.9317</td>\n",
       "      <td id=\"T_3fd68_row5_col7\" class=\"data row5 col7\" >0.9515</td>\n",
       "      <td id=\"T_3fd68_row5_col8\" class=\"data row5 col8\" >0.0236</td>\n",
       "      <td id=\"T_3fd68_row5_col9\" class=\"data row5 col9\" >0.8963</td>\n",
       "      <td id=\"T_3fd68_row5_col10\" class=\"data row5 col10\" >0.0760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3fd68_row6_col0\" class=\"data row6 col0\" >0.9746</td>\n",
       "      <td id=\"T_3fd68_row6_col1\" class=\"data row6 col1\" >0.9954</td>\n",
       "      <td id=\"T_3fd68_row6_col2\" class=\"data row6 col2\" >0.9746</td>\n",
       "      <td id=\"T_3fd68_row6_col3\" class=\"data row6 col3\" >0.9747</td>\n",
       "      <td id=\"T_3fd68_row6_col4\" class=\"data row6 col4\" >0.9742</td>\n",
       "      <td id=\"T_3fd68_row6_col5\" class=\"data row6 col5\" >0.9251</td>\n",
       "      <td id=\"T_3fd68_row6_col6\" class=\"data row6 col6\" >0.9264</td>\n",
       "      <td id=\"T_3fd68_row6_col7\" class=\"data row6 col7\" >0.9499</td>\n",
       "      <td id=\"T_3fd68_row6_col8\" class=\"data row6 col8\" >0.0254</td>\n",
       "      <td id=\"T_3fd68_row6_col9\" class=\"data row6 col9\" >0.8891</td>\n",
       "      <td id=\"T_3fd68_row6_col10\" class=\"data row6 col10\" >0.0746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3fd68_row7_col0\" class=\"data row7 col0\" >0.9779</td>\n",
       "      <td id=\"T_3fd68_row7_col1\" class=\"data row7 col1\" >0.9956</td>\n",
       "      <td id=\"T_3fd68_row7_col2\" class=\"data row7 col2\" >0.9779</td>\n",
       "      <td id=\"T_3fd68_row7_col3\" class=\"data row7 col3\" >0.9781</td>\n",
       "      <td id=\"T_3fd68_row7_col4\" class=\"data row7 col4\" >0.9776</td>\n",
       "      <td id=\"T_3fd68_row7_col5\" class=\"data row7 col5\" >0.9350</td>\n",
       "      <td id=\"T_3fd68_row7_col6\" class=\"data row7 col6\" >0.9361</td>\n",
       "      <td id=\"T_3fd68_row7_col7\" class=\"data row7 col7\" >0.9552</td>\n",
       "      <td id=\"T_3fd68_row7_col8\" class=\"data row7 col8\" >0.0221</td>\n",
       "      <td id=\"T_3fd68_row7_col9\" class=\"data row7 col9\" >0.9030</td>\n",
       "      <td id=\"T_3fd68_row7_col10\" class=\"data row7 col10\" >0.0737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3fd68_row8_col0\" class=\"data row8 col0\" >0.9756</td>\n",
       "      <td id=\"T_3fd68_row8_col1\" class=\"data row8 col1\" >0.9948</td>\n",
       "      <td id=\"T_3fd68_row8_col2\" class=\"data row8 col2\" >0.9756</td>\n",
       "      <td id=\"T_3fd68_row8_col3\" class=\"data row8 col3\" >0.9759</td>\n",
       "      <td id=\"T_3fd68_row8_col4\" class=\"data row8 col4\" >0.9753</td>\n",
       "      <td id=\"T_3fd68_row8_col5\" class=\"data row8 col5\" >0.9281</td>\n",
       "      <td id=\"T_3fd68_row8_col6\" class=\"data row8 col6\" >0.9295</td>\n",
       "      <td id=\"T_3fd68_row8_col7\" class=\"data row8 col7\" >0.9506</td>\n",
       "      <td id=\"T_3fd68_row8_col8\" class=\"data row8 col8\" >0.0244</td>\n",
       "      <td id=\"T_3fd68_row8_col9\" class=\"data row8 col9\" >0.8932</td>\n",
       "      <td id=\"T_3fd68_row8_col10\" class=\"data row8 col10\" >0.0793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3fd68_row9_col0\" class=\"data row9 col0\" >0.9761</td>\n",
       "      <td id=\"T_3fd68_row9_col1\" class=\"data row9 col1\" >0.9957</td>\n",
       "      <td id=\"T_3fd68_row9_col2\" class=\"data row9 col2\" >0.9761</td>\n",
       "      <td id=\"T_3fd68_row9_col3\" class=\"data row9 col3\" >0.9762</td>\n",
       "      <td id=\"T_3fd68_row9_col4\" class=\"data row9 col4\" >0.9757</td>\n",
       "      <td id=\"T_3fd68_row9_col5\" class=\"data row9 col5\" >0.9294</td>\n",
       "      <td id=\"T_3fd68_row9_col6\" class=\"data row9 col6\" >0.9306</td>\n",
       "      <td id=\"T_3fd68_row9_col7\" class=\"data row9 col7\" >0.9518</td>\n",
       "      <td id=\"T_3fd68_row9_col8\" class=\"data row9 col8\" >0.0239</td>\n",
       "      <td id=\"T_3fd68_row9_col9\" class=\"data row9 col9\" >0.8951</td>\n",
       "      <td id=\"T_3fd68_row9_col10\" class=\"data row9 col10\" >0.0737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_3fd68_row10_col0\" class=\"data row10 col0\" >0.9763</td>\n",
       "      <td id=\"T_3fd68_row10_col1\" class=\"data row10 col1\" >0.9955</td>\n",
       "      <td id=\"T_3fd68_row10_col2\" class=\"data row10 col2\" >0.9763</td>\n",
       "      <td id=\"T_3fd68_row10_col3\" class=\"data row10 col3\" >0.9765</td>\n",
       "      <td id=\"T_3fd68_row10_col4\" class=\"data row10 col4\" >0.9760</td>\n",
       "      <td id=\"T_3fd68_row10_col5\" class=\"data row10 col5\" >0.9302</td>\n",
       "      <td id=\"T_3fd68_row10_col6\" class=\"data row10 col6\" >0.9314</td>\n",
       "      <td id=\"T_3fd68_row10_col7\" class=\"data row10 col7\" >0.9520</td>\n",
       "      <td id=\"T_3fd68_row10_col8\" class=\"data row10 col8\" >0.0237</td>\n",
       "      <td id=\"T_3fd68_row10_col9\" class=\"data row10 col9\" >0.8962</td>\n",
       "      <td id=\"T_3fd68_row10_col10\" class=\"data row10 col10\" >0.0750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fd68_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_3fd68_row11_col0\" class=\"data row11 col0\" >0.0015</td>\n",
       "      <td id=\"T_3fd68_row11_col1\" class=\"data row11 col1\" >0.0004</td>\n",
       "      <td id=\"T_3fd68_row11_col2\" class=\"data row11 col2\" >0.0015</td>\n",
       "      <td id=\"T_3fd68_row11_col3\" class=\"data row11 col3\" >0.0015</td>\n",
       "      <td id=\"T_3fd68_row11_col4\" class=\"data row11 col4\" >0.0016</td>\n",
       "      <td id=\"T_3fd68_row11_col5\" class=\"data row11 col5\" >0.0046</td>\n",
       "      <td id=\"T_3fd68_row11_col6\" class=\"data row11 col6\" >0.0045</td>\n",
       "      <td id=\"T_3fd68_row11_col7\" class=\"data row11 col7\" >0.0031</td>\n",
       "      <td id=\"T_3fd68_row11_col8\" class=\"data row11 col8\" >0.0015</td>\n",
       "      <td id=\"T_3fd68_row11_col9\" class=\"data row11 col9\" >0.0066</td>\n",
       "      <td id=\"T_3fd68_row11_col10\" class=\"data row11 col10\" >0.0026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27113d12740>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 12:05:01 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "rf = create_model('rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7824407f-4b19-4413-aa1a-12494fe53e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_af97c_row10_col0, #T_af97c_row10_col1, #T_af97c_row10_col2, #T_af97c_row10_col3, #T_af97c_row10_col4, #T_af97c_row10_col5, #T_af97c_row10_col6, #T_af97c_row10_col7, #T_af97c_row10_col8, #T_af97c_row10_col9, #T_af97c_row10_col10 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_af97c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_af97c_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_af97c_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_af97c_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_af97c_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_af97c_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_af97c_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_af97c_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_af97c_level0_col7\" class=\"col_heading level0 col7\" >Balance Acc</th>\n",
       "      <th id=\"T_af97c_level0_col8\" class=\"col_heading level0 col8\" >Hamming Loss</th>\n",
       "      <th id=\"T_af97c_level0_col9\" class=\"col_heading level0 col9\" >Jaccard Score</th>\n",
       "      <th id=\"T_af97c_level0_col10\" class=\"col_heading level0 col10\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_af97c_row0_col0\" class=\"data row0 col0\" >0.9298</td>\n",
       "      <td id=\"T_af97c_row0_col1\" class=\"data row0 col1\" >0.9630</td>\n",
       "      <td id=\"T_af97c_row0_col2\" class=\"data row0 col2\" >0.9298</td>\n",
       "      <td id=\"T_af97c_row0_col3\" class=\"data row0 col3\" >0.9307</td>\n",
       "      <td id=\"T_af97c_row0_col4\" class=\"data row0 col4\" >0.9264</td>\n",
       "      <td id=\"T_af97c_row0_col5\" class=\"data row0 col5\" >0.7811</td>\n",
       "      <td id=\"T_af97c_row0_col6\" class=\"data row0 col6\" >0.7912</td>\n",
       "      <td id=\"T_af97c_row0_col7\" class=\"data row0 col7\" >0.8590</td>\n",
       "      <td id=\"T_af97c_row0_col8\" class=\"data row0 col8\" >0.0702</td>\n",
       "      <td id=\"T_af97c_row0_col9\" class=\"data row0 col9\" >0.7008</td>\n",
       "      <td id=\"T_af97c_row0_col10\" class=\"data row0 col10\" >0.2332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_af97c_row1_col0\" class=\"data row1 col0\" >0.9382</td>\n",
       "      <td id=\"T_af97c_row1_col1\" class=\"data row1 col1\" >0.9656</td>\n",
       "      <td id=\"T_af97c_row1_col2\" class=\"data row1 col2\" >0.9382</td>\n",
       "      <td id=\"T_af97c_row1_col3\" class=\"data row1 col3\" >0.9394</td>\n",
       "      <td id=\"T_af97c_row1_col4\" class=\"data row1 col4\" >0.9356</td>\n",
       "      <td id=\"T_af97c_row1_col5\" class=\"data row1 col5\" >0.8089</td>\n",
       "      <td id=\"T_af97c_row1_col6\" class=\"data row1 col6\" >0.8175</td>\n",
       "      <td id=\"T_af97c_row1_col7\" class=\"data row1 col7\" >0.8746</td>\n",
       "      <td id=\"T_af97c_row1_col8\" class=\"data row1 col8\" >0.0618</td>\n",
       "      <td id=\"T_af97c_row1_col9\" class=\"data row1 col9\" >0.7345</td>\n",
       "      <td id=\"T_af97c_row1_col10\" class=\"data row1 col10\" >0.2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_af97c_row2_col0\" class=\"data row2 col0\" >0.9307</td>\n",
       "      <td id=\"T_af97c_row2_col1\" class=\"data row2 col1\" >0.9611</td>\n",
       "      <td id=\"T_af97c_row2_col2\" class=\"data row2 col2\" >0.9307</td>\n",
       "      <td id=\"T_af97c_row2_col3\" class=\"data row2 col3\" >0.9314</td>\n",
       "      <td id=\"T_af97c_row2_col4\" class=\"data row2 col4\" >0.9275</td>\n",
       "      <td id=\"T_af97c_row2_col5\" class=\"data row2 col5\" >0.7848</td>\n",
       "      <td id=\"T_af97c_row2_col6\" class=\"data row2 col6\" >0.7940</td>\n",
       "      <td id=\"T_af97c_row2_col7\" class=\"data row2 col7\" >0.8622</td>\n",
       "      <td id=\"T_af97c_row2_col8\" class=\"data row2 col8\" >0.0693</td>\n",
       "      <td id=\"T_af97c_row2_col9\" class=\"data row2 col9\" >0.7056</td>\n",
       "      <td id=\"T_af97c_row2_col10\" class=\"data row2 col10\" >0.2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_af97c_row3_col0\" class=\"data row3 col0\" >0.9354</td>\n",
       "      <td id=\"T_af97c_row3_col1\" class=\"data row3 col1\" >0.9660</td>\n",
       "      <td id=\"T_af97c_row3_col2\" class=\"data row3 col2\" >0.9354</td>\n",
       "      <td id=\"T_af97c_row3_col3\" class=\"data row3 col3\" >0.9363</td>\n",
       "      <td id=\"T_af97c_row3_col4\" class=\"data row3 col4\" >0.9326</td>\n",
       "      <td id=\"T_af97c_row3_col5\" class=\"data row3 col5\" >0.7999</td>\n",
       "      <td id=\"T_af97c_row3_col6\" class=\"data row3 col6\" >0.8087</td>\n",
       "      <td id=\"T_af97c_row3_col7\" class=\"data row3 col7\" >0.8700</td>\n",
       "      <td id=\"T_af97c_row3_col8\" class=\"data row3 col8\" >0.0646</td>\n",
       "      <td id=\"T_af97c_row3_col9\" class=\"data row3 col9\" >0.7236</td>\n",
       "      <td id=\"T_af97c_row3_col10\" class=\"data row3 col10\" >0.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_af97c_row4_col0\" class=\"data row4 col0\" >0.9357</td>\n",
       "      <td id=\"T_af97c_row4_col1\" class=\"data row4 col1\" >0.9656</td>\n",
       "      <td id=\"T_af97c_row4_col2\" class=\"data row4 col2\" >0.9357</td>\n",
       "      <td id=\"T_af97c_row4_col3\" class=\"data row4 col3\" >0.9367</td>\n",
       "      <td id=\"T_af97c_row4_col4\" class=\"data row4 col4\" >0.9329</td>\n",
       "      <td id=\"T_af97c_row4_col5\" class=\"data row4 col5\" >0.8008</td>\n",
       "      <td id=\"T_af97c_row4_col6\" class=\"data row4 col6\" >0.8096</td>\n",
       "      <td id=\"T_af97c_row4_col7\" class=\"data row4 col7\" >0.8704</td>\n",
       "      <td id=\"T_af97c_row4_col8\" class=\"data row4 col8\" >0.0643</td>\n",
       "      <td id=\"T_af97c_row4_col9\" class=\"data row4 col9\" >0.7246</td>\n",
       "      <td id=\"T_af97c_row4_col10\" class=\"data row4 col10\" >0.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_af97c_row5_col0\" class=\"data row5 col0\" >0.9323</td>\n",
       "      <td id=\"T_af97c_row5_col1\" class=\"data row5 col1\" >0.9647</td>\n",
       "      <td id=\"T_af97c_row5_col2\" class=\"data row5 col2\" >0.9323</td>\n",
       "      <td id=\"T_af97c_row5_col3\" class=\"data row5 col3\" >0.9330</td>\n",
       "      <td id=\"T_af97c_row5_col4\" class=\"data row5 col4\" >0.9292</td>\n",
       "      <td id=\"T_af97c_row5_col5\" class=\"data row5 col5\" >0.7898</td>\n",
       "      <td id=\"T_af97c_row5_col6\" class=\"data row5 col6\" >0.7989</td>\n",
       "      <td id=\"T_af97c_row5_col7\" class=\"data row5 col7\" >0.8648</td>\n",
       "      <td id=\"T_af97c_row5_col8\" class=\"data row5 col8\" >0.0677</td>\n",
       "      <td id=\"T_af97c_row5_col9\" class=\"data row5 col9\" >0.7115</td>\n",
       "      <td id=\"T_af97c_row5_col10\" class=\"data row5 col10\" >0.2264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_af97c_row6_col0\" class=\"data row6 col0\" >0.9345</td>\n",
       "      <td id=\"T_af97c_row6_col1\" class=\"data row6 col1\" >0.9663</td>\n",
       "      <td id=\"T_af97c_row6_col2\" class=\"data row6 col2\" >0.9345</td>\n",
       "      <td id=\"T_af97c_row6_col3\" class=\"data row6 col3\" >0.9355</td>\n",
       "      <td id=\"T_af97c_row6_col4\" class=\"data row6 col4\" >0.9315</td>\n",
       "      <td id=\"T_af97c_row6_col5\" class=\"data row6 col5\" >0.7966</td>\n",
       "      <td id=\"T_af97c_row6_col6\" class=\"data row6 col6\" >0.8058</td>\n",
       "      <td id=\"T_af97c_row6_col7\" class=\"data row6 col7\" >0.8679</td>\n",
       "      <td id=\"T_af97c_row6_col8\" class=\"data row6 col8\" >0.0655</td>\n",
       "      <td id=\"T_af97c_row6_col9\" class=\"data row6 col9\" >0.7195</td>\n",
       "      <td id=\"T_af97c_row6_col10\" class=\"data row6 col10\" >0.2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_af97c_row7_col0\" class=\"data row7 col0\" >0.9341</td>\n",
       "      <td id=\"T_af97c_row7_col1\" class=\"data row7 col1\" >0.9635</td>\n",
       "      <td id=\"T_af97c_row7_col2\" class=\"data row7 col2\" >0.9341</td>\n",
       "      <td id=\"T_af97c_row7_col3\" class=\"data row7 col3\" >0.9349</td>\n",
       "      <td id=\"T_af97c_row7_col4\" class=\"data row7 col4\" >0.9312</td>\n",
       "      <td id=\"T_af97c_row7_col5\" class=\"data row7 col5\" >0.7957</td>\n",
       "      <td id=\"T_af97c_row7_col6\" class=\"data row7 col6\" >0.8045</td>\n",
       "      <td id=\"T_af97c_row7_col7\" class=\"data row7 col7\" >0.8680</td>\n",
       "      <td id=\"T_af97c_row7_col8\" class=\"data row7 col8\" >0.0659</td>\n",
       "      <td id=\"T_af97c_row7_col9\" class=\"data row7 col9\" >0.7186</td>\n",
       "      <td id=\"T_af97c_row7_col10\" class=\"data row7 col10\" >0.2274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_af97c_row8_col0\" class=\"data row8 col0\" >0.9329</td>\n",
       "      <td id=\"T_af97c_row8_col1\" class=\"data row8 col1\" >0.9644</td>\n",
       "      <td id=\"T_af97c_row8_col2\" class=\"data row8 col2\" >0.9329</td>\n",
       "      <td id=\"T_af97c_row8_col3\" class=\"data row8 col3\" >0.9341</td>\n",
       "      <td id=\"T_af97c_row8_col4\" class=\"data row8 col4\" >0.9297</td>\n",
       "      <td id=\"T_af97c_row8_col5\" class=\"data row8 col5\" >0.7910</td>\n",
       "      <td id=\"T_af97c_row8_col6\" class=\"data row8 col6\" >0.8010</td>\n",
       "      <td id=\"T_af97c_row8_col7\" class=\"data row8 col7\" >0.8640</td>\n",
       "      <td id=\"T_af97c_row8_col8\" class=\"data row8 col8\" >0.0671</td>\n",
       "      <td id=\"T_af97c_row8_col9\" class=\"data row8 col9\" >0.7125</td>\n",
       "      <td id=\"T_af97c_row8_col10\" class=\"data row8 col10\" >0.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_af97c_row9_col0\" class=\"data row9 col0\" >0.9312</td>\n",
       "      <td id=\"T_af97c_row9_col1\" class=\"data row9 col1\" >0.9634</td>\n",
       "      <td id=\"T_af97c_row9_col2\" class=\"data row9 col2\" >0.9312</td>\n",
       "      <td id=\"T_af97c_row9_col3\" class=\"data row9 col3\" >0.9320</td>\n",
       "      <td id=\"T_af97c_row9_col4\" class=\"data row9 col4\" >0.9280</td>\n",
       "      <td id=\"T_af97c_row9_col5\" class=\"data row9 col5\" >0.7861</td>\n",
       "      <td id=\"T_af97c_row9_col6\" class=\"data row9 col6\" >0.7955</td>\n",
       "      <td id=\"T_af97c_row9_col7\" class=\"data row9 col7\" >0.8625</td>\n",
       "      <td id=\"T_af97c_row9_col8\" class=\"data row9 col8\" >0.0688</td>\n",
       "      <td id=\"T_af97c_row9_col9\" class=\"data row9 col9\" >0.7069</td>\n",
       "      <td id=\"T_af97c_row9_col10\" class=\"data row9 col10\" >0.2279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_af97c_row10_col0\" class=\"data row10 col0\" >0.9335</td>\n",
       "      <td id=\"T_af97c_row10_col1\" class=\"data row10 col1\" >0.9643</td>\n",
       "      <td id=\"T_af97c_row10_col2\" class=\"data row10 col2\" >0.9335</td>\n",
       "      <td id=\"T_af97c_row10_col3\" class=\"data row10 col3\" >0.9344</td>\n",
       "      <td id=\"T_af97c_row10_col4\" class=\"data row10 col4\" >0.9305</td>\n",
       "      <td id=\"T_af97c_row10_col5\" class=\"data row10 col5\" >0.7935</td>\n",
       "      <td id=\"T_af97c_row10_col6\" class=\"data row10 col6\" >0.8027</td>\n",
       "      <td id=\"T_af97c_row10_col7\" class=\"data row10 col7\" >0.8663</td>\n",
       "      <td id=\"T_af97c_row10_col8\" class=\"data row10 col8\" >0.0665</td>\n",
       "      <td id=\"T_af97c_row10_col9\" class=\"data row10 col9\" >0.7158</td>\n",
       "      <td id=\"T_af97c_row10_col10\" class=\"data row10 col10\" >0.2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_af97c_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_af97c_row11_col0\" class=\"data row11 col0\" >0.0025</td>\n",
       "      <td id=\"T_af97c_row11_col1\" class=\"data row11 col1\" >0.0015</td>\n",
       "      <td id=\"T_af97c_row11_col2\" class=\"data row11 col2\" >0.0025</td>\n",
       "      <td id=\"T_af97c_row11_col3\" class=\"data row11 col3\" >0.0026</td>\n",
       "      <td id=\"T_af97c_row11_col4\" class=\"data row11 col4\" >0.0027</td>\n",
       "      <td id=\"T_af97c_row11_col5\" class=\"data row11 col5\" >0.0081</td>\n",
       "      <td id=\"T_af97c_row11_col6\" class=\"data row11 col6\" >0.0077</td>\n",
       "      <td id=\"T_af97c_row11_col7\" class=\"data row11 col7\" >0.0044</td>\n",
       "      <td id=\"T_af97c_row11_col8\" class=\"data row11 col8\" >0.0025</td>\n",
       "      <td id=\"T_af97c_row11_col9\" class=\"data row11 col9\" >0.0097</td>\n",
       "      <td id=\"T_af97c_row11_col10\" class=\"data row11 col10\" >0.0026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2710804fcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 13:00:12 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "rf_tuned_model, rf_tuner = tune_model(rf, search_library = 'optuna', return_tuner=True, n_iter=num_iterations_tuning, optimize=optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae1bcd83-0a9d-430d-b4eb-1068f65eebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='sqrt',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       monotonic_cst=None, n_estimators=100, n_jobs=-1,\n",
      "                       oob_score=False, random_state=1768, verbose=0,\n",
      "                       warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(rf_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f967dc6c-cc44-4286-a8c2-2902754955e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_04abf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_04abf_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_04abf_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_04abf_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_04abf_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_04abf_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_04abf_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_04abf_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_04abf_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_04abf_level0_col8\" class=\"col_heading level0 col8\" >Balance Acc</th>\n",
       "      <th id=\"T_04abf_level0_col9\" class=\"col_heading level0 col9\" >Hamming Loss</th>\n",
       "      <th id=\"T_04abf_level0_col10\" class=\"col_heading level0 col10\" >Jaccard Score</th>\n",
       "      <th id=\"T_04abf_level0_col11\" class=\"col_heading level0 col11\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_04abf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_04abf_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_04abf_row0_col1\" class=\"data row0 col1\" >0.9785</td>\n",
       "      <td id=\"T_04abf_row0_col2\" class=\"data row0 col2\" >0.9961</td>\n",
       "      <td id=\"T_04abf_row0_col3\" class=\"data row0 col3\" >0.9785</td>\n",
       "      <td id=\"T_04abf_row0_col4\" class=\"data row0 col4\" >0.9786</td>\n",
       "      <td id=\"T_04abf_row0_col5\" class=\"data row0 col5\" >0.9782</td>\n",
       "      <td id=\"T_04abf_row0_col6\" class=\"data row0 col6\" >0.9369</td>\n",
       "      <td id=\"T_04abf_row0_col7\" class=\"data row0 col7\" >0.9379</td>\n",
       "      <td id=\"T_04abf_row0_col8\" class=\"data row0 col8\" >0.9569</td>\n",
       "      <td id=\"T_04abf_row0_col9\" class=\"data row0 col9\" >0.0215</td>\n",
       "      <td id=\"T_04abf_row0_col10\" class=\"data row0 col10\" >0.9059</td>\n",
       "      <td id=\"T_04abf_row0_col11\" class=\"data row0 col11\" >0.0725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x271157443d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_rf = predict_model(rf_tuned_model, data = features_df_testing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50123496-3039-4e57-9520-b92cc6865e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3795d2ef8343ec835ff27e2bf568a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a31be2f-b8c2-46e9-92bc-4ba605a72cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meanWavelet</td>\n",
       "      <td>0.113125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>medianFreq</td>\n",
       "      <td>0.080381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>energyWavelet</td>\n",
       "      <td>0.071475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meanFreq</td>\n",
       "      <td>0.057107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>0.054538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spectral_flatness</td>\n",
       "      <td>0.049845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bandwidth</td>\n",
       "      <td>0.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rms</td>\n",
       "      <td>0.045366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>std</td>\n",
       "      <td>0.043982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meanSpectrogram</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ptp</td>\n",
       "      <td>0.038755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entropyWavelet</td>\n",
       "      <td>0.037427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.032731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>skewness</td>\n",
       "      <td>0.031557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>clearance</td>\n",
       "      <td>0.028709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spectral_skewness</td>\n",
       "      <td>0.028315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>varWavelet</td>\n",
       "      <td>0.027398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spectral_kurtosis</td>\n",
       "      <td>0.025669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entropy</td>\n",
       "      <td>0.023351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>0.021572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>shape</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>impulse</td>\n",
       "      <td>0.017669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>entropySpectrogram</td>\n",
       "      <td>0.016658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.016470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>crest</td>\n",
       "      <td>0.015136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>energySpectrogram</td>\n",
       "      <td>0.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>varSpectrogram</td>\n",
       "      <td>0.007570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features  importance\n",
       "0          meanWavelet    0.113125\n",
       "1           medianFreq    0.080381\n",
       "2        energyWavelet    0.071475\n",
       "3             meanFreq    0.057107\n",
       "4     spectral_entropy    0.054538\n",
       "5    spectral_flatness    0.049845\n",
       "6            bandwidth    0.046300\n",
       "7                  rms    0.045366\n",
       "8                  std    0.043982\n",
       "9      meanSpectrogram    0.040018\n",
       "10                 ptp    0.038755\n",
       "11      entropyWavelet    0.037427\n",
       "12              energy    0.032731\n",
       "13            skewness    0.031557\n",
       "14           clearance    0.028709\n",
       "15   spectral_skewness    0.028315\n",
       "16          varWavelet    0.027398\n",
       "17   spectral_kurtosis    0.025669\n",
       "18             entropy    0.023351\n",
       "19            kurtosis    0.021572\n",
       "20               shape    0.020200\n",
       "21             impulse    0.017669\n",
       "22  entropySpectrogram    0.016658\n",
       "23                mean    0.016470\n",
       "24               crest    0.015136\n",
       "25   energySpectrogram    0.008675\n",
       "26      varSpectrogram    0.007570"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_top_features = get_feature_importance_df(rf, features_df_training_normalized)\n",
    "rf_top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3e8fcdb-1e5a-4ef1-9c0f-538581f3f210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_88d52\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88d52_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_88d52_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_88d52_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_88d52_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_88d52_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_88d52_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_88d52_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_88d52_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_88d52_level0_col8\" class=\"col_heading level0 col8\" >Balance Acc</th>\n",
       "      <th id=\"T_88d52_level0_col9\" class=\"col_heading level0 col9\" >Hamming Loss</th>\n",
       "      <th id=\"T_88d52_level0_col10\" class=\"col_heading level0 col10\" >Jaccard Score</th>\n",
       "      <th id=\"T_88d52_level0_col11\" class=\"col_heading level0 col11\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88d52_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88d52_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_88d52_row0_col1\" class=\"data row0 col1\" >0.9785</td>\n",
       "      <td id=\"T_88d52_row0_col2\" class=\"data row0 col2\" >0.9961</td>\n",
       "      <td id=\"T_88d52_row0_col3\" class=\"data row0 col3\" >0.9785</td>\n",
       "      <td id=\"T_88d52_row0_col4\" class=\"data row0 col4\" >0.9786</td>\n",
       "      <td id=\"T_88d52_row0_col5\" class=\"data row0 col5\" >0.9782</td>\n",
       "      <td id=\"T_88d52_row0_col6\" class=\"data row0 col6\" >0.9369</td>\n",
       "      <td id=\"T_88d52_row0_col7\" class=\"data row0 col7\" >0.9379</td>\n",
       "      <td id=\"T_88d52_row0_col8\" class=\"data row0 col8\" >0.9569</td>\n",
       "      <td id=\"T_88d52_row0_col9\" class=\"data row0 col9\" >0.0215</td>\n",
       "      <td id=\"T_88d52_row0_col10\" class=\"data row0 col10\" >0.9059</td>\n",
       "      <td id=\"T_88d52_row0_col11\" class=\"data row0 col11\" >0.0725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2710cee6770>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_rf = predict_model(rf, data = features_df_testing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc2f4d83-272f-4b78-a3fa-f351cddf7020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>rms</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>ptp</th>\n",
       "      <th>crest</th>\n",
       "      <th>impulse</th>\n",
       "      <th>clearance</th>\n",
       "      <th>shape</th>\n",
       "      <th>...</th>\n",
       "      <th>varWavelet</th>\n",
       "      <th>entropyWavelet</th>\n",
       "      <th>energyWavelet</th>\n",
       "      <th>meanSpectrogram</th>\n",
       "      <th>varSpectrogram</th>\n",
       "      <th>entropySpectrogram</th>\n",
       "      <th>energySpectrogram</th>\n",
       "      <th>Label</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258524</th>\n",
       "      <td>0.036464</td>\n",
       "      <td>-0.602333</td>\n",
       "      <td>-0.637307</td>\n",
       "      <td>-0.407115</td>\n",
       "      <td>0.131417</td>\n",
       "      <td>-0.806982</td>\n",
       "      <td>0.949561</td>\n",
       "      <td>0.854643</td>\n",
       "      <td>-1.057003</td>\n",
       "      <td>1.018010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276646</td>\n",
       "      <td>0.164046</td>\n",
       "      <td>-0.302923</td>\n",
       "      <td>-0.242255</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207745</th>\n",
       "      <td>0.036146</td>\n",
       "      <td>-0.054912</td>\n",
       "      <td>-0.037686</td>\n",
       "      <td>-0.206209</td>\n",
       "      <td>-0.191703</td>\n",
       "      <td>-0.166550</td>\n",
       "      <td>-0.817718</td>\n",
       "      <td>-0.706493</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-0.686273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178280</td>\n",
       "      <td>0.195415</td>\n",
       "      <td>-0.197872</td>\n",
       "      <td>-0.181161</td>\n",
       "      <td>-0.119248</td>\n",
       "      <td>-0.154350</td>\n",
       "      <td>-0.119369</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255723</th>\n",
       "      <td>0.035643</td>\n",
       "      <td>-0.187058</td>\n",
       "      <td>-0.182074</td>\n",
       "      <td>0.147473</td>\n",
       "      <td>-0.086570</td>\n",
       "      <td>-0.243538</td>\n",
       "      <td>-0.400318</td>\n",
       "      <td>-0.316864</td>\n",
       "      <td>-0.104728</td>\n",
       "      <td>0.027741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222601</td>\n",
       "      <td>0.196681</td>\n",
       "      <td>-0.240971</td>\n",
       "      <td>-0.205668</td>\n",
       "      <td>-0.119463</td>\n",
       "      <td>-0.155770</td>\n",
       "      <td>-0.119586</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202856</th>\n",
       "      <td>0.030382</td>\n",
       "      <td>-0.143407</td>\n",
       "      <td>-0.134430</td>\n",
       "      <td>0.103309</td>\n",
       "      <td>-0.026063</td>\n",
       "      <td>-0.108780</td>\n",
       "      <td>-0.042167</td>\n",
       "      <td>-0.014115</td>\n",
       "      <td>0.139272</td>\n",
       "      <td>0.306646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.212232</td>\n",
       "      <td>0.201269</td>\n",
       "      <td>-0.227989</td>\n",
       "      <td>-0.197034</td>\n",
       "      <td>-0.119436</td>\n",
       "      <td>-0.155564</td>\n",
       "      <td>-0.119558</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205260</th>\n",
       "      <td>0.032710</td>\n",
       "      <td>-0.431614</td>\n",
       "      <td>-0.449423</td>\n",
       "      <td>0.020514</td>\n",
       "      <td>0.119952</td>\n",
       "      <td>-0.493347</td>\n",
       "      <td>0.822264</td>\n",
       "      <td>0.709045</td>\n",
       "      <td>-0.204833</td>\n",
       "      <td>0.761597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265597</td>\n",
       "      <td>0.174436</td>\n",
       "      <td>-0.290946</td>\n",
       "      <td>-0.234815</td>\n",
       "      <td>-0.119507</td>\n",
       "      <td>-0.156146</td>\n",
       "      <td>-0.119633</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259068</th>\n",
       "      <td>0.034660</td>\n",
       "      <td>-0.417189</td>\n",
       "      <td>-0.433603</td>\n",
       "      <td>0.038210</td>\n",
       "      <td>0.128827</td>\n",
       "      <td>-0.489982</td>\n",
       "      <td>0.490157</td>\n",
       "      <td>0.524692</td>\n",
       "      <td>-0.231692</td>\n",
       "      <td>1.146661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263326</td>\n",
       "      <td>0.174694</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.233749</td>\n",
       "      <td>-0.119504</td>\n",
       "      <td>-0.156123</td>\n",
       "      <td>-0.119630</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240598</th>\n",
       "      <td>0.036515</td>\n",
       "      <td>-0.391927</td>\n",
       "      <td>-0.405950</td>\n",
       "      <td>0.015472</td>\n",
       "      <td>0.119186</td>\n",
       "      <td>-0.474286</td>\n",
       "      <td>0.223008</td>\n",
       "      <td>0.354228</td>\n",
       "      <td>-0.224722</td>\n",
       "      <td>1.366387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.259031</td>\n",
       "      <td>0.175550</td>\n",
       "      <td>-0.285444</td>\n",
       "      <td>-0.231017</td>\n",
       "      <td>-0.119498</td>\n",
       "      <td>-0.156074</td>\n",
       "      <td>-0.119623</td>\n",
       "      <td>damaged</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262404</th>\n",
       "      <td>0.025626</td>\n",
       "      <td>0.131088</td>\n",
       "      <td>0.165457</td>\n",
       "      <td>0.391404</td>\n",
       "      <td>-0.025749</td>\n",
       "      <td>0.371228</td>\n",
       "      <td>-0.040433</td>\n",
       "      <td>-0.019632</td>\n",
       "      <td>0.566100</td>\n",
       "      <td>0.261995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.196419</td>\n",
       "      <td>-0.118451</td>\n",
       "      <td>-0.138517</td>\n",
       "      <td>-0.118858</td>\n",
       "      <td>-0.151940</td>\n",
       "      <td>-0.118968</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206916</th>\n",
       "      <td>0.041697</td>\n",
       "      <td>-0.158916</td>\n",
       "      <td>-0.151280</td>\n",
       "      <td>0.231444</td>\n",
       "      <td>-0.101904</td>\n",
       "      <td>-0.181929</td>\n",
       "      <td>-0.347732</td>\n",
       "      <td>-0.291088</td>\n",
       "      <td>-0.043652</td>\n",
       "      <td>-0.061274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216526</td>\n",
       "      <td>0.200570</td>\n",
       "      <td>-0.232714</td>\n",
       "      <td>-0.198674</td>\n",
       "      <td>-0.119441</td>\n",
       "      <td>-0.155599</td>\n",
       "      <td>-0.119563</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200497</th>\n",
       "      <td>0.033159</td>\n",
       "      <td>-0.386435</td>\n",
       "      <td>-0.400006</td>\n",
       "      <td>0.047990</td>\n",
       "      <td>0.064846</td>\n",
       "      <td>-0.452461</td>\n",
       "      <td>0.219733</td>\n",
       "      <td>0.307008</td>\n",
       "      <td>-0.226820</td>\n",
       "      <td>1.091975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258714</td>\n",
       "      <td>0.176503</td>\n",
       "      <td>-0.284612</td>\n",
       "      <td>-0.231184</td>\n",
       "      <td>-0.119501</td>\n",
       "      <td>-0.156092</td>\n",
       "      <td>-0.119626</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1327 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       rms       std  skewness  kurtosis       ptp     crest  \\\n",
       "258524  0.036464 -0.602333 -0.637307 -0.407115  0.131417 -0.806982  0.949561   \n",
       "207745  0.036146 -0.054912 -0.037686 -0.206209 -0.191703 -0.166550 -0.817718   \n",
       "255723  0.035643 -0.187058 -0.182074  0.147473 -0.086570 -0.243538 -0.400318   \n",
       "202856  0.030382 -0.143407 -0.134430  0.103309 -0.026063 -0.108780 -0.042167   \n",
       "205260  0.032710 -0.431614 -0.449423  0.020514  0.119952 -0.493347  0.822264   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "259068  0.034660 -0.417189 -0.433603  0.038210  0.128827 -0.489982  0.490157   \n",
       "240598  0.036515 -0.391927 -0.405950  0.015472  0.119186 -0.474286  0.223008   \n",
       "262404  0.025626  0.131088  0.165457  0.391404 -0.025749  0.371228 -0.040433   \n",
       "206916  0.041697 -0.158916 -0.151280  0.231444 -0.101904 -0.181929 -0.347732   \n",
       "200497  0.033159 -0.386435 -0.400006  0.047990  0.064846 -0.452461  0.219733   \n",
       "\n",
       "         impulse  clearance     shape  ...  varWavelet  entropyWavelet  \\\n",
       "258524  0.854643  -1.057003  1.018010  ...   -0.276646        0.164046   \n",
       "207745 -0.706493  -0.152971 -0.686273  ...   -0.178280        0.195415   \n",
       "255723 -0.316864  -0.104728  0.027741  ...   -0.222601        0.196681   \n",
       "202856 -0.014115   0.139272  0.306646  ...   -0.212232        0.201269   \n",
       "205260  0.709045  -0.204833  0.761597  ...   -0.265597        0.174436   \n",
       "...          ...        ...       ...  ...         ...             ...   \n",
       "259068  0.524692  -0.231692  1.146661  ...   -0.263326        0.174694   \n",
       "240598  0.354228  -0.224722  1.366387  ...   -0.259031        0.175550   \n",
       "262404 -0.019632   0.566100  0.261995  ...   -0.113738        0.196419   \n",
       "206916 -0.291088  -0.043652 -0.061274  ...   -0.216526        0.200570   \n",
       "200497  0.307008  -0.226820  1.091975  ...   -0.258714        0.176503   \n",
       "\n",
       "        energyWavelet  meanSpectrogram  varSpectrogram  entropySpectrogram  \\\n",
       "258524      -0.302923        -0.242255       -0.119511           -0.156183   \n",
       "207745      -0.197872        -0.181161       -0.119248           -0.154350   \n",
       "255723      -0.240971        -0.205668       -0.119463           -0.155770   \n",
       "202856      -0.227989        -0.197034       -0.119436           -0.155564   \n",
       "205260      -0.290946        -0.234815       -0.119507           -0.156146   \n",
       "...               ...              ...             ...                 ...   \n",
       "259068      -0.289062        -0.233749       -0.119504           -0.156123   \n",
       "240598      -0.285444        -0.231017       -0.119498           -0.156074   \n",
       "262404      -0.118451        -0.138517       -0.118858           -0.151940   \n",
       "206916      -0.232714        -0.198674       -0.119441           -0.155599   \n",
       "200497      -0.284612        -0.231184       -0.119501           -0.156092   \n",
       "\n",
       "        energySpectrogram    Label  prediction_label  prediction_score  \n",
       "258524          -0.119637  healthy           damaged              0.78  \n",
       "207745          -0.119369  healthy           damaged              0.75  \n",
       "255723          -0.119586  healthy           damaged              0.63  \n",
       "202856          -0.119558  healthy           damaged              0.90  \n",
       "205260          -0.119633  healthy           damaged              0.87  \n",
       "...                   ...      ...               ...               ...  \n",
       "259068          -0.119630  healthy           damaged              0.63  \n",
       "240598          -0.119623  damaged           healthy              0.51  \n",
       "262404          -0.118968  healthy           damaged              0.69  \n",
       "206916          -0.119563  healthy           damaged              0.90  \n",
       "200497          -0.119626  healthy           damaged              0.55  \n",
       "\n",
       "[1327 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_incorrect_predictions(predictions_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdc359a-4de6-48f8-a573-41c6d084a7ca",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "811f8d9f-491d-4f38-9ce9-e06344b3ac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_27886_row10_col0, #T_27886_row10_col1, #T_27886_row10_col2, #T_27886_row10_col3, #T_27886_row10_col4, #T_27886_row10_col5, #T_27886_row10_col6, #T_27886_row10_col7, #T_27886_row10_col8, #T_27886_row10_col9, #T_27886_row10_col10 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_27886\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_27886_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_27886_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_27886_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_27886_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_27886_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_27886_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_27886_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_27886_level0_col7\" class=\"col_heading level0 col7\" >Balance Acc</th>\n",
       "      <th id=\"T_27886_level0_col8\" class=\"col_heading level0 col8\" >Hamming Loss</th>\n",
       "      <th id=\"T_27886_level0_col9\" class=\"col_heading level0 col9\" >Jaccard Score</th>\n",
       "      <th id=\"T_27886_level0_col10\" class=\"col_heading level0 col10\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_27886_row0_col0\" class=\"data row0 col0\" >0.8780</td>\n",
       "      <td id=\"T_27886_row0_col1\" class=\"data row0 col1\" >0.8718</td>\n",
       "      <td id=\"T_27886_row0_col2\" class=\"data row0 col2\" >0.8780</td>\n",
       "      <td id=\"T_27886_row0_col3\" class=\"data row0 col3\" >0.8755</td>\n",
       "      <td id=\"T_27886_row0_col4\" class=\"data row0 col4\" >0.8682</td>\n",
       "      <td id=\"T_27886_row0_col5\" class=\"data row0 col5\" >0.6015</td>\n",
       "      <td id=\"T_27886_row0_col6\" class=\"data row0 col6\" >0.6219</td>\n",
       "      <td id=\"T_27886_row0_col7\" class=\"data row0 col7\" >0.7639</td>\n",
       "      <td id=\"T_27886_row0_col8\" class=\"data row0 col8\" >0.1220</td>\n",
       "      <td id=\"T_27886_row0_col9\" class=\"data row0 col9\" >0.5066</td>\n",
       "      <td id=\"T_27886_row0_col10\" class=\"data row0 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_27886_row1_col0\" class=\"data row1 col0\" >0.8845</td>\n",
       "      <td id=\"T_27886_row1_col1\" class=\"data row1 col1\" >0.8815</td>\n",
       "      <td id=\"T_27886_row1_col2\" class=\"data row1 col2\" >0.8845</td>\n",
       "      <td id=\"T_27886_row1_col3\" class=\"data row1 col3\" >0.8802</td>\n",
       "      <td id=\"T_27886_row1_col4\" class=\"data row1 col4\" >0.8802</td>\n",
       "      <td id=\"T_27886_row1_col5\" class=\"data row1 col5\" >0.6459</td>\n",
       "      <td id=\"T_27886_row1_col6\" class=\"data row1 col6\" >0.6512</td>\n",
       "      <td id=\"T_27886_row1_col7\" class=\"data row1 col7\" >0.8018</td>\n",
       "      <td id=\"T_27886_row1_col8\" class=\"data row1 col8\" >0.1155</td>\n",
       "      <td id=\"T_27886_row1_col9\" class=\"data row1 col9\" >0.5595</td>\n",
       "      <td id=\"T_27886_row1_col10\" class=\"data row1 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_27886_row2_col0\" class=\"data row2 col0\" >0.8820</td>\n",
       "      <td id=\"T_27886_row2_col1\" class=\"data row2 col1\" >0.8722</td>\n",
       "      <td id=\"T_27886_row2_col2\" class=\"data row2 col2\" >0.8820</td>\n",
       "      <td id=\"T_27886_row2_col3\" class=\"data row2 col3\" >0.8781</td>\n",
       "      <td id=\"T_27886_row2_col4\" class=\"data row2 col4\" >0.8747</td>\n",
       "      <td id=\"T_27886_row2_col5\" class=\"data row2 col5\" >0.6245</td>\n",
       "      <td id=\"T_27886_row2_col6\" class=\"data row2 col6\" >0.6375</td>\n",
       "      <td id=\"T_27886_row2_col7\" class=\"data row2 col7\" >0.7813</td>\n",
       "      <td id=\"T_27886_row2_col8\" class=\"data row2 col8\" >0.1180</td>\n",
       "      <td id=\"T_27886_row2_col9\" class=\"data row2 col9\" >0.5329</td>\n",
       "      <td id=\"T_27886_row2_col10\" class=\"data row2 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_27886_row3_col0\" class=\"data row3 col0\" >0.8881</td>\n",
       "      <td id=\"T_27886_row3_col1\" class=\"data row3 col1\" >0.8821</td>\n",
       "      <td id=\"T_27886_row3_col2\" class=\"data row3 col2\" >0.8881</td>\n",
       "      <td id=\"T_27886_row3_col3\" class=\"data row3 col3\" >0.8844</td>\n",
       "      <td id=\"T_27886_row3_col4\" class=\"data row3 col4\" >0.8850</td>\n",
       "      <td id=\"T_27886_row3_col5\" class=\"data row3 col5\" >0.6624</td>\n",
       "      <td id=\"T_27886_row3_col6\" class=\"data row3 col6\" >0.6655</td>\n",
       "      <td id=\"T_27886_row3_col7\" class=\"data row3 col7\" >0.8145</td>\n",
       "      <td id=\"T_27886_row3_col8\" class=\"data row3 col8\" >0.1119</td>\n",
       "      <td id=\"T_27886_row3_col9\" class=\"data row3 col9\" >0.5780</td>\n",
       "      <td id=\"T_27886_row3_col10\" class=\"data row3 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_27886_row4_col0\" class=\"data row4 col0\" >0.8891</td>\n",
       "      <td id=\"T_27886_row4_col1\" class=\"data row4 col1\" >0.8796</td>\n",
       "      <td id=\"T_27886_row4_col2\" class=\"data row4 col2\" >0.8891</td>\n",
       "      <td id=\"T_27886_row4_col3\" class=\"data row4 col3\" >0.8852</td>\n",
       "      <td id=\"T_27886_row4_col4\" class=\"data row4 col4\" >0.8842</td>\n",
       "      <td id=\"T_27886_row4_col5\" class=\"data row4 col5\" >0.6563</td>\n",
       "      <td id=\"T_27886_row4_col6\" class=\"data row4 col6\" >0.6636</td>\n",
       "      <td id=\"T_27886_row4_col7\" class=\"data row4 col7\" >0.8034</td>\n",
       "      <td id=\"T_27886_row4_col8\" class=\"data row4 col8\" >0.1109</td>\n",
       "      <td id=\"T_27886_row4_col9\" class=\"data row4 col9\" >0.5680</td>\n",
       "      <td id=\"T_27886_row4_col10\" class=\"data row4 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_27886_row5_col0\" class=\"data row5 col0\" >0.8724</td>\n",
       "      <td id=\"T_27886_row5_col1\" class=\"data row5 col1\" >0.8765</td>\n",
       "      <td id=\"T_27886_row5_col2\" class=\"data row5 col2\" >0.8724</td>\n",
       "      <td id=\"T_27886_row5_col3\" class=\"data row5 col3\" >0.8679</td>\n",
       "      <td id=\"T_27886_row5_col4\" class=\"data row5 col4\" >0.8630</td>\n",
       "      <td id=\"T_27886_row5_col5\" class=\"data row5 col5\" >0.5869</td>\n",
       "      <td id=\"T_27886_row5_col6\" class=\"data row5 col6\" >0.6039</td>\n",
       "      <td id=\"T_27886_row5_col7\" class=\"data row5 col7\" >0.7598</td>\n",
       "      <td id=\"T_27886_row5_col8\" class=\"data row5 col8\" >0.1276</td>\n",
       "      <td id=\"T_27886_row5_col9\" class=\"data row5 col9\" >0.4947</td>\n",
       "      <td id=\"T_27886_row5_col10\" class=\"data row5 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_27886_row6_col0\" class=\"data row6 col0\" >0.8855</td>\n",
       "      <td id=\"T_27886_row6_col1\" class=\"data row6 col1\" >0.8832</td>\n",
       "      <td id=\"T_27886_row6_col2\" class=\"data row6 col2\" >0.8855</td>\n",
       "      <td id=\"T_27886_row6_col3\" class=\"data row6 col3\" >0.8818</td>\n",
       "      <td id=\"T_27886_row6_col4\" class=\"data row6 col4\" >0.8827</td>\n",
       "      <td id=\"T_27886_row6_col5\" class=\"data row6 col5\" >0.6564</td>\n",
       "      <td id=\"T_27886_row6_col6\" class=\"data row6 col6\" >0.6588</td>\n",
       "      <td id=\"T_27886_row6_col7\" class=\"data row6 col7\" >0.8135</td>\n",
       "      <td id=\"T_27886_row6_col8\" class=\"data row6 col8\" >0.1145</td>\n",
       "      <td id=\"T_27886_row6_col9\" class=\"data row6 col9\" >0.5730</td>\n",
       "      <td id=\"T_27886_row6_col10\" class=\"data row6 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_27886_row7_col0\" class=\"data row7 col0\" >0.8765</td>\n",
       "      <td id=\"T_27886_row7_col1\" class=\"data row7 col1\" >0.8814</td>\n",
       "      <td id=\"T_27886_row7_col2\" class=\"data row7 col2\" >0.8765</td>\n",
       "      <td id=\"T_27886_row7_col3\" class=\"data row7 col3\" >0.8736</td>\n",
       "      <td id=\"T_27886_row7_col4\" class=\"data row7 col4\" >0.8747</td>\n",
       "      <td id=\"T_27886_row7_col5\" class=\"data row7 col5\" >0.6358</td>\n",
       "      <td id=\"T_27886_row7_col6\" class=\"data row7 col6\" >0.6367</td>\n",
       "      <td id=\"T_27886_row7_col7\" class=\"data row7 col7\" >0.8091</td>\n",
       "      <td id=\"T_27886_row7_col8\" class=\"data row7 col8\" >0.1235</td>\n",
       "      <td id=\"T_27886_row7_col9\" class=\"data row7 col9\" >0.5558</td>\n",
       "      <td id=\"T_27886_row7_col10\" class=\"data row7 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_27886_row8_col0\" class=\"data row8 col0\" >0.8684</td>\n",
       "      <td id=\"T_27886_row8_col1\" class=\"data row8 col1\" >0.8734</td>\n",
       "      <td id=\"T_27886_row8_col2\" class=\"data row8 col2\" >0.8684</td>\n",
       "      <td id=\"T_27886_row8_col3\" class=\"data row8 col3\" >0.8647</td>\n",
       "      <td id=\"T_27886_row8_col4\" class=\"data row8 col4\" >0.8660</td>\n",
       "      <td id=\"T_27886_row8_col5\" class=\"data row8 col5\" >0.6096</td>\n",
       "      <td id=\"T_27886_row8_col6\" class=\"data row8 col6\" >0.6108</td>\n",
       "      <td id=\"T_27886_row8_col7\" class=\"data row8 col7\" >0.7946</td>\n",
       "      <td id=\"T_27886_row8_col8\" class=\"data row8 col8\" >0.1316</td>\n",
       "      <td id=\"T_27886_row8_col9\" class=\"data row8 col9\" >0.5304</td>\n",
       "      <td id=\"T_27886_row8_col10\" class=\"data row8 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_27886_row9_col0\" class=\"data row9 col0\" >0.8705</td>\n",
       "      <td id=\"T_27886_row9_col1\" class=\"data row9 col1\" >0.8727</td>\n",
       "      <td id=\"T_27886_row9_col2\" class=\"data row9 col2\" >0.8705</td>\n",
       "      <td id=\"T_27886_row9_col3\" class=\"data row9 col3\" >0.8659</td>\n",
       "      <td id=\"T_27886_row9_col4\" class=\"data row9 col4\" >0.8672</td>\n",
       "      <td id=\"T_27886_row9_col5\" class=\"data row9 col5\" >0.6107</td>\n",
       "      <td id=\"T_27886_row9_col6\" class=\"data row9 col6\" >0.6131</td>\n",
       "      <td id=\"T_27886_row9_col7\" class=\"data row9 col7\" >0.7913</td>\n",
       "      <td id=\"T_27886_row9_col8\" class=\"data row9 col8\" >0.1295</td>\n",
       "      <td id=\"T_27886_row9_col9\" class=\"data row9 col9\" >0.5294</td>\n",
       "      <td id=\"T_27886_row9_col10\" class=\"data row9 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_27886_row10_col0\" class=\"data row10 col0\" >0.8795</td>\n",
       "      <td id=\"T_27886_row10_col1\" class=\"data row10 col1\" >0.8774</td>\n",
       "      <td id=\"T_27886_row10_col2\" class=\"data row10 col2\" >0.8795</td>\n",
       "      <td id=\"T_27886_row10_col3\" class=\"data row10 col3\" >0.8757</td>\n",
       "      <td id=\"T_27886_row10_col4\" class=\"data row10 col4\" >0.8746</td>\n",
       "      <td id=\"T_27886_row10_col5\" class=\"data row10 col5\" >0.6290</td>\n",
       "      <td id=\"T_27886_row10_col6\" class=\"data row10 col6\" >0.6363</td>\n",
       "      <td id=\"T_27886_row10_col7\" class=\"data row10 col7\" >0.7933</td>\n",
       "      <td id=\"T_27886_row10_col8\" class=\"data row10 col8\" >0.1205</td>\n",
       "      <td id=\"T_27886_row10_col9\" class=\"data row10 col9\" >0.5428</td>\n",
       "      <td id=\"T_27886_row10_col10\" class=\"data row10 col10\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_27886_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_27886_row11_col0\" class=\"data row11 col0\" >0.0071</td>\n",
       "      <td id=\"T_27886_row11_col1\" class=\"data row11 col1\" >0.0044</td>\n",
       "      <td id=\"T_27886_row11_col2\" class=\"data row11 col2\" >0.0071</td>\n",
       "      <td id=\"T_27886_row11_col3\" class=\"data row11 col3\" >0.0072</td>\n",
       "      <td id=\"T_27886_row11_col4\" class=\"data row11 col4\" >0.0078</td>\n",
       "      <td id=\"T_27886_row11_col5\" class=\"data row11 col5\" >0.0249</td>\n",
       "      <td id=\"T_27886_row11_col6\" class=\"data row11 col6\" >0.0218</td>\n",
       "      <td id=\"T_27886_row11_col7\" class=\"data row11 col7\" >0.0185</td>\n",
       "      <td id=\"T_27886_row11_col8\" class=\"data row11 col8\" >0.0071</td>\n",
       "      <td id=\"T_27886_row11_col9\" class=\"data row11 col9\" >0.0270</td>\n",
       "      <td id=\"T_27886_row11_col10\" class=\"data row11 col10\" >0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x27113e67940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 13:00:29 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "svm = create_model('svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fd446a9-4a12-4741-ba02-e0ca04b335d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d02f3_row10_col0, #T_d02f3_row10_col1, #T_d02f3_row10_col2, #T_d02f3_row10_col3, #T_d02f3_row10_col4, #T_d02f3_row10_col5, #T_d02f3_row10_col6, #T_d02f3_row10_col7, #T_d02f3_row10_col8, #T_d02f3_row10_col9, #T_d02f3_row10_col10 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d02f3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d02f3_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_d02f3_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_d02f3_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_d02f3_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_d02f3_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_d02f3_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_d02f3_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_d02f3_level0_col7\" class=\"col_heading level0 col7\" >Balance Acc</th>\n",
       "      <th id=\"T_d02f3_level0_col8\" class=\"col_heading level0 col8\" >Hamming Loss</th>\n",
       "      <th id=\"T_d02f3_level0_col9\" class=\"col_heading level0 col9\" >Jaccard Score</th>\n",
       "      <th id=\"T_d02f3_level0_col10\" class=\"col_heading level0 col10\" >Log Loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "      <th class=\"blank col8\" >&nbsp;</th>\n",
       "      <th class=\"blank col9\" >&nbsp;</th>\n",
       "      <th class=\"blank col10\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d02f3_row0_col0\" class=\"data row0 col0\" >0.8920</td>\n",
       "      <td id=\"T_d02f3_row0_col1\" class=\"data row0 col1\" >0.8875</td>\n",
       "      <td id=\"T_d02f3_row0_col2\" class=\"data row0 col2\" >0.8920</td>\n",
       "      <td id=\"T_d02f3_row0_col3\" class=\"data row0 col3\" >0.8901</td>\n",
       "      <td id=\"T_d02f3_row0_col4\" class=\"data row0 col4\" >0.8850</td>\n",
       "      <td id=\"T_d02f3_row0_col5\" class=\"data row0 col5\" >0.6549</td>\n",
       "      <td id=\"T_d02f3_row0_col6\" class=\"data row0 col6\" >0.6698</td>\n",
       "      <td id=\"T_d02f3_row0_col7\" class=\"data row0 col7\" >0.7936</td>\n",
       "      <td id=\"T_d02f3_row0_col8\" class=\"data row0 col8\" >0.1080</td>\n",
       "      <td id=\"T_d02f3_row0_col9\" class=\"data row0 col9\" >0.5617</td>\n",
       "      <td id=\"T_d02f3_row0_col10\" class=\"data row0 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d02f3_row1_col0\" class=\"data row1 col0\" >0.8956</td>\n",
       "      <td id=\"T_d02f3_row1_col1\" class=\"data row1 col1\" >0.8941</td>\n",
       "      <td id=\"T_d02f3_row1_col2\" class=\"data row1 col2\" >0.8956</td>\n",
       "      <td id=\"T_d02f3_row1_col3\" class=\"data row1 col3\" >0.8933</td>\n",
       "      <td id=\"T_d02f3_row1_col4\" class=\"data row1 col4\" >0.8897</td>\n",
       "      <td id=\"T_d02f3_row1_col5\" class=\"data row1 col5\" >0.6704</td>\n",
       "      <td id=\"T_d02f3_row1_col6\" class=\"data row1 col6\" >0.6822</td>\n",
       "      <td id=\"T_d02f3_row1_col7\" class=\"data row1 col7\" >0.8042</td>\n",
       "      <td id=\"T_d02f3_row1_col8\" class=\"data row1 col8\" >0.1044</td>\n",
       "      <td id=\"T_d02f3_row1_col9\" class=\"data row1 col9\" >0.5791</td>\n",
       "      <td id=\"T_d02f3_row1_col10\" class=\"data row1 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d02f3_row2_col0\" class=\"data row2 col0\" >0.8926</td>\n",
       "      <td id=\"T_d02f3_row2_col1\" class=\"data row2 col1\" >0.8868</td>\n",
       "      <td id=\"T_d02f3_row2_col2\" class=\"data row2 col2\" >0.8926</td>\n",
       "      <td id=\"T_d02f3_row2_col3\" class=\"data row2 col3\" >0.8902</td>\n",
       "      <td id=\"T_d02f3_row2_col4\" class=\"data row2 col4\" >0.8861</td>\n",
       "      <td id=\"T_d02f3_row2_col5\" class=\"data row2 col5\" >0.6590</td>\n",
       "      <td id=\"T_d02f3_row2_col6\" class=\"data row2 col6\" >0.6721</td>\n",
       "      <td id=\"T_d02f3_row2_col7\" class=\"data row2 col7\" >0.7974</td>\n",
       "      <td id=\"T_d02f3_row2_col8\" class=\"data row2 col8\" >0.1074</td>\n",
       "      <td id=\"T_d02f3_row2_col9\" class=\"data row2 col9\" >0.5669</td>\n",
       "      <td id=\"T_d02f3_row2_col10\" class=\"data row2 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d02f3_row3_col0\" class=\"data row3 col0\" >0.8942</td>\n",
       "      <td id=\"T_d02f3_row3_col1\" class=\"data row3 col1\" >0.8919</td>\n",
       "      <td id=\"T_d02f3_row3_col2\" class=\"data row3 col2\" >0.8942</td>\n",
       "      <td id=\"T_d02f3_row3_col3\" class=\"data row3 col3\" >0.8916</td>\n",
       "      <td id=\"T_d02f3_row3_col4\" class=\"data row3 col4\" >0.8884</td>\n",
       "      <td id=\"T_d02f3_row3_col5\" class=\"data row3 col5\" >0.6667</td>\n",
       "      <td id=\"T_d02f3_row3_col6\" class=\"data row3 col6\" >0.6779</td>\n",
       "      <td id=\"T_d02f3_row3_col7\" class=\"data row3 col7\" >0.8033</td>\n",
       "      <td id=\"T_d02f3_row3_col8\" class=\"data row3 col8\" >0.1058</td>\n",
       "      <td id=\"T_d02f3_row3_col9\" class=\"data row3 col9\" >0.5758</td>\n",
       "      <td id=\"T_d02f3_row3_col10\" class=\"data row3 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d02f3_row4_col0\" class=\"data row4 col0\" >0.8999</td>\n",
       "      <td id=\"T_d02f3_row4_col1\" class=\"data row4 col1\" >0.8968</td>\n",
       "      <td id=\"T_d02f3_row4_col2\" class=\"data row4 col2\" >0.8999</td>\n",
       "      <td id=\"T_d02f3_row4_col3\" class=\"data row4 col3\" >0.8982</td>\n",
       "      <td id=\"T_d02f3_row4_col4\" class=\"data row4 col4\" >0.8941</td>\n",
       "      <td id=\"T_d02f3_row4_col5\" class=\"data row4 col5\" >0.6835</td>\n",
       "      <td id=\"T_d02f3_row4_col6\" class=\"data row4 col6\" >0.6957</td>\n",
       "      <td id=\"T_d02f3_row4_col7\" class=\"data row4 col7\" >0.8100</td>\n",
       "      <td id=\"T_d02f3_row4_col8\" class=\"data row4 col8\" >0.1001</td>\n",
       "      <td id=\"T_d02f3_row4_col9\" class=\"data row4 col9\" >0.5924</td>\n",
       "      <td id=\"T_d02f3_row4_col10\" class=\"data row4 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d02f3_row5_col0\" class=\"data row5 col0\" >0.8935</td>\n",
       "      <td id=\"T_d02f3_row5_col1\" class=\"data row5 col1\" >0.8944</td>\n",
       "      <td id=\"T_d02f3_row5_col2\" class=\"data row5 col2\" >0.8935</td>\n",
       "      <td id=\"T_d02f3_row5_col3\" class=\"data row5 col3\" >0.8913</td>\n",
       "      <td id=\"T_d02f3_row5_col4\" class=\"data row5 col4\" >0.8871</td>\n",
       "      <td id=\"T_d02f3_row5_col5\" class=\"data row5 col5\" >0.6621</td>\n",
       "      <td id=\"T_d02f3_row5_col6\" class=\"data row5 col6\" >0.6751</td>\n",
       "      <td id=\"T_d02f3_row5_col7\" class=\"data row5 col7\" >0.7990</td>\n",
       "      <td id=\"T_d02f3_row5_col8\" class=\"data row5 col8\" >0.1065</td>\n",
       "      <td id=\"T_d02f3_row5_col9\" class=\"data row5 col9\" >0.5700</td>\n",
       "      <td id=\"T_d02f3_row5_col10\" class=\"data row5 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d02f3_row6_col0\" class=\"data row6 col0\" >0.8964</td>\n",
       "      <td id=\"T_d02f3_row6_col1\" class=\"data row6 col1\" >0.8951</td>\n",
       "      <td id=\"T_d02f3_row6_col2\" class=\"data row6 col2\" >0.8964</td>\n",
       "      <td id=\"T_d02f3_row6_col3\" class=\"data row6 col3\" >0.8943</td>\n",
       "      <td id=\"T_d02f3_row6_col4\" class=\"data row6 col4\" >0.8903</td>\n",
       "      <td id=\"T_d02f3_row6_col5\" class=\"data row6 col5\" >0.6719</td>\n",
       "      <td id=\"T_d02f3_row6_col6\" class=\"data row6 col6\" >0.6844</td>\n",
       "      <td id=\"T_d02f3_row6_col7\" class=\"data row6 col7\" >0.8042</td>\n",
       "      <td id=\"T_d02f3_row6_col8\" class=\"data row6 col8\" >0.1036</td>\n",
       "      <td id=\"T_d02f3_row6_col9\" class=\"data row6 col9\" >0.5803</td>\n",
       "      <td id=\"T_d02f3_row6_col10\" class=\"data row6 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d02f3_row7_col0\" class=\"data row7 col0\" >0.8963</td>\n",
       "      <td id=\"T_d02f3_row7_col1\" class=\"data row7 col1\" >0.8933</td>\n",
       "      <td id=\"T_d02f3_row7_col2\" class=\"data row7 col2\" >0.8963</td>\n",
       "      <td id=\"T_d02f3_row7_col3\" class=\"data row7 col3\" >0.8942</td>\n",
       "      <td id=\"T_d02f3_row7_col4\" class=\"data row7 col4\" >0.8903</td>\n",
       "      <td id=\"T_d02f3_row7_col5\" class=\"data row7 col5\" >0.6721</td>\n",
       "      <td id=\"T_d02f3_row7_col6\" class=\"data row7 col6\" >0.6843</td>\n",
       "      <td id=\"T_d02f3_row7_col7\" class=\"data row7 col7\" >0.8045</td>\n",
       "      <td id=\"T_d02f3_row7_col8\" class=\"data row7 col8\" >0.1037</td>\n",
       "      <td id=\"T_d02f3_row7_col9\" class=\"data row7 col9\" >0.5806</td>\n",
       "      <td id=\"T_d02f3_row7_col10\" class=\"data row7 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d02f3_row8_col0\" class=\"data row8 col0\" >0.8945</td>\n",
       "      <td id=\"T_d02f3_row8_col1\" class=\"data row8 col1\" >0.8883</td>\n",
       "      <td id=\"T_d02f3_row8_col2\" class=\"data row8 col2\" >0.8945</td>\n",
       "      <td id=\"T_d02f3_row8_col3\" class=\"data row8 col3\" >0.8922</td>\n",
       "      <td id=\"T_d02f3_row8_col4\" class=\"data row8 col4\" >0.8883</td>\n",
       "      <td id=\"T_d02f3_row8_col5\" class=\"data row8 col5\" >0.6657</td>\n",
       "      <td id=\"T_d02f3_row8_col6\" class=\"data row8 col6\" >0.6782</td>\n",
       "      <td id=\"T_d02f3_row8_col7\" class=\"data row8 col7\" >0.8012</td>\n",
       "      <td id=\"T_d02f3_row8_col8\" class=\"data row8 col8\" >0.1055</td>\n",
       "      <td id=\"T_d02f3_row8_col9\" class=\"data row8 col9\" >0.5740</td>\n",
       "      <td id=\"T_d02f3_row8_col10\" class=\"data row8 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d02f3_row9_col0\" class=\"data row9 col0\" >0.8932</td>\n",
       "      <td id=\"T_d02f3_row9_col1\" class=\"data row9 col1\" >0.8896</td>\n",
       "      <td id=\"T_d02f3_row9_col2\" class=\"data row9 col2\" >0.8932</td>\n",
       "      <td id=\"T_d02f3_row9_col3\" class=\"data row9 col3\" >0.8911</td>\n",
       "      <td id=\"T_d02f3_row9_col4\" class=\"data row9 col4\" >0.8866</td>\n",
       "      <td id=\"T_d02f3_row9_col5\" class=\"data row9 col5\" >0.6602</td>\n",
       "      <td id=\"T_d02f3_row9_col6\" class=\"data row9 col6\" >0.6739</td>\n",
       "      <td id=\"T_d02f3_row9_col7\" class=\"data row9 col7\" >0.7972</td>\n",
       "      <td id=\"T_d02f3_row9_col8\" class=\"data row9 col8\" >0.1068</td>\n",
       "      <td id=\"T_d02f3_row9_col9\" class=\"data row9 col9\" >0.5676</td>\n",
       "      <td id=\"T_d02f3_row9_col10\" class=\"data row9 col10\" >-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_d02f3_row10_col0\" class=\"data row10 col0\" >0.8948</td>\n",
       "      <td id=\"T_d02f3_row10_col1\" class=\"data row10 col1\" >0.8918</td>\n",
       "      <td id=\"T_d02f3_row10_col2\" class=\"data row10 col2\" >0.8948</td>\n",
       "      <td id=\"T_d02f3_row10_col3\" class=\"data row10 col3\" >0.8926</td>\n",
       "      <td id=\"T_d02f3_row10_col4\" class=\"data row10 col4\" >0.8886</td>\n",
       "      <td id=\"T_d02f3_row10_col5\" class=\"data row10 col5\" >0.6667</td>\n",
       "      <td id=\"T_d02f3_row10_col6\" class=\"data row10 col6\" >0.6794</td>\n",
       "      <td id=\"T_d02f3_row10_col7\" class=\"data row10 col7\" >0.8015</td>\n",
       "      <td id=\"T_d02f3_row10_col8\" class=\"data row10 col8\" >0.1052</td>\n",
       "      <td id=\"T_d02f3_row10_col9\" class=\"data row10 col9\" >0.5748</td>\n",
       "      <td id=\"T_d02f3_row10_col10\" class=\"data row10 col10\" >0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d02f3_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_d02f3_row11_col0\" class=\"data row11 col0\" >0.0022</td>\n",
       "      <td id=\"T_d02f3_row11_col1\" class=\"data row11 col1\" >0.0033</td>\n",
       "      <td id=\"T_d02f3_row11_col2\" class=\"data row11 col2\" >0.0022</td>\n",
       "      <td id=\"T_d02f3_row11_col3\" class=\"data row11 col3\" >0.0023</td>\n",
       "      <td id=\"T_d02f3_row11_col4\" class=\"data row11 col4\" >0.0025</td>\n",
       "      <td id=\"T_d02f3_row11_col5\" class=\"data row11 col5\" >0.0079</td>\n",
       "      <td id=\"T_d02f3_row11_col6\" class=\"data row11 col6\" >0.0072</td>\n",
       "      <td id=\"T_d02f3_row11_col7\" class=\"data row11 col7\" >0.0045</td>\n",
       "      <td id=\"T_d02f3_row11_col8\" class=\"data row11 col8\" >0.0022</td>\n",
       "      <td id=\"T_d02f3_row11_col9\" class=\"data row11 col9\" >0.0084</td>\n",
       "      <td id=\"T_d02f3_row11_col10\" class=\"data row11 col10\" >0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2711568cfa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/26 13:01:46 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    }
   ],
   "source": [
    "svm_tuned_model, svm_tuner = tune_model(svm, search_library = 'optuna', return_tuner=True, n_iter=num_iterations_tuning, optimize=optimized_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "459771ad-d31e-4e53-aedc-578b117a8958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=1.983570694577895e-06, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.050879465480455605,\n",
      "              fit_intercept=True, l1_ratio=0.3264919553269943,\n",
      "              learning_rate='adaptive', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "              random_state=1768, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(svm_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1ce39277-1001-4771-b1fd-1eabf85010dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_080b9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_080b9_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_080b9_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_080b9_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_080b9_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_080b9_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_080b9_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_080b9_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_080b9_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_080b9_level0_col8\" class=\"col_heading level0 col8\" >Balance Acc</th>\n",
       "      <th id=\"T_080b9_level0_col9\" class=\"col_heading level0 col9\" >Hamming Loss</th>\n",
       "      <th id=\"T_080b9_level0_col10\" class=\"col_heading level0 col10\" >Jaccard Score</th>\n",
       "      <th id=\"T_080b9_level0_col11\" class=\"col_heading level0 col11\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_080b9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_080b9_row0_col0\" class=\"data row0 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_080b9_row0_col1\" class=\"data row0 col1\" >0.8961</td>\n",
       "      <td id=\"T_080b9_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_080b9_row0_col3\" class=\"data row0 col3\" >0.8961</td>\n",
       "      <td id=\"T_080b9_row0_col4\" class=\"data row0 col4\" >0.8943</td>\n",
       "      <td id=\"T_080b9_row0_col5\" class=\"data row0 col5\" >0.8898</td>\n",
       "      <td id=\"T_080b9_row0_col6\" class=\"data row0 col6\" >0.6710</td>\n",
       "      <td id=\"T_080b9_row0_col7\" class=\"data row0 col7\" >0.6844</td>\n",
       "      <td id=\"T_080b9_row0_col8\" class=\"data row0 col8\" >0.8028</td>\n",
       "      <td id=\"T_080b9_row0_col9\" class=\"data row0 col9\" >0.1039</td>\n",
       "      <td id=\"T_080b9_row0_col10\" class=\"data row0 col10\" >0.5792</td>\n",
       "      <td id=\"T_080b9_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2717018bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_svm = predict_model(svm_tuned_model, data = features_df_testing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d6dd58a-03ef-438f-9194-e28dc7e12d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213bc01d369f4c8390af572378c98db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9ad3a02-579f-47c2-97b0-1dd8a2079bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptp</td>\n",
       "      <td>7.630259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clearance</td>\n",
       "      <td>5.968754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entropyWavelet</td>\n",
       "      <td>5.569796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3.389358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spectral_entropy</td>\n",
       "      <td>3.356334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>energy</td>\n",
       "      <td>2.531843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>impulse</td>\n",
       "      <td>2.116005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rms</td>\n",
       "      <td>1.965590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>meanSpectrogram</td>\n",
       "      <td>1.827582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>meanWavelet</td>\n",
       "      <td>1.564300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spectral_flatness</td>\n",
       "      <td>1.461514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entropySpectrogram</td>\n",
       "      <td>1.458172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>energyWavelet</td>\n",
       "      <td>1.142491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>varWavelet</td>\n",
       "      <td>1.066804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>skewness</td>\n",
       "      <td>0.861077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>medianFreq</td>\n",
       "      <td>0.809849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spectral_skewness</td>\n",
       "      <td>0.797180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mean</td>\n",
       "      <td>0.793914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spectral_kurtosis</td>\n",
       "      <td>0.595944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>crest</td>\n",
       "      <td>0.572248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>std</td>\n",
       "      <td>0.534351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>meanFreq</td>\n",
       "      <td>0.529711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>energySpectrogram</td>\n",
       "      <td>0.443298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>varSpectrogram</td>\n",
       "      <td>0.438321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>kurtosis</td>\n",
       "      <td>0.365298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bandwidth</td>\n",
       "      <td>0.302570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>shape</td>\n",
       "      <td>0.240969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Features  importance\n",
       "0                  ptp    7.630259\n",
       "1            clearance    5.968754\n",
       "2       entropyWavelet    5.569796\n",
       "3              entropy    3.389358\n",
       "4     spectral_entropy    3.356334\n",
       "5               energy    2.531843\n",
       "6              impulse    2.116005\n",
       "7                  rms    1.965590\n",
       "8      meanSpectrogram    1.827582\n",
       "9          meanWavelet    1.564300\n",
       "10   spectral_flatness    1.461514\n",
       "11  entropySpectrogram    1.458172\n",
       "12       energyWavelet    1.142491\n",
       "13          varWavelet    1.066804\n",
       "14            skewness    0.861077\n",
       "15          medianFreq    0.809849\n",
       "16   spectral_skewness    0.797180\n",
       "17                mean    0.793914\n",
       "18   spectral_kurtosis    0.595944\n",
       "19               crest    0.572248\n",
       "20                 std    0.534351\n",
       "21            meanFreq    0.529711\n",
       "22   energySpectrogram    0.443298\n",
       "23      varSpectrogram    0.438321\n",
       "24            kurtosis    0.365298\n",
       "25           bandwidth    0.302570\n",
       "26               shape    0.240969"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_top_features = get_svm_feature_importance_df(svm, features_df_training_normalized)\n",
    "svm_top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "049dda80-ba01-474f-b66d-250dcb0e8d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ceefa\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ceefa_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ceefa_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_ceefa_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_ceefa_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_ceefa_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_ceefa_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_ceefa_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_ceefa_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_ceefa_level0_col8\" class=\"col_heading level0 col8\" >Balance Acc</th>\n",
       "      <th id=\"T_ceefa_level0_col9\" class=\"col_heading level0 col9\" >Hamming Loss</th>\n",
       "      <th id=\"T_ceefa_level0_col10\" class=\"col_heading level0 col10\" >Jaccard Score</th>\n",
       "      <th id=\"T_ceefa_level0_col11\" class=\"col_heading level0 col11\" >Log Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ceefa_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ceefa_row0_col0\" class=\"data row0 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_ceefa_row0_col1\" class=\"data row0 col1\" >0.8847</td>\n",
       "      <td id=\"T_ceefa_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_ceefa_row0_col3\" class=\"data row0 col3\" >0.8847</td>\n",
       "      <td id=\"T_ceefa_row0_col4\" class=\"data row0 col4\" >0.8803</td>\n",
       "      <td id=\"T_ceefa_row0_col5\" class=\"data row0 col5\" >0.8797</td>\n",
       "      <td id=\"T_ceefa_row0_col6\" class=\"data row0 col6\" >0.6443</td>\n",
       "      <td id=\"T_ceefa_row0_col7\" class=\"data row0 col7\" >0.6512</td>\n",
       "      <td id=\"T_ceefa_row0_col8\" class=\"data row0 col8\" >0.7984</td>\n",
       "      <td id=\"T_ceefa_row0_col9\" class=\"data row0 col9\" >0.1153</td>\n",
       "      <td id=\"T_ceefa_row0_col10\" class=\"data row0 col10\" >0.5569</td>\n",
       "      <td id=\"T_ceefa_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2711364b280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_svm = predict_model(svm, data=features_df_testing_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d4e08c3-a8c6-4423-a289-1be18b4402e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>rms</th>\n",
       "      <th>std</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>ptp</th>\n",
       "      <th>crest</th>\n",
       "      <th>impulse</th>\n",
       "      <th>clearance</th>\n",
       "      <th>shape</th>\n",
       "      <th>...</th>\n",
       "      <th>meanWavelet</th>\n",
       "      <th>varWavelet</th>\n",
       "      <th>entropyWavelet</th>\n",
       "      <th>energyWavelet</th>\n",
       "      <th>meanSpectrogram</th>\n",
       "      <th>varSpectrogram</th>\n",
       "      <th>entropySpectrogram</th>\n",
       "      <th>energySpectrogram</th>\n",
       "      <th>Label</th>\n",
       "      <th>prediction_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0.012873</td>\n",
       "      <td>-0.573892</td>\n",
       "      <td>-0.608301</td>\n",
       "      <td>0.586265</td>\n",
       "      <td>-0.043286</td>\n",
       "      <td>-0.772690</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>-0.026207</td>\n",
       "      <td>-0.986468</td>\n",
       "      <td>0.022755</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.687903</td>\n",
       "      <td>-0.276503</td>\n",
       "      <td>0.164883</td>\n",
       "      <td>-0.302537</td>\n",
       "      <td>-0.241933</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261113</th>\n",
       "      <td>0.036416</td>\n",
       "      <td>-0.036985</td>\n",
       "      <td>-0.018097</td>\n",
       "      <td>0.094470</td>\n",
       "      <td>-0.122904</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.201324</td>\n",
       "      <td>-0.202111</td>\n",
       "      <td>0.204035</td>\n",
       "      <td>-0.177289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075207</td>\n",
       "      <td>-0.182138</td>\n",
       "      <td>0.209378</td>\n",
       "      <td>-0.191124</td>\n",
       "      <td>-0.174411</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.154960</td>\n",
       "      <td>-0.119475</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207745</th>\n",
       "      <td>0.036146</td>\n",
       "      <td>-0.054912</td>\n",
       "      <td>-0.037686</td>\n",
       "      <td>-0.206209</td>\n",
       "      <td>-0.191703</td>\n",
       "      <td>-0.166550</td>\n",
       "      <td>-0.817718</td>\n",
       "      <td>-0.706493</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-0.686273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053889</td>\n",
       "      <td>-0.178280</td>\n",
       "      <td>0.195415</td>\n",
       "      <td>-0.197872</td>\n",
       "      <td>-0.181161</td>\n",
       "      <td>-0.119248</td>\n",
       "      <td>-0.154350</td>\n",
       "      <td>-0.119369</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124580</th>\n",
       "      <td>0.118151</td>\n",
       "      <td>-0.448350</td>\n",
       "      <td>-0.469693</td>\n",
       "      <td>2.502898</td>\n",
       "      <td>0.034874</td>\n",
       "      <td>-0.643918</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>0.117064</td>\n",
       "      <td>-0.489718</td>\n",
       "      <td>1.077598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.614637</td>\n",
       "      <td>-0.275118</td>\n",
       "      <td>0.167714</td>\n",
       "      <td>-0.300557</td>\n",
       "      <td>-0.236559</td>\n",
       "      <td>-0.119499</td>\n",
       "      <td>-0.156091</td>\n",
       "      <td>-0.119625</td>\n",
       "      <td>damaged</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82414</th>\n",
       "      <td>0.059542</td>\n",
       "      <td>-0.577416</td>\n",
       "      <td>-0.608461</td>\n",
       "      <td>0.420073</td>\n",
       "      <td>-0.140666</td>\n",
       "      <td>-0.783024</td>\n",
       "      <td>-0.452562</td>\n",
       "      <td>-0.416848</td>\n",
       "      <td>-1.082528</td>\n",
       "      <td>-0.429675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.692653</td>\n",
       "      <td>-0.276226</td>\n",
       "      <td>0.165140</td>\n",
       "      <td>-0.302350</td>\n",
       "      <td>-0.241967</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>damaged</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260610</th>\n",
       "      <td>0.037051</td>\n",
       "      <td>-0.120273</td>\n",
       "      <td>-0.109091</td>\n",
       "      <td>-0.046457</td>\n",
       "      <td>-0.052223</td>\n",
       "      <td>-0.075470</td>\n",
       "      <td>-0.119359</td>\n",
       "      <td>-0.054110</td>\n",
       "      <td>0.157594</td>\n",
       "      <td>0.420565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069341</td>\n",
       "      <td>-0.204878</td>\n",
       "      <td>0.201230</td>\n",
       "      <td>-0.220567</td>\n",
       "      <td>-0.194898</td>\n",
       "      <td>-0.119423</td>\n",
       "      <td>-0.155466</td>\n",
       "      <td>-0.119544</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258687</th>\n",
       "      <td>0.037649</td>\n",
       "      <td>-0.412417</td>\n",
       "      <td>-0.428330</td>\n",
       "      <td>0.099707</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>-0.512874</td>\n",
       "      <td>-0.121624</td>\n",
       "      <td>-0.001592</td>\n",
       "      <td>-0.423838</td>\n",
       "      <td>0.784442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.523616</td>\n",
       "      <td>-0.262370</td>\n",
       "      <td>0.174837</td>\n",
       "      <td>-0.288400</td>\n",
       "      <td>-0.233108</td>\n",
       "      <td>-0.119503</td>\n",
       "      <td>-0.156112</td>\n",
       "      <td>-0.119628</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81693</th>\n",
       "      <td>0.065867</td>\n",
       "      <td>-0.578473</td>\n",
       "      <td>-0.609811</td>\n",
       "      <td>-0.018680</td>\n",
       "      <td>-0.113815</td>\n",
       "      <td>-0.777508</td>\n",
       "      <td>-0.068149</td>\n",
       "      <td>-0.135078</td>\n",
       "      <td>-1.034727</td>\n",
       "      <td>-0.366921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.695291</td>\n",
       "      <td>-0.276252</td>\n",
       "      <td>0.165059</td>\n",
       "      <td>-0.302391</td>\n",
       "      <td>-0.241969</td>\n",
       "      <td>-0.119511</td>\n",
       "      <td>-0.156183</td>\n",
       "      <td>-0.119637</td>\n",
       "      <td>damaged</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205706</th>\n",
       "      <td>0.035491</td>\n",
       "      <td>-0.426794</td>\n",
       "      <td>-0.444088</td>\n",
       "      <td>0.048360</td>\n",
       "      <td>0.038563</td>\n",
       "      <td>-0.511299</td>\n",
       "      <td>0.161131</td>\n",
       "      <td>0.161734</td>\n",
       "      <td>-0.395557</td>\n",
       "      <td>0.467480</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516059</td>\n",
       "      <td>-0.264963</td>\n",
       "      <td>0.174827</td>\n",
       "      <td>-0.290323</td>\n",
       "      <td>-0.234408</td>\n",
       "      <td>-0.119506</td>\n",
       "      <td>-0.156138</td>\n",
       "      <td>-0.119632</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201271</th>\n",
       "      <td>0.034609</td>\n",
       "      <td>-0.404988</td>\n",
       "      <td>-0.420263</td>\n",
       "      <td>-0.027683</td>\n",
       "      <td>-0.020592</td>\n",
       "      <td>-0.524025</td>\n",
       "      <td>-0.304570</td>\n",
       "      <td>-0.192165</td>\n",
       "      <td>-0.476571</td>\n",
       "      <td>0.417044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510256</td>\n",
       "      <td>-0.261506</td>\n",
       "      <td>0.175662</td>\n",
       "      <td>-0.287366</td>\n",
       "      <td>-0.232991</td>\n",
       "      <td>-0.119503</td>\n",
       "      <td>-0.156113</td>\n",
       "      <td>-0.119629</td>\n",
       "      <td>healthy</td>\n",
       "      <td>damaged</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7104 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       rms       std  skewness  kurtosis       ptp     crest  \\\n",
       "371     0.012873 -0.573892 -0.608301  0.586265 -0.043286 -0.772690  0.000642   \n",
       "261113  0.036416 -0.036985 -0.018097  0.094470 -0.122904 -0.000295 -0.201324   \n",
       "207745  0.036146 -0.054912 -0.037686 -0.206209 -0.191703 -0.166550 -0.817718   \n",
       "124580  0.118151 -0.448350 -0.469693  2.502898  0.034874 -0.643918 -0.024141   \n",
       "82414   0.059542 -0.577416 -0.608461  0.420073 -0.140666 -0.783024 -0.452562   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "260610  0.037051 -0.120273 -0.109091 -0.046457 -0.052223 -0.075470 -0.119359   \n",
       "258687  0.037649 -0.412417 -0.428330  0.099707  0.062800 -0.512874 -0.121624   \n",
       "81693   0.065867 -0.578473 -0.609811 -0.018680 -0.113815 -0.777508 -0.068149   \n",
       "205706  0.035491 -0.426794 -0.444088  0.048360  0.038563 -0.511299  0.161131   \n",
       "201271  0.034609 -0.404988 -0.420263 -0.027683 -0.020592 -0.524025 -0.304570   \n",
       "\n",
       "         impulse  clearance     shape  ...  meanWavelet  varWavelet  \\\n",
       "371    -0.026207  -0.986468  0.022755  ...    -0.687903   -0.276503   \n",
       "261113 -0.202111   0.204035 -0.177289  ...     0.075207   -0.182138   \n",
       "207745 -0.706493  -0.152971 -0.686273  ...    -0.053889   -0.178280   \n",
       "124580  0.117064  -0.489718  1.077598  ...    -0.614637   -0.275118   \n",
       "82414  -0.416848  -1.082528 -0.429675  ...    -0.692653   -0.276226   \n",
       "...          ...        ...       ...  ...          ...         ...   \n",
       "260610 -0.054110   0.157594  0.420565  ...    -0.069341   -0.204878   \n",
       "258687 -0.001592  -0.423838  0.784442  ...    -0.523616   -0.262370   \n",
       "81693  -0.135078  -1.034727 -0.366921  ...    -0.695291   -0.276252   \n",
       "205706  0.161734  -0.395557  0.467480  ...    -0.516059   -0.264963   \n",
       "201271 -0.192165  -0.476571  0.417044  ...    -0.510256   -0.261506   \n",
       "\n",
       "        entropyWavelet  energyWavelet  meanSpectrogram  varSpectrogram  \\\n",
       "371           0.164883      -0.302537        -0.241933       -0.119511   \n",
       "261113        0.209378      -0.191124        -0.174411       -0.119359   \n",
       "207745        0.195415      -0.197872        -0.181161       -0.119248   \n",
       "124580        0.167714      -0.300557        -0.236559       -0.119499   \n",
       "82414         0.165140      -0.302350        -0.241967       -0.119511   \n",
       "...                ...            ...              ...             ...   \n",
       "260610        0.201230      -0.220567        -0.194898       -0.119423   \n",
       "258687        0.174837      -0.288400        -0.233108       -0.119503   \n",
       "81693         0.165059      -0.302391        -0.241969       -0.119511   \n",
       "205706        0.174827      -0.290323        -0.234408       -0.119506   \n",
       "201271        0.175662      -0.287366        -0.232991       -0.119503   \n",
       "\n",
       "        entropySpectrogram  energySpectrogram    Label  prediction_label  \n",
       "371              -0.156183          -0.119637  healthy           damaged  \n",
       "261113           -0.154960          -0.119475  healthy           damaged  \n",
       "207745           -0.154350          -0.119369  healthy           damaged  \n",
       "124580           -0.156091          -0.119625  damaged           healthy  \n",
       "82414            -0.156183          -0.119637  damaged           healthy  \n",
       "...                    ...                ...      ...               ...  \n",
       "260610           -0.155466          -0.119544  healthy           damaged  \n",
       "258687           -0.156112          -0.119628  healthy           damaged  \n",
       "81693            -0.156183          -0.119637  damaged           healthy  \n",
       "205706           -0.156138          -0.119632  healthy           damaged  \n",
       "201271           -0.156113          -0.119629  healthy           damaged  \n",
       "\n",
       "[7104 rows x 29 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_incorrect_predictions(predictions_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378342ee-8ffa-4f37-9937-a2051463887a",
   "metadata": {},
   "source": [
    "# Experiment Setup (DL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c085121-3acd-4d2e-9fb4-5c19183fe186",
   "metadata": {},
   "source": [
    "## Configure Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fee3568a-b1fa-4505-bd7f-88819ba246fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (157669, 28) | Val Shape: (39418, 28) | Test Shape: (49272, 28)\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(features_df_training_normalized, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.2, random_state=42)\n",
    "print(f\"Train Shape: {train.shape} | Val Shape: {val.shape} | Test Shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41773c3d-7a5e-43b7-8682-2aea065f0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Label\"\n",
    "\n",
    "categorical_cols = [\n",
    "    col\n",
    "    for col in features_df_training_normalized.select_dtypes(include=[\"object\",\"category\"]).columns\n",
    "    if col != target\n",
    "]\n",
    "\n",
    "continuous_cols = features_df_training_normalized.select_dtypes(include=[\"number\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a28e6e44-1bea-4842-8482-9708cc2c1367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: Label\n",
      "Categorical inputs: []\n",
      "Continuous inputs: ['mean', 'rms', 'std', 'skewness', 'kurtosis', 'ptp', 'crest', 'impulse', 'clearance', 'shape', 'energy', 'entropy', 'meanFreq', 'medianFreq', 'bandwidth', 'spectral_flatness', 'spectral_entropy', 'spectral_skewness', 'spectral_kurtosis', 'meanWavelet', 'varWavelet', 'entropyWavelet', 'energyWavelet', 'meanSpectrogram', 'varSpectrogram', 'entropySpectrogram', 'energySpectrogram']\n"
     ]
    }
   ],
   "source": [
    "print(\"Target:\", target)\n",
    "print(\"Categorical inputs:\", categorical_cols)  \n",
    "print(\"Continuous inputs:\", continuous_cols)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f339072-98d8-491e-a93c-cdcce0517bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[target],\n",
    "    continuous_cols=continuous_cols,\n",
    "    categorical_cols=categorical_cols,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c70fc27-0191-47e7-b183-e78605871c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU: Yes\n"
     ]
    }
   ],
   "source": [
    "available_gpu=1 if torch.cuda.is_available() else 0\n",
    "print(f\"Available GPU: {'Yes' if available_gpu else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19a562ad-72cd-4216-8f77-36c195d0f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,\n",
    "    max_epochs=20,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    batch_size=256,\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "experiment_config = ExperimentConfig(\n",
    "        project_name=\"TEST\",\n",
    "        run_name=\"test\",\n",
    "        log_target=\"tensorboard\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c24af441-0171-4f3f-a221-95eedb193867",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feeb2f9-8fcd-45c6-99f4-566f19f8f14e",
   "metadata": {},
   "source": [
    "## Tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c76181c3-dfb9-4f2f-ae38-efd79cc13346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TabNet_Optimization(trial):\n",
    "    n_d     = trial.suggest_int(\"n_d\", 4, 64)\n",
    "    n_a     = trial.suggest_int(\"n_a\", 4, 64)\n",
    "    n_steps = trial.suggest_int(\"n_steps\", 3, 10)\n",
    "    gamma   = trial.suggest_float(\"gamma\", 1.0, 2.0)\n",
    "    embedding_dropout = trial.suggest_float(\"embedding_dropout\", 0, 1)\n",
    "    lr      = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "    \n",
    "    tabnet_config = TabNetModelConfig(\n",
    "        task=\"classification\",\n",
    "        n_d=n_d,\n",
    "        n_a=n_a,\n",
    "        n_steps=n_steps,\n",
    "        gamma=gamma,\n",
    "        embedding_dropout=embedding_dropout,\n",
    "        learning_rate=lr,\n",
    "        n_independent=2,\n",
    "        metrics=[\n",
    "            \"auroc\",\n",
    "            \"recall\",\n",
    "            \"precision\",\n",
    "            \"f1_score\",\n",
    "            \"cohen_kappa\",\n",
    "            \"matthews_corrcoef\",\n",
    "            \"hamming_distance\",\n",
    "            \"jaccard_index\",\n",
    "        ],\n",
    "        metrics_prob_input=[\n",
    "            True,   # auroc\n",
    "            False,  # recall\n",
    "            False,  # precision\n",
    "            False,  # f1_score\n",
    "            False,  # cohen_kappa\n",
    "            False,  # matthews_corrcoef\n",
    "            False,  # hamming_distance\n",
    "            False,  # jaccard_index\n",
    "        ],\n",
    "        metrics_params=[\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # auroc\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # recall\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # precision\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # f1_score\n",
    "            {\"num_classes\": 2},                      # cohen_kappa\n",
    "            {},                                      # matthews_corrcoef\n",
    "            {},                                      # hamming_distance\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # jaccard_index\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    tabnet_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=tabnet_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    tabnet_model.fit(train=train, validation=val)\n",
    "\n",
    "    preds_df = tabnet_model.predict(val)\n",
    "    y_pred = preds_df[\"Label_prediction\"].to_numpy()\n",
    "    y_true = val[\"Label\"].to_numpy()\n",
    "    return f1_score(y_true, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97f728e4-7cc5-4933-adfd-776aba50e437",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">611</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:33\u001b[0m,\u001b[1;36m611\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">715</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:33\u001b[0m,\u001b[1;36m715\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">746</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:33\u001b[0m,\u001b[1;36m746\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">931</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:33\u001b[0m,\u001b[1;36m931\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">991</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:33\u001b[0m,\u001b[1;36m991\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">327</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:34\u001b[0m,\u001b[1;36m327\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f664dff37ca84cb8be331ce2d2f2f6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.006918309709189364\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_851882fe-ef9a-42b5-9ca9-4b099a08222c.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_851882fe-ef9a-42b5-9ca9-4b099a08222c.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">375</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.006918309709189364</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:48\u001b[0m,\u001b[1;36m375\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.006918309709189364\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:18:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">384</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:18:48\u001b[0m,\u001b[1;36m384\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  283 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  283 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 283 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 283 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 179                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 283 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 283 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 179                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9615e638caeb4536b5d4a25c22477fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">280</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:44\u001b[0m,\u001b[1;36m280\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">281</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:44\u001b[0m,\u001b[1;36m281\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">615</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:49\u001b[0m,\u001b[1;36m615\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">648</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:49\u001b[0m,\u001b[1;36m648\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">680</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:49\u001b[0m,\u001b[1;36m680\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">843</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:49\u001b[0m,\u001b[1;36m843\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">916</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:49\u001b[0m,\u001b[1;36m916\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:26:49</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">958</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:26:49\u001b[0m,\u001b[1;36m958\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f744f813d94ca19cd368ec4341691b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_70d97d0a-dbb4-4663-84d7-5ac8c18e2e77.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_70d97d0a-dbb4-4663-84d7-5ac8c18e2e77.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:27:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">847</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:27:06\u001b[0m,\u001b[1;36m847\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:27:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">857</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:27:06\u001b[0m,\u001b[1;36m857\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  349 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  349 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 349 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 349 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 251                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 349 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 349 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 251                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26515c9ad581464abc1279b563d16ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">624</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:22\u001b[0m,\u001b[1;36m624\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:22\u001b[0m,\u001b[1;36m626\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:29\u001b[0m,\u001b[1;36m204\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:29\u001b[0m,\u001b[1;36m236\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">265</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:29\u001b[0m,\u001b[1;36m265\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">420</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:29\u001b[0m,\u001b[1;36m420\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">474</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:29\u001b[0m,\u001b[1;36m474\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">515</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:29\u001b[0m,\u001b[1;36m515\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f4f25c33604f1d915abb4081a2470b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.05248074602497723\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_d31491fd-fdff-4d3a-a7c9-9421dbf75094.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_d31491fd-fdff-4d3a-a7c9-9421dbf75094.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">830</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05248074602497723</span>. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:41\u001b[0m,\u001b[1;36m830\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.05248074602497723\u001b[0m. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:35:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">835</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:35:41\u001b[0m,\u001b[1;36m835\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │ 41.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │ 41.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 41.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 41.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 155                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 41.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 41.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 155                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b960ff7679423ab85279387c820527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">016</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:41\u001b[0m,\u001b[1;36m016\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">018</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:41\u001b[0m,\u001b[1;36m018\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">404</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:44\u001b[0m,\u001b[1;36m404\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">437</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:44\u001b[0m,\u001b[1;36m437\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">466</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:44\u001b[0m,\u001b[1;36m466\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">621</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:44\u001b[0m,\u001b[1;36m621\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:44\u001b[0m,\u001b[1;36m669\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">709</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:44\u001b[0m,\u001b[1;36m709\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5312a53ca142407c8742d3452799be0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.02089296130854041\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_511e1bfe-cb5e-4bd3-a6dd-b77077f978ed.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_511e1bfe-cb5e-4bd3-a6dd-b77077f978ed.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:54</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">821</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.02089296130854041</span>. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:54\u001b[0m,\u001b[1;36m821\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.02089296130854041\u001b[0m. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:40:54</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">825</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:40:54\u001b[0m,\u001b[1;36m825\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │ 45.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │ 45.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 45.5 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 45.5 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 107                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 45.5 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 45.5 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 107                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1901bba37d4d588930220f9b838231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:00\u001b[0m,\u001b[1;36m226\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">228</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:00\u001b[0m,\u001b[1;36m228\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">942</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:02\u001b[0m,\u001b[1;36m942\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">974</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:02\u001b[0m,\u001b[1;36m974\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">002</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:03\u001b[0m,\u001b[1;36m002\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">167</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:03\u001b[0m,\u001b[1;36m167\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">224</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:03\u001b[0m,\u001b[1;36m224\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">264</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:03\u001b[0m,\u001b[1;36m264\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846bb832c6aa4942a8ddcad30f84ac92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.09120108393559097\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_23167e65-821e-4cb4-9628-fa1abd0a9861.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_23167e65-821e-4cb4-9628-fa1abd0a9861.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">815</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.09120108393559097</span>. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:19\u001b[0m,\u001b[1;36m815\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.09120108393559097\u001b[0m. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">13:50:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">822</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m13:50:19\u001b[0m,\u001b[1;36m822\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │ 76.7 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │ 76.7 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 76.7 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 76.7 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 251                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 76.7 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 76.7 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 251                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27df4c327d7b46a3b38f1f0f37a7ee79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">937</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:03\u001b[0m,\u001b[1;36m937\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">939</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:03\u001b[0m,\u001b[1;36m939\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">911</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:08\u001b[0m,\u001b[1;36m911\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">944</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:08\u001b[0m,\u001b[1;36m944\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:08\u001b[0m,\u001b[1;36m972\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">143</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:09\u001b[0m,\u001b[1;36m143\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">196</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:09\u001b[0m,\u001b[1;36m196\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:09</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">236</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:09\u001b[0m,\u001b[1;36m236\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcfb6f2d6ca4b00b1da140ae4701b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.0630957344480193\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_14e01c57-bcdd-4e79-a3bb-84facc2618de.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_14e01c57-bcdd-4e79-a3bb-84facc2618de.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">315</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0630957344480193</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:20\u001b[0m,\u001b[1;36m315\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.0630957344480193\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:13:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:13:20\u001b[0m,\u001b[1;36m322\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  257 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  257 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 257 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 257 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 131                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 257 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 257 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 131                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d126c1793342aa94704326e00f04f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">746</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:25\u001b[0m,\u001b[1;36m746\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:25</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:25\u001b[0m,\u001b[1;36m748\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">785</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:29\u001b[0m,\u001b[1;36m785\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:29\u001b[0m,\u001b[1;36m818\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">845</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:29\u001b[0m,\u001b[1;36m845\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">006</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:30\u001b[0m,\u001b[1;36m006\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">054</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:30\u001b[0m,\u001b[1;36m054\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">097</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:30\u001b[0m,\u001b[1;36m097\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00f86e75b684629960b91891cba67b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.006918309709189364\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_4d77e7b2-1a80-4468-948d-fecf2068863a.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_4d77e7b2-1a80-4468-948d-fecf2068863a.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">058</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.006918309709189364</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:40\u001b[0m,\u001b[1;36m058\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.006918309709189364\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:20:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">063</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:20:40\u001b[0m,\u001b[1;36m063\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  125 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  125 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 125 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 125 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 107                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 125 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 125 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 107                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2542e5426d3c47a2a153b13736847fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:08\u001b[0m,\u001b[1;36m718\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">719</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:08\u001b[0m,\u001b[1;36m719\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">677</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:11\u001b[0m,\u001b[1;36m677\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">709</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:11\u001b[0m,\u001b[1;36m709\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:11\u001b[0m,\u001b[1;36m736\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">890</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:11\u001b[0m,\u001b[1;36m890\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">941</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:11\u001b[0m,\u001b[1;36m941\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">981</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:11\u001b[0m,\u001b[1;36m981\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7aad9f825734cf28c08f0e808f02f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.005754399373371567\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_20ab6327-c7f3-4517-95cf-9d127cbafef1.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_20ab6327-c7f3-4517-95cf-9d127cbafef1.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">104</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.005754399373371567</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:24\u001b[0m,\u001b[1;36m104\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.005754399373371567\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:32:24</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:32:24\u001b[0m,\u001b[1;36m110\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  121 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  121 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 121 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 121 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 155                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 121 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 121 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 155                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c9bc26acf54464aaa7801438eb58c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">397</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:14\u001b[0m,\u001b[1;36m397\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:14</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">399</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:14\u001b[0m,\u001b[1;36m399\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">264</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:18\u001b[0m,\u001b[1;36m264\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">296</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:18\u001b[0m,\u001b[1;36m296\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">322</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:18\u001b[0m,\u001b[1;36m322\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">472</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:18\u001b[0m,\u001b[1;36m472\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:18\u001b[0m,\u001b[1;36m524\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">566</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:18\u001b[0m,\u001b[1;36m566\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4384348773434c2b9557cbc9c84579f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.030199517204020192\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_58a1acac-c8e2-46f2-96cd-ff764260a306.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_58a1acac-c8e2-46f2-96cd-ff764260a306.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">621</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.030199517204020192</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:29\u001b[0m,\u001b[1;36m621\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.030199517204020192\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:46:29</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">627</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:46:29\u001b[0m,\u001b[1;36m627\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │ 73.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │ 73.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 73.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 73.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 131                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 73.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 73.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 131                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86f8dbbc6df46bf95704c39c10fd025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">034</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:45\u001b[0m,\u001b[1;36m034\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">036</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:45\u001b[0m,\u001b[1;36m036\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">274</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:48\u001b[0m,\u001b[1;36m274\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">306</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:48\u001b[0m,\u001b[1;36m306\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">333</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:48\u001b[0m,\u001b[1;36m333\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">483</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabNetModel            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:48\u001b[0m,\u001b[1;36m483\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabNetModel            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">533</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:48\u001b[0m,\u001b[1;36m533\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">572</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:48\u001b[0m,\u001b[1;36m572\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3a4622569b4bc8a78b4fe3d6c335bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_c7af7fbf-8f56-45e2-99d2-ef1728c942d5.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_c7af7fbf-8f56-45e2-99d2-ef1728c942d5.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:58</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">519</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:58\u001b[0m,\u001b[1;36m519\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:53:58</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">525</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:53:58\u001b[0m,\u001b[1;36m525\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _backbone        │ TabNetBackbone   │  155 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Identity         │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ TabNetBackbone   │  155 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Identity         │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 155 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 155 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 107                                                                                         \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 155 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 155 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 107                                                                                         \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae8b898e5134c3fb707cc4166cd6ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">320</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:41\u001b[0m,\u001b[1;36m320\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:41</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">321</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:41\u001b[0m,\u001b[1;36m321\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabnet_study = optuna.create_study(direction=\"maximize\")\n",
    "tabnet_study.optimize(TabNet_Optimization, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b979953b-bebb-4b1f-90c2-ff9d4ed7d590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_d': 33, 'n_a': 46, 'n_steps': 3, 'gamma': 1.2864230491528987, 'embedding_dropout': 0.1825276618254278, 'learning_rate': 0.00468046516266798}\n",
      "Best F1 score: 0.9057275814173009\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", tabnet_study.best_params)\n",
    "print(\"Best F1 score:\", tabnet_study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a4748-8644-48c4-9cd9-0d63bc5cde54",
   "metadata": {},
   "source": [
    "## GANDALF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26bfc5a2-13df-4eea-bf2c-d2a22cce451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GANDALF_Optimization(trial):\n",
    "    gflu_stages               = trial.suggest_int(\"gflu_stages\", 1, 10)\n",
    "    gflu_dropout              = trial.suggest_float(\"gflu_dropout\", 0.0, 0.5)\n",
    "    gflu_feature_init_sparsity = trial.suggest_float(\"gflu_feature_init_sparsity\", 0.1, 0.9)\n",
    "    learnable_sparsity        = trial.suggest_categorical(\"learnable_sparsity\", [True, False])\n",
    "    embedding_dropout         = trial.suggest_float(\"embedding_dropout\", 0.0, 0.5)\n",
    "    batch_norm_continuous     = trial.suggest_categorical(\"batch_norm_continuous_input\", [True, False])\n",
    "    learning_rate             = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-2)\n",
    "\n",
    "    # 2) build Gandalf config\n",
    "    gandalf_config = GANDALFConfig(\n",
    "        task=\"classification\",\n",
    "        gflu_stages=gflu_stages,\n",
    "        gflu_dropout=gflu_dropout,\n",
    "        gflu_feature_init_sparsity=gflu_feature_init_sparsity,\n",
    "        learnable_sparsity=learnable_sparsity,\n",
    "        embedding_dropout=embedding_dropout,\n",
    "        batch_norm_continuous_input=batch_norm_continuous,\n",
    "        learning_rate=learning_rate,\n",
    "        metrics=[\n",
    "            \"auroc\",\n",
    "            \"recall\",\n",
    "            \"precision\",\n",
    "            \"f1_score\",\n",
    "            \"cohen_kappa\",\n",
    "            \"matthews_corrcoef\",\n",
    "            \"hamming_distance\",\n",
    "            \"jaccard_index\",\n",
    "        ],\n",
    "        metrics_prob_input=[\n",
    "            True,   # auroc\n",
    "            False,  # recall\n",
    "            False,  # precision\n",
    "            False,  # f1_score\n",
    "            False,  # cohen_kappa\n",
    "            False,  # matthews_corrcoef\n",
    "            False,  # hamming_distance\n",
    "            False,  # jaccard_index\n",
    "        ],\n",
    "        metrics_params=[\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # auroc\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # recall\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # precision\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # f1_score\n",
    "            {\"num_classes\": 2},                      # cohen_kappa\n",
    "            {},                                      # matthews_corrcoef\n",
    "            {},                                      # hamming_distance\n",
    "            {\"average\": \"macro\", \"num_classes\": 2},  # jaccard_index\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # 3) instantiate & train\n",
    "    model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=gandalf_config,\n",
    "        optimizer_config=optimizer_config,\n",
    "        trainer_config=trainer_config,\n",
    "        verbose=True\n",
    "    )\n",
    "    model.fit(train=train, validation=val)\n",
    "\n",
    "    # 4) predict & return macro-F1\n",
    "    preds = model.predict(val)\n",
    "    y_pred = preds[\"Label_prediction\"].to_numpy()\n",
    "    y_true = val[\"Label\"].to_numpy()\n",
    "    return f1_score(y_true, y_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f7e9818-c3ab-4d02-90d7-8d845fb10055",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">664</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:44\u001b[0m,\u001b[1;36m664\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">699</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:44\u001b[0m,\u001b[1;36m699\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">730</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:44\u001b[0m,\u001b[1;36m730\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">897</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:44\u001b[0m,\u001b[1;36m897\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">958</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:44\u001b[0m,\u001b[1;36m958\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">001</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:45\u001b[0m,\u001b[1;36m001\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923bb2955c0d4e2aa915031290cb6237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_99af5e1e-8642-4ffd-becf-0f4d5d5ddd5c.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_99af5e1e-8642-4ffd-becf-0f4d5d5ddd5c.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:53\u001b[0m,\u001b[1;36m284\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:59:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">287</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m14:59:53\u001b[0m,\u001b[1;36m287\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 31.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 31.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 31.5 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 7                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 31.5 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 30                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 31.5 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 7                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 31.5 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 30                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2556c87f6934f63859343ba65bd7694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">895</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:40\u001b[0m,\u001b[1;36m895\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">897</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:40\u001b[0m,\u001b[1;36m897\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">682</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:42\u001b[0m,\u001b[1;36m682\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:42\u001b[0m,\u001b[1;36m718\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">746</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:42\u001b[0m,\u001b[1;36m746\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">904</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:42\u001b[0m,\u001b[1;36m904\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">952</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:42\u001b[0m,\u001b[1;36m952\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:43\u001b[0m,\u001b[1;36m000\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f594fbd05d394e0aa5c6361d1f8de537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01445439770745928\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_48892689-382b-47af-91f8-9f177bef6553.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_48892689-382b-47af-91f8-9f177bef6553.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">876</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01445439770745928</span>. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:50\u001b[0m,\u001b[1;36m876\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01445439770745928\u001b[0m. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:04:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">879</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:04:50\u001b[0m,\u001b[1;36m879\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 26.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 26.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 27.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 6                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 27.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 28                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 27.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 6                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 27.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 28                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ddaeacc53d249c4b52926f2a09a082a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">160</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:06\u001b[0m,\u001b[1;36m160\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:06</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">162</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:06\u001b[0m,\u001b[1;36m162\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">774</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:07\u001b[0m,\u001b[1;36m774\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">806</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:07\u001b[0m,\u001b[1;36m806\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">832</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:07\u001b[0m,\u001b[1;36m832\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">001</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:08\u001b[0m,\u001b[1;36m001\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">048</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:08\u001b[0m,\u001b[1;36m048\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:08</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">091</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:08\u001b[0m,\u001b[1;36m091\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a901dd099540fcabc688ab35fb4390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_a36b762b-e13a-48ea-b62a-ece08a31afc2.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_a36b762b-e13a-48ea-b62a-ece08a31afc2.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">404</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:17\u001b[0m,\u001b[1;36m404\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:08:17</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">408</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:08:17\u001b[0m,\u001b[1;36m408\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 44.8 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 44.8 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 44.9 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 44.9 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 36                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 44.9 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 44.9 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 36                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6bfe0be6bd4c3f83bcac9bd91efc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">284</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:18\u001b[0m,\u001b[1;36m284\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:18</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:18\u001b[0m,\u001b[1;36m286\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">254</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:20\u001b[0m,\u001b[1;36m254\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">286</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:20\u001b[0m,\u001b[1;36m286\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">313</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:20\u001b[0m,\u001b[1;36m313\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">479</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:20\u001b[0m,\u001b[1;36m479\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">522</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:20\u001b[0m,\u001b[1;36m522\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">562</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:20\u001b[0m,\u001b[1;36m562\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c01b5cd2a984a0ca9057ee923e6a024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.017378008287493765\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_660381c1-aec6-482d-936e-2c78ace2e4da.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_660381c1-aec6-482d-936e-2c78ace2e4da.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">972</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.017378008287493765</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:26\u001b[0m,\u001b[1;36m972\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.017378008287493765\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:11:26</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">975</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:11:26\u001b[0m,\u001b[1;36m975\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │  4.5 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │  4.5 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.5 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.5 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.5 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.5 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfdab85a16724d6392e36a806c75c19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">713</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:33\u001b[0m,\u001b[1;36m713\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:33</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">715</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:33\u001b[0m,\u001b[1;36m715\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">820</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:34\u001b[0m,\u001b[1;36m820\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">853</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:34\u001b[0m,\u001b[1;36m853\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:34</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">882</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:34\u001b[0m,\u001b[1;36m882\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">056</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:35\u001b[0m,\u001b[1;36m056\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">109</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:35\u001b[0m,\u001b[1;36m109\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">156</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:35\u001b[0m,\u001b[1;36m156\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4a00552edf439db9abf1caf1d42dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.017378008287493765\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_1d2429da-04b1-4a31-95f1-23f3692c71d6.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_1d2429da-04b1-4a31-95f1-23f3692c71d6.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.017378008287493765</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:43\u001b[0m,\u001b[1;36m810\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.017378008287493765\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:13:43</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">814</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:13:43\u001b[0m,\u001b[1;36m814\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 35.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 35.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 36.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 36.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 32                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 36.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 36.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 32                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb538aede2ae461b8566849382b2fe2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">627</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:00\u001b[0m,\u001b[1;36m627\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">629</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:00\u001b[0m,\u001b[1;36m629\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">543</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:02\u001b[0m,\u001b[1;36m543\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">576</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:02\u001b[0m,\u001b[1;36m576\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">604</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:02\u001b[0m,\u001b[1;36m604\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">759</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:02\u001b[0m,\u001b[1;36m759\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">807</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:02\u001b[0m,\u001b[1;36m807\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:02</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">852</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:02\u001b[0m,\u001b[1;36m852\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ccc47a1a5246fdb80f3559b14c4ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.017378008287493765\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_6c919b69-a64b-4c03-8d75-0cbe3a13a9ef.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_6c919b69-a64b-4c03-8d75-0cbe3a13a9ef.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">369</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.017378008287493765</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:11\u001b[0m,\u001b[1;36m369\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.017378008287493765\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:18:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">372</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:18:11\u001b[0m,\u001b[1;36m372\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 35.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 35.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 35.9 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 8                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 35.9 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 30                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 35.9 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 8                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 35.9 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 30                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f329444cbf846dd8c7092fb70c239b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">543</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:46\u001b[0m,\u001b[1;36m543\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:46</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">545</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:46\u001b[0m,\u001b[1;36m545\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:48\u001b[0m,\u001b[1;36m630\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">665</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:48\u001b[0m,\u001b[1;36m665\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">695</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:48\u001b[0m,\u001b[1;36m695\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">851</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:48\u001b[0m,\u001b[1;36m851\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">896</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:48\u001b[0m,\u001b[1;36m896\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:48</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">940</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:48\u001b[0m,\u001b[1;36m940\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5eb43679794ee585f9ed627c50f4eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01445439770745928\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_e3c86eb3-45b8-4769-9bc7-7269a03cad70.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_e3c86eb3-45b8-4769-9bc7-7269a03cad70.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">240</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01445439770745928</span>. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:56\u001b[0m,\u001b[1;36m240\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01445439770745928\u001b[0m. For plot \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:23:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">243</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:23:56\u001b[0m,\u001b[1;36m243\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 17.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 17.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 18.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 4                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 18.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 24                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 18.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 4                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 18.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 24                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654c49c487bb4794816ba6e1c6ab2b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">202</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:20\u001b[0m,\u001b[1;36m202\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:20</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">205</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:20\u001b[0m,\u001b[1;36m205\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">716</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:21\u001b[0m,\u001b[1;36m716\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">748</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:21\u001b[0m,\u001b[1;36m748\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">775</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:21\u001b[0m,\u001b[1;36m775\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">939</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:21\u001b[0m,\u001b[1;36m939\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:21</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">987</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:21\u001b[0m,\u001b[1;36m987\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">031</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:22\u001b[0m,\u001b[1;36m031\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6ce16bb105458fb8adb95fd97f155b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.030199517204020192\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_7debf09e-9788-46b5-84cf-8cfb2f084aee.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_7debf09e-9788-46b5-84cf-8cfb2f084aee.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">941</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.030199517204020192</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:30\u001b[0m,\u001b[1;36m941\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.030199517204020192\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:26:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">945</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:26:30\u001b[0m,\u001b[1;36m945\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 40.3 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 40.3 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 40.4 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 9                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 40.4 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 32                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 40.4 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 9                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 40.4 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 32                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0362e35346144049981568f417a6e663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">255</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:50\u001b[0m,\u001b[1;36m255\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:50</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">257</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:50\u001b[0m,\u001b[1;36m257\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">313</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:52\u001b[0m,\u001b[1;36m313\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">344</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:52\u001b[0m,\u001b[1;36m344\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:52\u001b[0m,\u001b[1;36m373\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">546</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:52\u001b[0m,\u001b[1;36m546\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">595</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:52\u001b[0m,\u001b[1;36m595\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">637</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:30:52\u001b[0m,\u001b[1;36m637\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c057736619b4fe88486bdc1397dafd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.012022644346174132\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_ee21c77c-c1a8-41af-b21c-07acae991628.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_ee21c77c-c1a8-41af-b21c-07acae991628.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:31:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">297</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.012022644346174132</span>. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:31:00\u001b[0m,\u001b[1;36m297\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.012022644346174132\u001b[0m. For plot\n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:31:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:31:00\u001b[0m,\u001b[1;36m300\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 22.4 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 22.4 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │      0 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 22.5 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 22.5 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 24                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 22.5 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 22.5 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 24                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb158f8e7564df6b52834f12dbc4a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">537</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:30\u001b[0m,\u001b[1;36m537\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:30</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">539</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:30\u001b[0m,\u001b[1;36m539\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:31</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">998</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:31\u001b[0m,\u001b[1;36m998\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">031</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:32\u001b[0m,\u001b[1;36m031\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">058</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:32\u001b[0m,\u001b[1;36m058\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "classification task                                                                                                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">211</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: GANDALFModel           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:32\u001b[0m,\u001b[1;36m211\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: GANDALFModel           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">258</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:32\u001b[0m,\u001b[1;36m258\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:32</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">301</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:32\u001b[0m,\u001b[1;36m301\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12c2dc586a3447d81c367d36c5d91b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.01\n",
      "Restoring states from the checkpoint path at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_f835963a-4b9f-45b2-ad9b-20d569d85943.ckpt\n",
      "Restored all states from the checkpoint at G:\\Semester Arbeit\\Programming\\masterarbeit_python\\.lr_find_f835963a-4b9f-45b2-ad9b-20d569d85943.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">226</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01</span>. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:40\u001b[0m,\u001b[1;36m226\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.01\u001b[0m. For plot and detailed   \n",
       "analysis, use `find_learning_rate` method.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:33:40</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">229</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:33:40\u001b[0m,\u001b[1;36m229\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ GANDALFBackbone  │ 26.9 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ _head            │ Sequential       │     58 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ GANDALFBackbone  │ 26.9 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer │     54 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ _head            │ Sequential       │     58 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ CrossEntropyLoss │      0 │ train │\n",
       "└───┴──────────────────┴──────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 27.0 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 6                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 27.0 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 28                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 27.0 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 6                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 27.0 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 28                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e6d35c3b3543b3bb106da6ce7360c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:39:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">216</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:39:35\u001b[0m,\u001b[1;36m216\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">09</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:39:35</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">218</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m09\u001b[0m-\u001b[1;36m26\u001b[0m \u001b[1;92m15:39:35\u001b[0m,\u001b[1;36m218\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gandalf_study = optuna.create_study(direction=\"maximize\")\n",
    "gandalf_study.optimize(GANDALF_Optimization, n_trials=n_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b78d45bc-c0e6-47bc-bb27-43fa402152d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gflu_stages': 8, 'gflu_dropout': 0.20621973444441227, 'gflu_feature_init_sparsity': 0.5069371167197942, 'learnable_sparsity': False, 'embedding_dropout': 0.06647823724375934, 'batch_norm_continuous_input': False, 'learning_rate': 2.6124262014312122e-05}\n",
      "Best F1 score: 0.9000711214059307\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", gandalf_study.best_params)\n",
    "print(\"Best F1 score:\", gandalf_study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
